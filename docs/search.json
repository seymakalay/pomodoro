[{"path":"/articles/Pomodoro_Vignette.html","id":"estimate_models","dir":"Articles","previous_headings":"","what":"Estimate_Models","title":"Pomodoro_Vignette","text":"Estimate_Models function considers exog xadd variables set multiple models based selected exog xadd. one hand exog subtract selected vector dataset run model dataset splits exog. hand xadd add selected vectors run model. dnames unique values exog save model estimates name.","code":"sample_data <- sample_data[c(1:750),] yvar <- c(\"Loan.Type\") xvar <- c(\"sex\", \"married\", \"age\", \"havejob\", \"educ\", \"political.afl\", \"rural\", \"region\", \"fin.intermdiaries\", \"fin.knowldge\", \"income\") CCP.RF <- Estimate_Models(sample_data, yvar, xvec = xvar, exog = \"political.afl\", xadd = c(\"networth\", \"networth_homequity\", \"liquid.assets\"), type = \"RF\", dnames = c(\"0\",\"1\")) #> + Fold01: mtry= 2  #> - Fold01: mtry= 2  #> + Fold01: mtry= 6  #> - Fold01: mtry= 6  #> + Fold01: mtry=11  #> - Fold01: mtry=11  #> + Fold02: mtry= 2  #> - Fold02: mtry= 2  #> + Fold02: mtry= 6  #> - Fold02: mtry= 6  #> + Fold02: mtry=11  #> - Fold02: mtry=11  #> + Fold03: mtry= 2  #> - Fold03: mtry= 2  #> + Fold03: mtry= 6  #> - Fold03: mtry= 6  #> + Fold03: mtry=11  #> - Fold03: mtry=11  #> + Fold04: mtry= 2  #> - Fold04: mtry= 2  #> + Fold04: mtry= 6  #> - Fold04: mtry= 6  #> + Fold04: mtry=11  #> - Fold04: mtry=11  #> + Fold05: mtry= 2  #> - Fold05: mtry= 2  #> + Fold05: mtry= 6  #> - Fold05: mtry= 6  #> + Fold05: mtry=11  #> - Fold05: mtry=11  #> + Fold06: mtry= 2  #> - Fold06: mtry= 2  #> + Fold06: mtry= 6  #> - Fold06: mtry= 6  #> + Fold06: mtry=11  #> - Fold06: mtry=11  #> + Fold07: mtry= 2  #> - Fold07: mtry= 2  #> + Fold07: mtry= 6  #> - Fold07: mtry= 6  #> + Fold07: mtry=11  #> - Fold07: mtry=11  #> + Fold08: mtry= 2  #> - Fold08: mtry= 2  #> + Fold08: mtry= 6  #> - Fold08: mtry= 6  #> + Fold08: mtry=11  #> - Fold08: mtry=11  #> + Fold09: mtry= 2  #> - Fold09: mtry= 2  #> + Fold09: mtry= 6  #> - Fold09: mtry= 6  #> + Fold09: mtry=11  #> - Fold09: mtry=11  #> + Fold10: mtry= 2  #> - Fold10: mtry= 2  #> + Fold10: mtry= 6  #> - Fold10: mtry= 6  #> + Fold10: mtry=11  #> - Fold10: mtry=11  #> Aggregating results #> Selecting tuning parameters #> Fitting mtry = 2 on full training set #> + Fold01: mtry= 2  #> - Fold01: mtry= 2  #> + Fold01: mtry= 6  #> - Fold01: mtry= 6  #> + Fold01: mtry=11  #> - Fold01: mtry=11  #> + Fold02: mtry= 2  #> - Fold02: mtry= 2  #> + Fold02: mtry= 6  #> - Fold02: mtry= 6  #> + Fold02: mtry=11  #> - Fold02: mtry=11  #> + Fold03: mtry= 2  #> - Fold03: mtry= 2  #> + Fold03: mtry= 6  #> - Fold03: mtry= 6  #> + Fold03: mtry=11  #> - Fold03: mtry=11  #> + Fold04: mtry= 2  #> - Fold04: mtry= 2  #> + Fold04: mtry= 6  #> - Fold04: mtry= 6  #> + Fold04: mtry=11  #> - Fold04: mtry=11  #> + Fold05: mtry= 2  #> - Fold05: mtry= 2  #> + Fold05: mtry= 6  #> - Fold05: mtry= 6  #> + Fold05: mtry=11  #> - Fold05: mtry=11  #> + Fold06: mtry= 2  #> - Fold06: mtry= 2  #> + Fold06: mtry= 6  #> - Fold06: mtry= 6  #> + Fold06: mtry=11  #> - Fold06: mtry=11  #> + Fold07: mtry= 2  #> - Fold07: mtry= 2  #> + Fold07: mtry= 6  #> - Fold07: mtry= 6  #> + Fold07: mtry=11  #> - Fold07: mtry=11  #> + Fold08: mtry= 2  #> - Fold08: mtry= 2  #> + Fold08: mtry= 6  #> - Fold08: mtry= 6  #> + Fold08: mtry=11  #> - Fold08: mtry=11  #> + Fold09: mtry= 2  #> - Fold09: mtry= 2  #> + Fold09: mtry= 6  #> - Fold09: mtry= 6  #> + Fold09: mtry=11  #> - Fold09: mtry=11  #> + Fold10: mtry= 2  #> - Fold10: mtry= 2  #> + Fold10: mtry= 6  #> - Fold10: mtry= 6  #> + Fold10: mtry=11  #> - Fold10: mtry=11  #> Aggregating results #> Selecting tuning parameters #> Fitting mtry = 2 on full training set #> + Fold01: mtry= 2  #> - Fold01: mtry= 2  #> + Fold01: mtry= 6  #> - Fold01: mtry= 6  #> + Fold01: mtry=11  #> - Fold01: mtry=11  #> + Fold02: mtry= 2  #> - Fold02: mtry= 2  #> + Fold02: mtry= 6  #> - Fold02: mtry= 6  #> + Fold02: mtry=11  #> - Fold02: mtry=11  #> + Fold03: mtry= 2  #> - Fold03: mtry= 2  #> + Fold03: mtry= 6  #> - Fold03: mtry= 6  #> + Fold03: mtry=11  #> - Fold03: mtry=11  #> + Fold04: mtry= 2  #> - Fold04: mtry= 2  #> + Fold04: mtry= 6  #> - Fold04: mtry= 6  #> + Fold04: mtry=11  #> - Fold04: mtry=11  #> + Fold05: mtry= 2  #> - Fold05: mtry= 2  #> + Fold05: mtry= 6  #> - Fold05: mtry= 6  #> + Fold05: mtry=11  #> - Fold05: mtry=11  #> + Fold06: mtry= 2  #> - Fold06: mtry= 2  #> + Fold06: mtry= 6  #> - Fold06: mtry= 6  #> + Fold06: mtry=11  #> - Fold06: mtry=11  #> + Fold07: mtry= 2  #> - Fold07: mtry= 2  #> + Fold07: mtry= 6  #> - Fold07: mtry= 6  #> + Fold07: mtry=11  #> - Fold07: mtry=11  #> + Fold08: mtry= 2  #> - Fold08: mtry= 2  #> + Fold08: mtry= 6  #> - Fold08: mtry= 6  #> + Fold08: mtry=11  #> - Fold08: mtry=11  #> + Fold09: mtry= 2  #> - Fold09: mtry= 2  #> + Fold09: mtry= 6  #> - Fold09: mtry= 6  #> + Fold09: mtry=11  #> - Fold09: mtry=11  #> + Fold10: mtry= 2  #> - Fold10: mtry= 2  #> + Fold10: mtry= 6  #> - Fold10: mtry= 6  #> + Fold10: mtry=11  #> - Fold10: mtry=11  #> Aggregating results #> Selecting tuning parameters #> Fitting mtry = 2 on full training set #> + Fold01: mtry= 2  #> - Fold01: mtry= 2  #> + Fold01: mtry= 6  #> - Fold01: mtry= 6  #> + Fold01: mtry=11  #> - Fold01: mtry=11  #> + Fold02: mtry= 2  #> - Fold02: mtry= 2  #> + Fold02: mtry= 6  #> - Fold02: mtry= 6  #> + Fold02: mtry=11  #> - Fold02: mtry=11  #> + Fold03: mtry= 2  #> - Fold03: mtry= 2  #> + Fold03: mtry= 6  #> - Fold03: mtry= 6  #> + Fold03: mtry=11  #> - Fold03: mtry=11  #> + Fold04: mtry= 2  #> - Fold04: mtry= 2  #> + Fold04: mtry= 6  #> - Fold04: mtry= 6  #> + Fold04: mtry=11  #> - Fold04: mtry=11  #> + Fold05: mtry= 2  #> - Fold05: mtry= 2  #> + Fold05: mtry= 6  #> - Fold05: mtry= 6  #> + Fold05: mtry=11  #> - Fold05: mtry=11  #> + Fold06: mtry= 2  #> - Fold06: mtry= 2  #> + Fold06: mtry= 6  #> - Fold06: mtry= 6  #> + Fold06: mtry=11  #> - Fold06: mtry=11  #> + Fold07: mtry= 2  #> - Fold07: mtry= 2  #> + Fold07: mtry= 6  #> - Fold07: mtry= 6  #> + Fold07: mtry=11  #> - Fold07: mtry=11  #> + Fold08: mtry= 2  #> - Fold08: mtry= 2  #> + Fold08: mtry= 6  #> - Fold08: mtry= 6  #> + Fold08: mtry=11  #> - Fold08: mtry=11  #> + Fold09: mtry= 2  #> - Fold09: mtry= 2  #> + Fold09: mtry= 6  #> - Fold09: mtry= 6  #> + Fold09: mtry=11  #> - Fold09: mtry=11  #> + Fold10: mtry= 2  #> - Fold10: mtry= 2  #> + Fold10: mtry= 6  #> - Fold10: mtry= 6  #> + Fold10: mtry=11  #> - Fold10: mtry=11  #> Aggregating results #> Selecting tuning parameters #> Fitting mtry = 2 on full training set #> + Fold01: mtry= 2  #> - Fold01: mtry= 2  #> + Fold01: mtry= 6  #> - Fold01: mtry= 6  #> + Fold01: mtry=11  #> - Fold01: mtry=11  #> + Fold02: mtry= 2  #> - Fold02: mtry= 2  #> + Fold02: mtry= 6  #> - Fold02: mtry= 6  #> + Fold02: mtry=11  #> - Fold02: mtry=11  #> + Fold03: mtry= 2  #> - Fold03: mtry= 2  #> + Fold03: mtry= 6  #> - Fold03: mtry= 6  #> + Fold03: mtry=11  #> - Fold03: mtry=11  #> + Fold04: mtry= 2  #> - Fold04: mtry= 2  #> + Fold04: mtry= 6  #> - Fold04: mtry= 6  #> + Fold04: mtry=11  #> - Fold04: mtry=11  #> + Fold05: mtry= 2  #> - Fold05: mtry= 2  #> + Fold05: mtry= 6  #> - Fold05: mtry= 6  #> + Fold05: mtry=11  #> - Fold05: mtry=11  #> + Fold06: mtry= 2  #> - Fold06: mtry= 2  #> + Fold06: mtry= 6  #> - Fold06: mtry= 6  #> + Fold06: mtry=11  #> - Fold06: mtry=11  #> + Fold07: mtry= 2  #> - Fold07: mtry= 2  #> + Fold07: mtry= 6  #> - Fold07: mtry= 6  #> + Fold07: mtry=11  #> - Fold07: mtry=11  #> + Fold08: mtry= 2  #> - Fold08: mtry= 2  #> + Fold08: mtry= 6  #> - Fold08: mtry= 6  #> + Fold08: mtry=11  #> - Fold08: mtry=11  #> + Fold09: mtry= 2  #> - Fold09: mtry= 2  #> + Fold09: mtry= 6  #> - Fold09: mtry= 6  #> + Fold09: mtry=11  #> - Fold09: mtry=11  #> + Fold10: mtry= 2  #> - Fold10: mtry= 2  #> + Fold10: mtry= 6  #> - Fold10: mtry= 6  #> + Fold10: mtry=11  #> - Fold10: mtry=11  #> Aggregating results #> Selecting tuning parameters #> Fitting mtry = 2 on full training set #> + Fold01: mtry= 2  #> - Fold01: mtry= 2  #> + Fold01: mtry= 6  #> - Fold01: mtry= 6  #> + Fold01: mtry=11  #> - Fold01: mtry=11  #> + Fold02: mtry= 2  #> - Fold02: mtry= 2  #> + Fold02: mtry= 6  #> - Fold02: mtry= 6  #> + Fold02: mtry=11  #> - Fold02: mtry=11  #> + Fold03: mtry= 2  #> - Fold03: mtry= 2  #> + Fold03: mtry= 6  #> - Fold03: mtry= 6  #> + Fold03: mtry=11  #> - Fold03: mtry=11  #> + Fold04: mtry= 2  #> - Fold04: mtry= 2  #> + Fold04: mtry= 6  #> - Fold04: mtry= 6  #> + Fold04: mtry=11  #> - Fold04: mtry=11  #> + Fold05: mtry= 2  #> - Fold05: mtry= 2  #> + Fold05: mtry= 6  #> - Fold05: mtry= 6  #> + Fold05: mtry=11  #> - Fold05: mtry=11  #> + Fold06: mtry= 2  #> - Fold06: mtry= 2  #> + Fold06: mtry= 6  #> - Fold06: mtry= 6  #> + Fold06: mtry=11  #> - Fold06: mtry=11  #> + Fold07: mtry= 2  #> - Fold07: mtry= 2  #> + Fold07: mtry= 6  #> - Fold07: mtry= 6  #> + Fold07: mtry=11  #> - Fold07: mtry=11  #> + Fold08: mtry= 2  #> - Fold08: mtry= 2  #> + Fold08: mtry= 6  #> - Fold08: mtry= 6  #> + Fold08: mtry=11  #> - Fold08: mtry=11  #> + Fold09: mtry= 2  #> - Fold09: mtry= 2  #> + Fold09: mtry= 6  #> - Fold09: mtry= 6  #> + Fold09: mtry=11  #> - Fold09: mtry=11  #> + Fold10: mtry= 2  #> - Fold10: mtry= 2  #> + Fold10: mtry= 6  #> - Fold10: mtry= 6  #> + Fold10: mtry=11  #> - Fold10: mtry=11  #> Aggregating results #> Selecting tuning parameters #> Fitting mtry = 2 on full training set #> + Fold01: mtry= 2  #> - Fold01: mtry= 2  #> + Fold01: mtry= 6  #> - Fold01: mtry= 6  #> + Fold01: mtry=11  #> - Fold01: mtry=11  #> + Fold02: mtry= 2  #> - Fold02: mtry= 2  #> + Fold02: mtry= 6  #> - Fold02: mtry= 6  #> + Fold02: mtry=11  #> - Fold02: mtry=11  #> + Fold03: mtry= 2  #> - Fold03: mtry= 2  #> + Fold03: mtry= 6  #> - Fold03: mtry= 6  #> + Fold03: mtry=11  #> - Fold03: mtry=11  #> + Fold04: mtry= 2  #> - Fold04: mtry= 2  #> + Fold04: mtry= 6  #> - Fold04: mtry= 6  #> + Fold04: mtry=11  #> - Fold04: mtry=11  #> + Fold05: mtry= 2  #> - Fold05: mtry= 2  #> + Fold05: mtry= 6  #> - Fold05: mtry= 6  #> + Fold05: mtry=11  #> - Fold05: mtry=11  #> + Fold06: mtry= 2  #> - Fold06: mtry= 2  #> + Fold06: mtry= 6  #> - Fold06: mtry= 6  #> + Fold06: mtry=11  #> - Fold06: mtry=11  #> + Fold07: mtry= 2  #> - Fold07: mtry= 2  #> + Fold07: mtry= 6  #> - Fold07: mtry= 6  #> + Fold07: mtry=11  #> - Fold07: mtry=11  #> + Fold08: mtry= 2  #> - Fold08: mtry= 2  #> + Fold08: mtry= 6  #> - Fold08: mtry= 6  #> + Fold08: mtry=11  #> - Fold08: mtry=11  #> + Fold09: mtry= 2  #> - Fold09: mtry= 2  #> + Fold09: mtry= 6  #> - Fold09: mtry= 6  #> + Fold09: mtry=11  #> - Fold09: mtry=11  #> + Fold10: mtry= 2  #> - Fold10: mtry= 2  #> + Fold10: mtry= 6  #> - Fold10: mtry= 6  #> + Fold10: mtry=11  #> - Fold10: mtry=11  #> Aggregating results #> Selecting tuning parameters #> Fitting mtry = 2 on full training set #> + Fold01: mtry= 2  #> - Fold01: mtry= 2  #> + Fold01: mtry= 6  #> - Fold01: mtry= 6  #> + Fold01: mtry=11  #> - Fold01: mtry=11  #> + Fold02: mtry= 2  #> - Fold02: mtry= 2  #> + Fold02: mtry= 6  #> - Fold02: mtry= 6  #> + Fold02: mtry=11  #> - Fold02: mtry=11  #> + Fold03: mtry= 2  #> - Fold03: mtry= 2  #> + Fold03: mtry= 6  #> - Fold03: mtry= 6  #> + Fold03: mtry=11  #> - Fold03: mtry=11  #> + Fold04: mtry= 2  #> - Fold04: mtry= 2  #> + Fold04: mtry= 6  #> - Fold04: mtry= 6  #> + Fold04: mtry=11  #> - Fold04: mtry=11  #> + Fold05: mtry= 2  #> - Fold05: mtry= 2  #> + Fold05: mtry= 6  #> - Fold05: mtry= 6  #> + Fold05: mtry=11  #> - Fold05: mtry=11  #> + Fold06: mtry= 2  #> - Fold06: mtry= 2  #> + Fold06: mtry= 6  #> - Fold06: mtry= 6  #> + Fold06: mtry=11  #> - Fold06: mtry=11  #> + Fold07: mtry= 2  #> - Fold07: mtry= 2  #> + Fold07: mtry= 6  #> - Fold07: mtry= 6  #> + Fold07: mtry=11  #> - Fold07: mtry=11  #> + Fold08: mtry= 2  #> - Fold08: mtry= 2  #> + Fold08: mtry= 6  #> - Fold08: mtry= 6  #> + Fold08: mtry=11  #> - Fold08: mtry=11  #> + Fold09: mtry= 2  #> - Fold09: mtry= 2  #> + Fold09: mtry= 6  #> - Fold09: mtry= 6  #> + Fold09: mtry=11  #> - Fold09: mtry=11  #> + Fold10: mtry= 2  #> - Fold10: mtry= 2  #> + Fold10: mtry= 6  #> - Fold10: mtry= 6  #> + Fold10: mtry=11  #> - Fold10: mtry=11  #> Aggregating results #> Selecting tuning parameters #> Fitting mtry = 2 on full training set #> + Fold01: mtry= 2  #> - Fold01: mtry= 2  #> + Fold01: mtry= 6  #> - Fold01: mtry= 6  #> + Fold01: mtry=11  #> - Fold01: mtry=11  #> + Fold02: mtry= 2  #> - Fold02: mtry= 2  #> + Fold02: mtry= 6  #> - Fold02: mtry= 6  #> + Fold02: mtry=11  #> - Fold02: mtry=11  #> + Fold03: mtry= 2  #> - Fold03: mtry= 2  #> + Fold03: mtry= 6  #> - Fold03: mtry= 6  #> + Fold03: mtry=11  #> - Fold03: mtry=11  #> + Fold04: mtry= 2  #> - Fold04: mtry= 2  #> + Fold04: mtry= 6  #> - Fold04: mtry= 6  #> + Fold04: mtry=11  #> - Fold04: mtry=11  #> + Fold05: mtry= 2  #> - Fold05: mtry= 2  #> + Fold05: mtry= 6  #> - Fold05: mtry= 6  #> + Fold05: mtry=11  #> - Fold05: mtry=11  #> + Fold06: mtry= 2  #> - Fold06: mtry= 2  #> + Fold06: mtry= 6  #> - Fold06: mtry= 6  #> + Fold06: mtry=11  #> - Fold06: mtry=11  #> + Fold07: mtry= 2  #> - Fold07: mtry= 2  #> + Fold07: mtry= 6  #> - Fold07: mtry= 6  #> + Fold07: mtry=11  #> - Fold07: mtry=11  #> + Fold08: mtry= 2  #> - Fold08: mtry= 2  #> + Fold08: mtry= 6  #> - Fold08: mtry= 6  #> + Fold08: mtry=11  #> - Fold08: mtry=11  #> + Fold09: mtry= 2  #> - Fold09: mtry= 2  #> + Fold09: mtry= 6  #> - Fold09: mtry= 6  #> + Fold09: mtry=11  #> - Fold09: mtry=11  #> + Fold10: mtry= 2  #> - Fold10: mtry= 2  #> + Fold10: mtry= 6  #> - Fold10: mtry= 6  #> + Fold10: mtry=11  #> - Fold10: mtry=11  #> Aggregating results #> Selecting tuning parameters #> Fitting mtry = 2 on full training set"},{"path":"/articles/Pomodoro_Vignette.html","id":"combined_performance","dir":"Articles","previous_headings":"","what":"Combined_Performance","title":"Pomodoro_Vignette","text":"Estimate_Models gives results based splits exog. Combined_Performance prints total performance splits.","code":"Sub.CCP.RF <- list(Mdl.1 = CCP.RF$EstMdl$`D.1+networth`, Mdl.0 = CCP.RF$EstMdl$`D.0+networth`) CCP.NoCCP.RF <- Combined_Performance (Sub.CCP.RF)"},{"path":"/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Seyma Kalay. Maintainer.","code":""},{"path":"/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Kalay S (2022). pomodoro: Predictive Power Linear Tree Modeling. https://github.com/seymakalay/pomodoro, https://seymakalay.github.io/pomodoro/.","code":"@Manual{,   title = {pomodoro: Predictive Power of Linear and Tree Modeling},   author = {Seyma Kalay},   year = {2022},   note = {https://github.com/seymakalay/pomodoro, https://seymakalay.github.io/pomodoro/}, }"},{"path":"/index.html","id":"pomodoro","dir":"","previous_headings":"","what":"Predictive Power of Linear and Tree Modeling","title":"Predictive Power of Linear and Tree Modeling","text":"goal pomodoro provide functions make predictive modeling easy.","code":""},{"path":"/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Predictive Power of Linear and Tree Modeling","text":"can install released version pomodoro CRAN :","code":"install.packages(\"pomodoro\") library(pomodoro)"},{"path":"/index.html","id":"overview","dir":"","previous_headings":"","what":"Overview","title":"Predictive Power of Linear and Tree Modeling","text":"Runs bagging, boosting, random forest, multinominal logistic logistic models. purpose package report predictive modelling results ease.","code":""},{"path":"/reference/BAG_Model.html","id":null,"dir":"Reference","previous_headings":"","what":"Bagging Model — BAG_Model","title":"Bagging Model — BAG_Model","text":"Bagging Model","code":""},{"path":"/reference/BAG_Model.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Bagging Model — BAG_Model","text":"","code":"BAG_Model(Data, xvar, yvar)"},{"path":"/reference/BAG_Model.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Bagging Model — BAG_Model","text":"Data name Dataset. xvar X variables. yvar Y variable.","code":""},{"path":"/reference/BAG_Model.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Bagging Model — BAG_Model","text":"output  BAG_Model.","code":""},{"path":"/reference/BAG_Model.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Bagging Model — BAG_Model","text":"Decision trees suffer high variance (split training data-set randomly two parts set decision tree parts, results might quite different). Bagging ensemble procedure reduces variance increases prediction accuracy statistical learning method considering many training sets (\\(\\hat{f}^{1}(x),\\hat{f}^{2}(x),\\ldots,\\hat{f}^{B}(x)\\)) population. Since can multiple training-sets, single training data-set, can generate \\(B\\) different bootstrapped training data-sets (\\(\\hat{f}^{*1}(x), \\hat{f}^{*2}(x), \\ldots,\\hat{f}^{*B}(x)\\)) \\(B\\) trees take majority vote. Therefore, bagging classification problem  defined  $$\\hat{f}(x)=arg\\max_{k}\\hat{f}^{*b}(x)$$","code":""},{"path":"/reference/BAG_Model.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Bagging Model — BAG_Model","text":"","code":"# \\donttest{ yvar <- c(\"Loan.Type\") sample_data <- sample_data[c(1:750),] xvar <- c(\"sex\", \"married\", \"age\", \"havejob\", \"educ\", \"political.afl\", \"rural\", \"region\", \"fin.intermdiaries\", \"fin.knowldge\", \"income\") BchMk.BAG <- BAG_Model(sample_data, c(xvar, \"networth\"), yvar ) #> Loading required package: ggplot2 #> Loading required package: lattice #> + Fold01: parameter=none  #> - Fold01: parameter=none  #> + Fold02: parameter=none  #> - Fold02: parameter=none  #> + Fold03: parameter=none  #> - Fold03: parameter=none  #> + Fold04: parameter=none  #> - Fold04: parameter=none  #> + Fold05: parameter=none  #> - Fold05: parameter=none  #> + Fold06: parameter=none  #> - Fold06: parameter=none  #> + Fold07: parameter=none  #> - Fold07: parameter=none  #> + Fold08: parameter=none  #> - Fold08: parameter=none  #> + Fold09: parameter=none  #> - Fold09: parameter=none  #> + Fold10: parameter=none  #> - Fold10: parameter=none  #> Aggregating results #> Fitting final model on full training set BchMk.BAG$Roc$auc #> Multi-class area under the curve: 0.7012 # }"},{"path":"/reference/Combined_Performance.html","id":null,"dir":"Reference","previous_headings":"","what":"Combined Performance of the Data Splits — Combined_Performance","title":"Combined Performance of the Data Splits — Combined_Performance","text":"Combined Performance Data Splits","code":""},{"path":"/reference/Combined_Performance.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Combined Performance of the Data Splits — Combined_Performance","text":"","code":"Combined_Performance(Sub.Est.Mdls)"},{"path":"/reference/Combined_Performance.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Combined Performance of the Data Splits — Combined_Performance","text":"Sub.Est.Mdls total perfomance exog.","code":""},{"path":"/reference/Combined_Performance.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Combined Performance of the Data Splits — Combined_Performance","text":"output  Combined_Performance.","code":""},{"path":"/reference/Combined_Performance.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Combined Performance of the Data Splits — Combined_Performance","text":"","code":"# \\donttest{ sample_data <- sample_data[c(1:750),] yvar <- c(\"Loan.Type\") xvar <- c(\"sex\", \"married\", \"age\", \"havejob\", \"educ\", \"political.afl\", \"rural\", \"region\", \"fin.intermdiaries\", \"fin.knowldge\", \"income\") CCP.RF <- Estimate_Models(sample_data, yvar, xvec = xvar, exog = \"political.afl\", xadd = c(\"networth\", \"networth_homequity\", \"liquid.assets\"), type = \"RF\", dnames = c(\"0\",\"1\")) #> + Fold01: mtry= 2  #> - Fold01: mtry= 2  #> + Fold01: mtry= 6  #> - Fold01: mtry= 6  #> + Fold01: mtry=11  #> - Fold01: mtry=11  #> + Fold02: mtry= 2  #> - Fold02: mtry= 2  #> + Fold02: mtry= 6  #> - Fold02: mtry= 6  #> + Fold02: mtry=11  #> - Fold02: mtry=11  #> + Fold03: mtry= 2  #> - Fold03: mtry= 2  #> + Fold03: mtry= 6  #> - Fold03: mtry= 6  #> + Fold03: mtry=11  #> - Fold03: mtry=11  #> + Fold04: mtry= 2  #> - Fold04: mtry= 2  #> + Fold04: mtry= 6  #> - Fold04: mtry= 6  #> + Fold04: mtry=11  #> - Fold04: mtry=11  #> + Fold05: mtry= 2  #> - Fold05: mtry= 2  #> + Fold05: mtry= 6  #> - Fold05: mtry= 6  #> + Fold05: mtry=11  #> - Fold05: mtry=11  #> + Fold06: mtry= 2  #> - Fold06: mtry= 2  #> + Fold06: mtry= 6  #> - Fold06: mtry= 6  #> + Fold06: mtry=11  #> - Fold06: mtry=11  #> + Fold07: mtry= 2  #> - Fold07: mtry= 2  #> + Fold07: mtry= 6  #> - Fold07: mtry= 6  #> + Fold07: mtry=11  #> - Fold07: mtry=11  #> + Fold08: mtry= 2  #> - Fold08: mtry= 2  #> + Fold08: mtry= 6  #> - Fold08: mtry= 6  #> + Fold08: mtry=11  #> - Fold08: mtry=11  #> + Fold09: mtry= 2  #> - Fold09: mtry= 2  #> + Fold09: mtry= 6  #> - Fold09: mtry= 6  #> + Fold09: mtry=11  #> - Fold09: mtry=11  #> + Fold10: mtry= 2  #> - Fold10: mtry= 2  #> + Fold10: mtry= 6  #> - Fold10: mtry= 6  #> + Fold10: mtry=11  #> - Fold10: mtry=11  #> Aggregating results #> Selecting tuning parameters #> Fitting mtry = 2 on full training set #> + Fold01: mtry= 2  #> - Fold01: mtry= 2  #> + Fold01: mtry= 6  #> - Fold01: mtry= 6  #> + Fold01: mtry=11  #> - Fold01: mtry=11  #> + Fold02: mtry= 2  #> - Fold02: mtry= 2  #> + Fold02: mtry= 6  #> - Fold02: mtry= 6  #> + Fold02: mtry=11  #> - Fold02: mtry=11  #> + Fold03: mtry= 2  #> - Fold03: mtry= 2  #> + Fold03: mtry= 6  #> - Fold03: mtry= 6  #> + Fold03: mtry=11  #> - Fold03: mtry=11  #> + Fold04: mtry= 2  #> - Fold04: mtry= 2  #> + Fold04: mtry= 6  #> - Fold04: mtry= 6  #> + Fold04: mtry=11  #> - Fold04: mtry=11  #> + Fold05: mtry= 2  #> - Fold05: mtry= 2  #> + Fold05: mtry= 6  #> - Fold05: mtry= 6  #> + Fold05: mtry=11  #> - Fold05: mtry=11  #> + Fold06: mtry= 2  #> - Fold06: mtry= 2  #> + Fold06: mtry= 6  #> - Fold06: mtry= 6  #> + Fold06: mtry=11  #> - Fold06: mtry=11  #> + Fold07: mtry= 2  #> - Fold07: mtry= 2  #> + Fold07: mtry= 6  #> - Fold07: mtry= 6  #> + Fold07: mtry=11  #> - Fold07: mtry=11  #> + Fold08: mtry= 2  #> - Fold08: mtry= 2  #> + Fold08: mtry= 6  #> - Fold08: mtry= 6  #> + Fold08: mtry=11  #> - Fold08: mtry=11  #> + Fold09: mtry= 2  #> - Fold09: mtry= 2  #> + Fold09: mtry= 6  #> - Fold09: mtry= 6  #> + Fold09: mtry=11  #> - Fold09: mtry=11  #> + Fold10: mtry= 2  #> - Fold10: mtry= 2  #> + Fold10: mtry= 6  #> - Fold10: mtry= 6  #> + Fold10: mtry=11  #> - Fold10: mtry=11  #> Aggregating results #> Selecting tuning parameters #> Fitting mtry = 2 on full training set #> + Fold01: mtry= 2  #> - Fold01: mtry= 2  #> + Fold01: mtry= 6  #> - Fold01: mtry= 6  #> + Fold01: mtry=11  #> - Fold01: mtry=11  #> + Fold02: mtry= 2  #> - Fold02: mtry= 2  #> + Fold02: mtry= 6  #> - Fold02: mtry= 6  #> + Fold02: mtry=11  #> - Fold02: mtry=11  #> + Fold03: mtry= 2  #> - Fold03: mtry= 2  #> + Fold03: mtry= 6  #> - Fold03: mtry= 6  #> + Fold03: mtry=11  #> - Fold03: mtry=11  #> + Fold04: mtry= 2  #> - Fold04: mtry= 2  #> + Fold04: mtry= 6  #> - Fold04: mtry= 6  #> + Fold04: mtry=11  #> - Fold04: mtry=11  #> + Fold05: mtry= 2  #> - Fold05: mtry= 2  #> + Fold05: mtry= 6  #> - Fold05: mtry= 6  #> + Fold05: mtry=11  #> - Fold05: mtry=11  #> + Fold06: mtry= 2  #> - Fold06: mtry= 2  #> + Fold06: mtry= 6  #> - Fold06: mtry= 6  #> + Fold06: mtry=11  #> - Fold06: mtry=11  #> + Fold07: mtry= 2  #> - Fold07: mtry= 2  #> + Fold07: mtry= 6  #> - Fold07: mtry= 6  #> + Fold07: mtry=11  #> - Fold07: mtry=11  #> + Fold08: mtry= 2  #> - Fold08: mtry= 2  #> + Fold08: mtry= 6  #> - Fold08: mtry= 6  #> + Fold08: mtry=11  #> - Fold08: mtry=11  #> + Fold09: mtry= 2  #> - Fold09: mtry= 2  #> + Fold09: mtry= 6  #> - Fold09: mtry= 6  #> + Fold09: mtry=11  #> - Fold09: mtry=11  #> + Fold10: mtry= 2  #> - Fold10: mtry= 2  #> + Fold10: mtry= 6  #> - Fold10: mtry= 6  #> + Fold10: mtry=11  #> - Fold10: mtry=11  #> Aggregating results #> Selecting tuning parameters #> Fitting mtry = 2 on full training set #> + Fold01: mtry= 2  #> - Fold01: mtry= 2  #> + Fold01: mtry= 6  #> - Fold01: mtry= 6  #> + Fold01: mtry=11  #> - Fold01: mtry=11  #> + Fold02: mtry= 2  #> - Fold02: mtry= 2  #> + Fold02: mtry= 6  #> - Fold02: mtry= 6  #> + Fold02: mtry=11  #> - Fold02: mtry=11  #> + Fold03: mtry= 2  #> - Fold03: mtry= 2  #> + Fold03: mtry= 6  #> - Fold03: mtry= 6  #> + Fold03: mtry=11  #> - Fold03: mtry=11  #> + Fold04: mtry= 2  #> - Fold04: mtry= 2  #> + Fold04: mtry= 6  #> - Fold04: mtry= 6  #> + Fold04: mtry=11  #> - Fold04: mtry=11  #> + Fold05: mtry= 2  #> - Fold05: mtry= 2  #> + Fold05: mtry= 6  #> - Fold05: mtry= 6  #> + Fold05: mtry=11  #> - Fold05: mtry=11  #> + Fold06: mtry= 2  #> - Fold06: mtry= 2  #> + Fold06: mtry= 6  #> - Fold06: mtry= 6  #> + Fold06: mtry=11  #> - Fold06: mtry=11  #> + Fold07: mtry= 2  #> - Fold07: mtry= 2  #> + Fold07: mtry= 6  #> - Fold07: mtry= 6  #> + Fold07: mtry=11  #> - Fold07: mtry=11  #> + Fold08: mtry= 2  #> - Fold08: mtry= 2  #> + Fold08: mtry= 6  #> - Fold08: mtry= 6  #> + Fold08: mtry=11  #> - Fold08: mtry=11  #> + Fold09: mtry= 2  #> - Fold09: mtry= 2  #> + Fold09: mtry= 6  #> - Fold09: mtry= 6  #> + Fold09: mtry=11  #> - Fold09: mtry=11  #> + Fold10: mtry= 2  #> - Fold10: mtry= 2  #> + Fold10: mtry= 6  #> - Fold10: mtry= 6  #> + Fold10: mtry=11  #> - Fold10: mtry=11  #> Aggregating results #> Selecting tuning parameters #> Fitting mtry = 2 on full training set #> + Fold01: mtry= 2  #> - Fold01: mtry= 2  #> + Fold01: mtry= 6  #> - Fold01: mtry= 6  #> + Fold01: mtry=11  #> - Fold01: mtry=11  #> + Fold02: mtry= 2  #> - Fold02: mtry= 2  #> + Fold02: mtry= 6  #> - Fold02: mtry= 6  #> + Fold02: mtry=11  #> - Fold02: mtry=11  #> + Fold03: mtry= 2  #> - Fold03: mtry= 2  #> + Fold03: mtry= 6  #> - Fold03: mtry= 6  #> + Fold03: mtry=11  #> - Fold03: mtry=11  #> + Fold04: mtry= 2  #> - Fold04: mtry= 2  #> + Fold04: mtry= 6  #> - Fold04: mtry= 6  #> + Fold04: mtry=11  #> - Fold04: mtry=11  #> + Fold05: mtry= 2  #> - Fold05: mtry= 2  #> + Fold05: mtry= 6  #> - Fold05: mtry= 6  #> + Fold05: mtry=11  #> - Fold05: mtry=11  #> + Fold06: mtry= 2  #> - Fold06: mtry= 2  #> + Fold06: mtry= 6  #> - Fold06: mtry= 6  #> + Fold06: mtry=11  #> - Fold06: mtry=11  #> + Fold07: mtry= 2  #> - Fold07: mtry= 2  #> + Fold07: mtry= 6  #> - Fold07: mtry= 6  #> + Fold07: mtry=11  #> - Fold07: mtry=11  #> + Fold08: mtry= 2  #> - Fold08: mtry= 2  #> + Fold08: mtry= 6  #> - Fold08: mtry= 6  #> + Fold08: mtry=11  #> - Fold08: mtry=11  #> + Fold09: mtry= 2  #> - Fold09: mtry= 2  #> + Fold09: mtry= 6  #> - Fold09: mtry= 6  #> + Fold09: mtry=11  #> - Fold09: mtry=11  #> + Fold10: mtry= 2  #> - Fold10: mtry= 2  #> + Fold10: mtry= 6  #> - Fold10: mtry= 6  #> + Fold10: mtry=11  #> - Fold10: mtry=11  #> Aggregating results #> Selecting tuning parameters #> Fitting mtry = 6 on full training set #> + Fold01: mtry= 2  #> - Fold01: mtry= 2  #> + Fold01: mtry= 6  #> - Fold01: mtry= 6  #> + Fold01: mtry=11  #> - Fold01: mtry=11  #> + Fold02: mtry= 2  #> - Fold02: mtry= 2  #> + Fold02: mtry= 6  #> - Fold02: mtry= 6  #> + Fold02: mtry=11  #> - Fold02: mtry=11  #> + Fold03: mtry= 2  #> - Fold03: mtry= 2  #> + Fold03: mtry= 6  #> - Fold03: mtry= 6  #> + Fold03: mtry=11  #> - Fold03: mtry=11  #> + Fold04: mtry= 2  #> - Fold04: mtry= 2  #> + Fold04: mtry= 6  #> - Fold04: mtry= 6  #> + Fold04: mtry=11  #> - Fold04: mtry=11  #> + Fold05: mtry= 2  #> - Fold05: mtry= 2  #> + Fold05: mtry= 6  #> - Fold05: mtry= 6  #> + Fold05: mtry=11  #> - Fold05: mtry=11  #> + Fold06: mtry= 2  #> - Fold06: mtry= 2  #> + Fold06: mtry= 6  #> - Fold06: mtry= 6  #> + Fold06: mtry=11  #> - Fold06: mtry=11  #> + Fold07: mtry= 2  #> - Fold07: mtry= 2  #> + Fold07: mtry= 6  #> - Fold07: mtry= 6  #> + Fold07: mtry=11  #> - Fold07: mtry=11  #> + Fold08: mtry= 2  #> - Fold08: mtry= 2  #> + Fold08: mtry= 6  #> - Fold08: mtry= 6  #> + Fold08: mtry=11  #> - Fold08: mtry=11  #> + Fold09: mtry= 2  #> - Fold09: mtry= 2  #> + Fold09: mtry= 6  #> - Fold09: mtry= 6  #> + Fold09: mtry=11  #> - Fold09: mtry=11  #> + Fold10: mtry= 2  #> - Fold10: mtry= 2  #> + Fold10: mtry= 6  #> - Fold10: mtry= 6  #> + Fold10: mtry=11  #> - Fold10: mtry=11  #> Aggregating results #> Selecting tuning parameters #> Fitting mtry = 2 on full training set #> + Fold01: mtry= 2  #> - Fold01: mtry= 2  #> + Fold01: mtry= 6  #> - Fold01: mtry= 6  #> + Fold01: mtry=11  #> - Fold01: mtry=11  #> + Fold02: mtry= 2  #> - Fold02: mtry= 2  #> + Fold02: mtry= 6  #> - Fold02: mtry= 6  #> + Fold02: mtry=11  #> - Fold02: mtry=11  #> + Fold03: mtry= 2  #> - Fold03: mtry= 2  #> + Fold03: mtry= 6  #> - Fold03: mtry= 6  #> + Fold03: mtry=11  #> - Fold03: mtry=11  #> + Fold04: mtry= 2  #> - Fold04: mtry= 2  #> + Fold04: mtry= 6  #> - Fold04: mtry= 6  #> + Fold04: mtry=11  #> - Fold04: mtry=11  #> + Fold05: mtry= 2  #> - Fold05: mtry= 2  #> + Fold05: mtry= 6  #> - Fold05: mtry= 6  #> + Fold05: mtry=11  #> - Fold05: mtry=11  #> + Fold06: mtry= 2  #> - Fold06: mtry= 2  #> + Fold06: mtry= 6  #> - Fold06: mtry= 6  #> + Fold06: mtry=11  #> - Fold06: mtry=11  #> + Fold07: mtry= 2  #> - Fold07: mtry= 2  #> + Fold07: mtry= 6  #> - Fold07: mtry= 6  #> + Fold07: mtry=11  #> - Fold07: mtry=11  #> + Fold08: mtry= 2  #> - Fold08: mtry= 2  #> + Fold08: mtry= 6  #> - Fold08: mtry= 6  #> + Fold08: mtry=11  #> - Fold08: mtry=11  #> + Fold09: mtry= 2  #> - Fold09: mtry= 2  #> + Fold09: mtry= 6  #> - Fold09: mtry= 6  #> + Fold09: mtry=11  #> - Fold09: mtry=11  #> + Fold10: mtry= 2  #> - Fold10: mtry= 2  #> + Fold10: mtry= 6  #> - Fold10: mtry= 6  #> + Fold10: mtry=11  #> - Fold10: mtry=11  #> Aggregating results #> Selecting tuning parameters #> Fitting mtry = 2 on full training set #> + Fold01: mtry= 2  #> - Fold01: mtry= 2  #> + Fold01: mtry= 6  #> - Fold01: mtry= 6  #> + Fold01: mtry=11  #> - Fold01: mtry=11  #> + Fold02: mtry= 2  #> - Fold02: mtry= 2  #> + Fold02: mtry= 6  #> - Fold02: mtry= 6  #> + Fold02: mtry=11  #> - Fold02: mtry=11  #> + Fold03: mtry= 2  #> - Fold03: mtry= 2  #> + Fold03: mtry= 6  #> - Fold03: mtry= 6  #> + Fold03: mtry=11  #> - Fold03: mtry=11  #> + Fold04: mtry= 2  #> - Fold04: mtry= 2  #> + Fold04: mtry= 6  #> - Fold04: mtry= 6  #> + Fold04: mtry=11  #> - Fold04: mtry=11  #> + Fold05: mtry= 2  #> - Fold05: mtry= 2  #> + Fold05: mtry= 6  #> - Fold05: mtry= 6  #> + Fold05: mtry=11  #> - Fold05: mtry=11  #> + Fold06: mtry= 2  #> - Fold06: mtry= 2  #> + Fold06: mtry= 6  #> - Fold06: mtry= 6  #> + Fold06: mtry=11  #> - Fold06: mtry=11  #> + Fold07: mtry= 2  #> - Fold07: mtry= 2  #> + Fold07: mtry= 6  #> - Fold07: mtry= 6  #> + Fold07: mtry=11  #> - Fold07: mtry=11  #> + Fold08: mtry= 2  #> - Fold08: mtry= 2  #> + Fold08: mtry= 6  #> - Fold08: mtry= 6  #> + Fold08: mtry=11  #> - Fold08: mtry=11  #> + Fold09: mtry= 2  #> - Fold09: mtry= 2  #> + Fold09: mtry= 6  #> - Fold09: mtry= 6  #> + Fold09: mtry=11  #> - Fold09: mtry=11  #> + Fold10: mtry= 2  #> - Fold10: mtry= 2  #> + Fold10: mtry= 6  #> - Fold10: mtry= 6  #> + Fold10: mtry=11  #> - Fold10: mtry=11  #> Aggregating results #> Selecting tuning parameters #> Fitting mtry = 2 on full training set #> + Fold01: mtry= 2  #> - Fold01: mtry= 2  #> + Fold01: mtry= 6  #> - Fold01: mtry= 6  #> + Fold01: mtry=11  #> - Fold01: mtry=11  #> + Fold02: mtry= 2  #> - Fold02: mtry= 2  #> + Fold02: mtry= 6  #> - Fold02: mtry= 6  #> + Fold02: mtry=11  #> - Fold02: mtry=11  #> + Fold03: mtry= 2  #> - Fold03: mtry= 2  #> + Fold03: mtry= 6  #> - Fold03: mtry= 6  #> + Fold03: mtry=11  #> - Fold03: mtry=11  #> + Fold04: mtry= 2  #> - Fold04: mtry= 2  #> + Fold04: mtry= 6  #> - Fold04: mtry= 6  #> + Fold04: mtry=11  #> - Fold04: mtry=11  #> + Fold05: mtry= 2  #> - Fold05: mtry= 2  #> + Fold05: mtry= 6  #> - Fold05: mtry= 6  #> + Fold05: mtry=11  #> - Fold05: mtry=11  #> + Fold06: mtry= 2  #> - Fold06: mtry= 2  #> + Fold06: mtry= 6  #> - Fold06: mtry= 6  #> + Fold06: mtry=11  #> - Fold06: mtry=11  #> + Fold07: mtry= 2  #> - Fold07: mtry= 2  #> + Fold07: mtry= 6  #> - Fold07: mtry= 6  #> + Fold07: mtry=11  #> - Fold07: mtry=11  #> + Fold08: mtry= 2  #> - Fold08: mtry= 2  #> + Fold08: mtry= 6  #> - Fold08: mtry= 6  #> + Fold08: mtry=11  #> - Fold08: mtry=11  #> + Fold09: mtry= 2  #> - Fold09: mtry= 2  #> + Fold09: mtry= 6  #> - Fold09: mtry= 6  #> + Fold09: mtry=11  #> - Fold09: mtry=11  #> + Fold10: mtry= 2  #> - Fold10: mtry= 2  #> + Fold10: mtry= 6  #> - Fold10: mtry= 6  #> + Fold10: mtry=11  #> - Fold10: mtry=11  #> Aggregating results #> Selecting tuning parameters #> Fitting mtry = 2 on full training set Sub.CCP.RF <- list (Mdl.1 = CCP.RF$EstMdl$`D.1+networth`, Mdl.0 = CCP.RF$EstMdl$`D.0+networth`) CCP.NoCCP.RF <- Combined_Performance (Sub.CCP.RF) # }"},{"path":"/reference/Estimate_Models.html","id":null,"dir":"Reference","previous_headings":"","what":"Results of the Each Data and Data Splits — Estimate_Models","title":"Results of the Each Data and Data Splits — Estimate_Models","text":"Results Data Data Splits","code":""},{"path":"/reference/Estimate_Models.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Results of the Each Data and Data Splits — Estimate_Models","text":"","code":"Estimate_Models(DataSet, yvar, exog = NULL, xvec, xadd, type, dnames)"},{"path":"/reference/Estimate_Models.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Results of the Each Data and Data Splits — Estimate_Models","text":"DataSet name Dataset. yvar Y variable. exog vector subtract calculation. xvec vector variables used. xadd additional vector used. type can RF, GLM, MLM, BAG, GBM. dnames unique values exog.","code":""},{"path":"/reference/Estimate_Models.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Results of the Each Data and Data Splits — Estimate_Models","text":"output  Estimate_Models.","code":""},{"path":"/reference/Estimate_Models.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Results of the Each Data and Data Splits — Estimate_Models","text":"","code":"# \\donttest{ sample_data <- sample_data[c(1:750),] m2.xvar0 <- c(\"sex\",\"married\",\"age\",\"havejob\",\"educ\",\"rural\",\"region\",\"income\") CCP.RF <- Estimate_Models(sample_data, yvar = c(\"Loan.Type\"), exog = \"political.afl\", xvec = m2.xvar0, xadd = \"networth\", type = \"RF\", dnames = c(\"0\",\"1\")) #> + Fold01: mtry=2  #> - Fold01: mtry=2  #> + Fold01: mtry=5  #> - Fold01: mtry=5  #> + Fold01: mtry=9  #> - Fold01: mtry=9  #> + Fold02: mtry=2  #> - Fold02: mtry=2  #> + Fold02: mtry=5  #> - Fold02: mtry=5  #> + Fold02: mtry=9  #> - Fold02: mtry=9  #> + Fold03: mtry=2  #> - Fold03: mtry=2  #> + Fold03: mtry=5  #> - Fold03: mtry=5  #> + Fold03: mtry=9  #> - Fold03: mtry=9  #> + Fold04: mtry=2  #> - Fold04: mtry=2  #> + Fold04: mtry=5  #> - Fold04: mtry=5  #> + Fold04: mtry=9  #> - Fold04: mtry=9  #> + Fold05: mtry=2  #> - Fold05: mtry=2  #> + Fold05: mtry=5  #> - Fold05: mtry=5  #> + Fold05: mtry=9  #> - Fold05: mtry=9  #> + Fold06: mtry=2  #> - Fold06: mtry=2  #> + Fold06: mtry=5  #> - Fold06: mtry=5  #> + Fold06: mtry=9  #> - Fold06: mtry=9  #> + Fold07: mtry=2  #> - Fold07: mtry=2  #> + Fold07: mtry=5  #> - Fold07: mtry=5  #> + Fold07: mtry=9  #> - Fold07: mtry=9  #> + Fold08: mtry=2  #> - Fold08: mtry=2  #> + Fold08: mtry=5  #> - Fold08: mtry=5  #> + Fold08: mtry=9  #> - Fold08: mtry=9  #> + Fold09: mtry=2  #> - Fold09: mtry=2  #> + Fold09: mtry=5  #> - Fold09: mtry=5  #> + Fold09: mtry=9  #> - Fold09: mtry=9  #> + Fold10: mtry=2  #> - Fold10: mtry=2  #> + Fold10: mtry=5  #> - Fold10: mtry=5  #> + Fold10: mtry=9  #> - Fold10: mtry=9  #> Aggregating results #> Selecting tuning parameters #> Fitting mtry = 2 on full training set #> + Fold01: mtry=2  #> - Fold01: mtry=2  #> + Fold01: mtry=5  #> - Fold01: mtry=5  #> + Fold01: mtry=9  #> - Fold01: mtry=9  #> + Fold02: mtry=2  #> - Fold02: mtry=2  #> + Fold02: mtry=5  #> - Fold02: mtry=5  #> + Fold02: mtry=9  #> - Fold02: mtry=9  #> + Fold03: mtry=2  #> - Fold03: mtry=2  #> + Fold03: mtry=5  #> - Fold03: mtry=5  #> + Fold03: mtry=9  #> - Fold03: mtry=9  #> + Fold04: mtry=2  #> - Fold04: mtry=2  #> + Fold04: mtry=5  #> - Fold04: mtry=5  #> + Fold04: mtry=9  #> - Fold04: mtry=9  #> + Fold05: mtry=2  #> - Fold05: mtry=2  #> + Fold05: mtry=5  #> - Fold05: mtry=5  #> + Fold05: mtry=9  #> - Fold05: mtry=9  #> + Fold06: mtry=2  #> - Fold06: mtry=2  #> + Fold06: mtry=5  #> - Fold06: mtry=5  #> + Fold06: mtry=9  #> - Fold06: mtry=9  #> + Fold07: mtry=2  #> - Fold07: mtry=2  #> + Fold07: mtry=5  #> - Fold07: mtry=5  #> + Fold07: mtry=9  #> - Fold07: mtry=9  #> + Fold08: mtry=2  #> - Fold08: mtry=2  #> + Fold08: mtry=5  #> - Fold08: mtry=5  #> + Fold08: mtry=9  #> - Fold08: mtry=9  #> + Fold09: mtry=2  #> - Fold09: mtry=2  #> + Fold09: mtry=5  #> - Fold09: mtry=5  #> + Fold09: mtry=9  #> - Fold09: mtry=9  #> + Fold10: mtry=2  #> - Fold10: mtry=2  #> + Fold10: mtry=5  #> - Fold10: mtry=5  #> + Fold10: mtry=9  #> - Fold10: mtry=9  #> Aggregating results #> Selecting tuning parameters #> Fitting mtry = 2 on full training set #> + Fold01: mtry=2  #> - Fold01: mtry=2  #> + Fold01: mtry=5  #> - Fold01: mtry=5  #> + Fold01: mtry=9  #> - Fold01: mtry=9  #> + Fold02: mtry=2  #> - Fold02: mtry=2  #> + Fold02: mtry=5  #> - Fold02: mtry=5  #> + Fold02: mtry=9  #> - Fold02: mtry=9  #> + Fold03: mtry=2  #> - Fold03: mtry=2  #> + Fold03: mtry=5  #> - Fold03: mtry=5  #> + Fold03: mtry=9  #> - Fold03: mtry=9  #> + Fold04: mtry=2  #> - Fold04: mtry=2  #> + Fold04: mtry=5  #> - Fold04: mtry=5  #> + Fold04: mtry=9  #> - Fold04: mtry=9  #> + Fold05: mtry=2  #> - Fold05: mtry=2  #> + Fold05: mtry=5  #> - Fold05: mtry=5  #> + Fold05: mtry=9  #> - Fold05: mtry=9  #> + Fold06: mtry=2  #> - Fold06: mtry=2  #> + Fold06: mtry=5  #> - Fold06: mtry=5  #> + Fold06: mtry=9  #> - Fold06: mtry=9  #> + Fold07: mtry=2  #> - Fold07: mtry=2  #> + Fold07: mtry=5  #> - Fold07: mtry=5  #> + Fold07: mtry=9  #> - Fold07: mtry=9  #> + Fold08: mtry=2  #> - Fold08: mtry=2  #> + Fold08: mtry=5  #> - Fold08: mtry=5  #> + Fold08: mtry=9  #> - Fold08: mtry=9  #> + Fold09: mtry=2  #> - Fold09: mtry=2  #> + Fold09: mtry=5  #> - Fold09: mtry=5  #> + Fold09: mtry=9  #> - Fold09: mtry=9  #> + Fold10: mtry=2  #> - Fold10: mtry=2  #> + Fold10: mtry=5  #> - Fold10: mtry=5  #> + Fold10: mtry=9  #> - Fold10: mtry=9  #> Aggregating results #> Selecting tuning parameters #> Fitting mtry = 2 on full training set # }"},{"path":"/reference/GBM_Model.html","id":null,"dir":"Reference","previous_headings":"","what":"Gradient Boosting Model — GBM_Model","title":"Gradient Boosting Model — GBM_Model","text":"Gradient Boosting Model","code":""},{"path":"/reference/GBM_Model.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Gradient Boosting Model — GBM_Model","text":"","code":"GBM_Model(Data, xvar, yvar)"},{"path":"/reference/GBM_Model.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Gradient Boosting Model — GBM_Model","text":"Data name Dataset. xvar X variables. yvar Y variable.","code":""},{"path":"/reference/GBM_Model.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Gradient Boosting Model — GBM_Model","text":"output  GBM_Model.","code":""},{"path":"/reference/GBM_Model.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Gradient Boosting Model — GBM_Model","text":"Unlike bagging trees, boosting use bootstrap sampling, rather tree fit using information previous trees. event probability stochastic gradient boosting model given $$\\hat{\\pi_i} = \\frac{1}{1 + exp[-f(x)]^\\prime}$$  \\(f(x)\\) range \\([-\\infty,\\infty]\\) initial estimate model  \\(f^{(0)}_i=log(\\frac{\\pi_{}}{1-\\pi_{}})\\),  \\(\\hat{\\pi}\\) estimated sample proportion single class training set.","code":""},{"path":"/reference/GBM_Model.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Gradient Boosting Model — GBM_Model","text":"","code":"# \\donttest{ yvar <- c(\"Loan.Type\") sample_data <- sample_data[c(1:120),] xvar <- c(\"sex\", \"married\", \"age\", \"havejob\", \"educ\", \"political.afl\", \"rural\", \"region\", \"fin.intermdiaries\", \"fin.knowldge\", \"income\") BchMk.GBM <- GBM_Model(sample_data, c(xvar, \"networth\"), yvar ) #> Warning: Some classes have a single record ( Informal ) and these will be selected for the sample #> Warning: These variables have zero variances: rural, region #> Warning: These variables have zero variances: rural, region #> Warning: variable 7: rural has no variation. #> Warning: variable 8: region has no variation. #> Iter   TrainDeviance   ValidDeviance   StepSize   Improve #>      1        1.0986             nan     0.1000    0.3118 #>      2        0.8995             nan     0.1000    0.1925 #>      3        0.7708             nan     0.1000    0.1605 #>      4        0.6724             nan     0.1000    0.1070 #>      5        0.5919             nan     0.1000    0.0718 #>      6        0.5396             nan     0.1000    0.0657 #>      7        0.4895             nan     0.1000    0.0526 #>      8        0.4496             nan     0.1000    0.0285 #>      9        0.4232             nan     0.1000    0.0392 #>     10        0.3901             nan     0.1000    0.0311 #>     20        0.2485             nan     0.1000    0.0003 #>     40        0.1505             nan     0.1000   -0.0014 #>     60        0.1039             nan     0.1000   -0.0094 #>     80        0.0812             nan     0.1000   -0.0103 #>    100        0.0583             nan     0.1000   -0.0087 #>    120        0.0441             nan     0.1000   -0.0067 #>    140        0.0315             nan     0.1000   -0.0034 #>    150        0.0264             nan     0.1000   -0.0013 #>  #> Warning: These variables have zero variances: rural, region #> Warning: variable 7: rural has no variation. #> Warning: variable 8: region has no variation. #> Iter   TrainDeviance   ValidDeviance   StepSize   Improve #>      1        1.0986             nan     0.1000    0.2994 #>      2        0.9056             nan     0.1000    0.2204 #>      3        0.7736             nan     0.1000    0.1513 #>      4        0.6758             nan     0.1000    0.1140 #>      5        0.5920             nan     0.1000    0.0855 #>      6        0.5287             nan     0.1000    0.0776 #>      7        0.4655             nan     0.1000    0.0604 #>      8        0.4217             nan     0.1000    0.0490 #>      9        0.3861             nan     0.1000    0.0209 #>     10        0.3586             nan     0.1000    0.0472 #>     20        0.1825             nan     0.1000   -0.0100 #>     40        0.0760             nan     0.1000   -0.0103 #>     60        0.0400             nan     0.1000   -0.0001 #>     80        0.0225             nan     0.1000   -0.0073 #>    100        0.0138             nan     0.1000   -0.0018 #>    120        0.0094             nan     0.1000   -0.0004 #>    140        0.0069             nan     0.1000   -0.0027 #>    150        0.0052             nan     0.1000   -0.0014 #>  #> Warning: These variables have zero variances: rural, region #> Warning: variable 7: rural has no variation. #> Warning: variable 8: region has no variation. #> Iter   TrainDeviance   ValidDeviance   StepSize   Improve #>      1        1.0986             nan     0.1000    0.3623 #>      2        0.9000             nan     0.1000    0.2013 #>      3        0.7707             nan     0.1000    0.1387 #>      4        0.6713             nan     0.1000    0.1175 #>      5        0.5956             nan     0.1000    0.0781 #>      6        0.5253             nan     0.1000    0.0644 #>      7        0.4813             nan     0.1000    0.0585 #>      8        0.4410             nan     0.1000    0.0758 #>      9        0.3838             nan     0.1000    0.0253 #>     10        0.3580             nan     0.1000    0.0317 #>     20        0.1740             nan     0.1000   -0.0101 #>     40        0.0732             nan     0.1000   -0.0064 #>     60        0.0342             nan     0.1000   -0.0111 #>     80        0.0177             nan     0.1000   -0.0042 #>    100        0.0136             nan     0.1000   -0.0040 #>    120        0.0058             nan     0.1000   -0.0008 #>    140        0.0034             nan     0.1000   -0.0003 #>    150        0.0036             nan     0.1000   -0.0006 #>  #> Warning: These variables have zero variances: rural, region #> Warning: variable 7: rural has no variation. #> Warning: variable 8: region has no variation. #> Iter   TrainDeviance   ValidDeviance   StepSize   Improve #>      1        1.0986             nan     0.1000    0.3388 #>      2        0.9038             nan     0.1000    0.2325 #>      3        0.7577             nan     0.1000    0.1458 #>      4        0.6634             nan     0.1000    0.1233 #>      5        0.5710             nan     0.1000    0.0837 #>      6        0.5034             nan     0.1000    0.0750 #>      7        0.4563             nan     0.1000    0.0497 #>      8        0.4149             nan     0.1000    0.0180 #>      9        0.3926             nan     0.1000    0.0279 #>     10        0.3579             nan     0.1000    0.0150 #>     20        0.2424             nan     0.1000   -0.0019 #>     40        0.1583             nan     0.1000   -0.0131 #>     60        0.1137             nan     0.1000   -0.0087 #>     80        0.0831             nan     0.1000   -0.0156 #>    100        0.0592             nan     0.1000   -0.0044 #>    120        0.0440             nan     0.1000   -0.0049 #>    140        0.0356             nan     0.1000   -0.0034 #>    150        0.0315             nan     0.1000   -0.0072 #>  #> Warning: These variables have zero variances: rural, region #> Warning: variable 7: rural has no variation. #> Warning: variable 8: region has no variation. #> Iter   TrainDeviance   ValidDeviance   StepSize   Improve #>      1        1.0986             nan     0.1000    0.3305 #>      2        0.8896             nan     0.1000    0.2181 #>      3        0.7424             nan     0.1000    0.1528 #>      4        0.6441             nan     0.1000    0.1404 #>      5        0.5623             nan     0.1000    0.0834 #>      6        0.5054             nan     0.1000    0.0914 #>      7        0.4464             nan     0.1000    0.0496 #>      8        0.4060             nan     0.1000    0.0466 #>      9        0.3735             nan     0.1000    0.0268 #>     10        0.3461             nan     0.1000    0.0170 #>     20        0.2043             nan     0.1000   -0.0024 #>     40        0.0859             nan     0.1000   -0.0070 #>     60        0.0419             nan     0.1000   -0.0080 #>     80        0.0256             nan     0.1000   -0.0025 #>    100        0.0174             nan     0.1000   -0.0014 #>    120        0.0141             nan     0.1000   -0.0003 #>    140        0.0092             nan     0.1000   -0.0006 #>    150        0.0061             nan     0.1000   -0.0004 #>  #> Warning: These variables have zero variances: rural, region #> Warning: variable 7: rural has no variation. #> Warning: variable 8: region has no variation. #> Iter   TrainDeviance   ValidDeviance   StepSize   Improve #>      1        1.0986             nan     0.1000    0.3133 #>      2        0.8862             nan     0.1000    0.2359 #>      3        0.7365             nan     0.1000    0.1303 #>      4        0.6427             nan     0.1000    0.1155 #>      5        0.5579             nan     0.1000    0.1065 #>      6        0.4875             nan     0.1000    0.0425 #>      7        0.4448             nan     0.1000    0.0604 #>      8        0.4034             nan     0.1000    0.0222 #>      9        0.3730             nan     0.1000    0.0217 #>     10        0.3442             nan     0.1000    0.0158 #>     20        0.1994             nan     0.1000   -0.0033 #>     40        0.0791             nan     0.1000   -0.0062 #>     60        0.0371             nan     0.1000   -0.0013 #>     80        0.0189             nan     0.1000   -0.0042 #>    100        0.0146             nan     0.1000   -0.0037 #>    120        0.0115             nan     0.1000    0.0001 #>    140        0.0119             nan     0.1000   -0.0016 #>    150        0.0089             nan     0.1000   -0.0035 #>  #> Warning: These variables have zero variances: rural, region #> Warning: variable 7: rural has no variation. #> Warning: variable 8: region has no variation. #> Iter   TrainDeviance   ValidDeviance   StepSize   Improve #>      1        1.0986             nan     0.1000    0.2603 #>      2        0.9183             nan     0.1000    0.1661 #>      3        0.8130             nan     0.1000    0.1395 #>      4        0.7267             nan     0.1000    0.0765 #>      5        0.6651             nan     0.1000    0.0872 #>      6        0.6115             nan     0.1000    0.0695 #>      7        0.5702             nan     0.1000    0.0321 #>      8        0.5385             nan     0.1000    0.0319 #>      9        0.5068             nan     0.1000    0.0039 #>     10        0.4807             nan     0.1000    0.0139 #>     20        0.3296             nan     0.1000    0.0039 #>     40        0.2098             nan     0.1000    0.0018 #>     60        0.1506             nan     0.1000   -0.0045 #>     80        0.1083             nan     0.1000   -0.0006 #>    100        0.0859             nan     0.1000   -0.0034 #>    120        0.0622             nan     0.1000   -0.0032 #>    140        0.0501             nan     0.1000   -0.0027 #>    150        0.0433             nan     0.1000   -0.0033 #>  #> Warning: These variables have zero variances: rural, region #> Warning: variable 7: rural has no variation. #> Warning: variable 8: region has no variation. #> Iter   TrainDeviance   ValidDeviance   StepSize   Improve #>      1        1.0986             nan     0.1000    0.2764 #>      2        0.9054             nan     0.1000    0.2128 #>      3        0.7808             nan     0.1000    0.1739 #>      4        0.6837             nan     0.1000    0.0926 #>      5        0.6142             nan     0.1000    0.0828 #>      6        0.5571             nan     0.1000    0.0496 #>      7        0.5123             nan     0.1000    0.0348 #>      8        0.4789             nan     0.1000    0.0454 #>      9        0.4431             nan     0.1000    0.0446 #>     10        0.4087             nan     0.1000    0.0277 #>     20        0.2288             nan     0.1000    0.0001 #>     40        0.1035             nan     0.1000   -0.0074 #>     60        0.0550             nan     0.1000   -0.0091 #>     80        0.0284             nan     0.1000   -0.0013 #>    100        0.0174             nan     0.1000   -0.0011 #>    120        0.0104             nan     0.1000   -0.0005 #>    140        0.0064             nan     0.1000   -0.0010 #>    150        0.0047             nan     0.1000   -0.0007 #>  #> Warning: These variables have zero variances: rural, region #> Warning: variable 7: rural has no variation. #> Warning: variable 8: region has no variation. #> Iter   TrainDeviance   ValidDeviance   StepSize   Improve #>      1        1.0986             nan     0.1000    0.2846 #>      2        0.9162             nan     0.1000    0.1631 #>      3        0.7966             nan     0.1000    0.1238 #>      4        0.6951             nan     0.1000    0.0858 #>      5        0.6296             nan     0.1000    0.0699 #>      6        0.5713             nan     0.1000    0.0638 #>      7        0.5209             nan     0.1000    0.0547 #>      8        0.4770             nan     0.1000    0.0288 #>      9        0.4412             nan     0.1000    0.0287 #>     10        0.4118             nan     0.1000    0.0118 #>     20        0.2331             nan     0.1000   -0.0052 #>     40        0.0928             nan     0.1000   -0.0105 #>     60        0.0417             nan     0.1000   -0.0008 #>     80        0.0198             nan     0.1000   -0.0037 #>    100        0.0117             nan     0.1000   -0.0022 #>    120        0.0090             nan     0.1000   -0.0015 #>    140        0.0058             nan     0.1000   -0.0020 #>    150        0.0050             nan     0.1000   -0.0019 #>  #> Warning: These variables have zero variances: rural, region #> Warning: variable 7: rural has no variation. #> Warning: variable 8: region has no variation. #> Iter   TrainDeviance   ValidDeviance   StepSize   Improve #>      1        1.3863             nan     0.1000    0.4852 #>      2        1.1024             nan     0.1000    0.3579 #>      3        0.9125             nan     0.1000    0.2388 #>      4        0.7658             nan     0.1000    0.1777 #>      5        0.6659             nan     0.1000    0.1394 #>      6        0.5906             nan     0.1000    0.1006 #>      7        0.5220             nan     0.1000    0.0702 #>      8        0.4774             nan     0.1000    0.0638 #>      9        0.4312             nan     0.1000    0.0446 #>     10        0.3979             nan     0.1000    0.0202 #>     20        0.2447             nan     0.1000   -0.0049 #>     40        0.1371             nan     0.1000   -0.0048 #>     60        0.0888             nan     0.1000   -0.0090 #>     80        0.0581             nan     0.1000   -0.0078 #>    100        0.0459             nan     0.1000   -0.0121 #>    120        0.0328             nan     0.1000   -0.0052 #>    140        0.0264             nan     0.1000   -0.0044 #>    150        0.0258             nan     0.1000   -0.0058 #>  #> Warning: These variables have zero variances: rural, region #> Warning: variable 7: rural has no variation. #> Warning: variable 8: region has no variation. #> Iter   TrainDeviance   ValidDeviance   StepSize   Improve #>      1        1.3863             nan     0.1000    0.5255 #>      2        1.0826             nan     0.1000    0.3309 #>      3        0.8870             nan     0.1000    0.2404 #>      4        0.7491             nan     0.1000    0.1751 #>      5        0.6506             nan     0.1000    0.1407 #>      6        0.5731             nan     0.1000    0.0981 #>      7        0.5074             nan     0.1000    0.0605 #>      8        0.4567             nan     0.1000    0.0544 #>      9        0.4133             nan     0.1000    0.0419 #>     10        0.3747             nan     0.1000    0.0535 #>     20        0.1850             nan     0.1000   -0.0005 #>     40        0.0735             nan     0.1000   -0.0115 #>     60        0.0359             nan     0.1000   -0.0087 #>     80        0.0192             nan     0.1000   -0.0023 #>    100        0.0082             nan     0.1000   -0.0003 #>    120        0.0057             nan     0.1000    0.0003 #>    140        0.0043             nan     0.1000   -0.0001 #>    150        0.0038             nan     0.1000   -0.0005 #>  #> Warning: These variables have zero variances: rural, region #> Warning: variable 7: rural has no variation. #> Warning: variable 8: region has no variation. #> Iter   TrainDeviance   ValidDeviance   StepSize   Improve #>      1        1.3863             nan     0.1000    0.4540 #>      2        1.1034             nan     0.1000    0.3439 #>      3        0.9028             nan     0.1000    0.2405 #>      4        0.7699             nan     0.1000    0.1507 #>      5        0.6618             nan     0.1000    0.1173 #>      6        0.5770             nan     0.1000    0.0772 #>      7        0.5198             nan     0.1000    0.0909 #>      8        0.4630             nan     0.1000    0.0555 #>      9        0.4174             nan     0.1000    0.0465 #>     10        0.3812             nan     0.1000    0.0319 #>     20        0.1855             nan     0.1000   -0.0114 #>     40        0.0578             nan     0.1000   -0.0010 #>     60        0.0238             nan     0.1000   -0.0018 #>     80        0.0091             nan     0.1000   -0.0023 #>    100        0.0062             nan     0.1000   -0.0018 #>    120        0.0031             nan     0.1000   -0.0016 #>    140        0.0031             nan     0.1000    0.0001 #>    150        0.0024             nan     0.1000   -0.0012 #>  #> Warning: These variables have zero variances: rural, region #> Warning: variable 7: rural has no variation. #> Warning: variable 8: region has no variation. #> Iter   TrainDeviance   ValidDeviance   StepSize   Improve #>      1        1.0986             nan     0.1000    0.2588 #>      2        0.9273             nan     0.1000    0.1844 #>      3        0.8104             nan     0.1000    0.1126 #>      4        0.7376             nan     0.1000    0.1076 #>      5        0.6714             nan     0.1000    0.0762 #>      6        0.6233             nan     0.1000    0.0613 #>      7        0.5783             nan     0.1000    0.0337 #>      8        0.5451             nan     0.1000    0.0305 #>      9        0.5148             nan     0.1000    0.0243 #>     10        0.4929             nan     0.1000    0.0128 #>     20        0.3411             nan     0.1000    0.0003 #>     40        0.2150             nan     0.1000    0.0007 #>     60        0.1568             nan     0.1000   -0.0209 #>     80        0.1172             nan     0.1000   -0.0037 #>    100        0.0849             nan     0.1000   -0.0040 #>    120        0.0675             nan     0.1000   -0.0067 #>    140        0.0509             nan     0.1000   -0.0022 #>    150        0.0437             nan     0.1000   -0.0025 #>  #> Warning: These variables have zero variances: rural, region #> Warning: variable 7: rural has no variation. #> Warning: variable 8: region has no variation. #> Iter   TrainDeviance   ValidDeviance   StepSize   Improve #>      1        1.0986             nan     0.1000    0.3212 #>      2        0.9206             nan     0.1000    0.1828 #>      3        0.7993             nan     0.1000    0.1124 #>      4        0.7199             nan     0.1000    0.1270 #>      5        0.6404             nan     0.1000    0.0654 #>      6        0.5892             nan     0.1000    0.0495 #>      7        0.5447             nan     0.1000    0.0484 #>      8        0.5045             nan     0.1000    0.0580 #>      9        0.4597             nan     0.1000    0.0320 #>     10        0.4277             nan     0.1000    0.0168 #>     20        0.2475             nan     0.1000   -0.0093 #>     40        0.1179             nan     0.1000   -0.0008 #>     60        0.0602             nan     0.1000   -0.0018 #>     80        0.0317             nan     0.1000   -0.0012 #>    100        0.0190             nan     0.1000   -0.0008 #>    120        0.0092             nan     0.1000   -0.0006 #>    140        0.0059             nan     0.1000   -0.0003 #>    150        0.0050             nan     0.1000   -0.0002 #>  #> Warning: These variables have zero variances: rural, region #> Warning: variable 7: rural has no variation. #> Warning: variable 8: region has no variation. #> Iter   TrainDeviance   ValidDeviance   StepSize   Improve #>      1        1.0986             nan     0.1000    0.2465 #>      2        0.9304             nan     0.1000    0.1713 #>      3        0.8153             nan     0.1000    0.1160 #>      4        0.7297             nan     0.1000    0.0823 #>      5        0.6580             nan     0.1000    0.0728 #>      6        0.5981             nan     0.1000    0.0569 #>      7        0.5504             nan     0.1000    0.0314 #>      8        0.5186             nan     0.1000    0.0249 #>      9        0.4845             nan     0.1000    0.0419 #>     10        0.4498             nan     0.1000    0.0560 #>     20        0.2746             nan     0.1000    0.0106 #>     40        0.1060             nan     0.1000   -0.0031 #>     60        0.0466             nan     0.1000   -0.0020 #>     80        0.0259             nan     0.1000   -0.0036 #>    100        0.0116             nan     0.1000   -0.0012 #>    120        0.0102             nan     0.1000   -0.0004 #>    140        0.0042             nan     0.1000   -0.0011 #>    150        0.0035             nan     0.1000   -0.0008 #>  #> Warning: These variables have zero variances: rural, region #> Warning: variable 7: rural has no variation. #> Warning: variable 8: region has no variation. #> Iter   TrainDeviance   ValidDeviance   StepSize   Improve #>      1        1.3863             nan     0.1000    0.4673 #>      2        1.1128             nan     0.1000    0.2839 #>      3        0.9311             nan     0.1000    0.1955 #>      4        0.8024             nan     0.1000    0.1404 #>      5        0.7013             nan     0.1000    0.1190 #>      6        0.6236             nan     0.1000    0.1074 #>      7        0.5591             nan     0.1000    0.0758 #>      8        0.5097             nan     0.1000    0.0468 #>      9        0.4704             nan     0.1000    0.0358 #>     10        0.4372             nan     0.1000    0.0365 #>     20        0.2726             nan     0.1000    0.0063 #>     40        0.1483             nan     0.1000   -0.0013 #>     60        0.0833             nan     0.1000   -0.0049 #>     80        0.0482             nan     0.1000   -0.0004 #>    100        0.0276             nan     0.1000   -0.0018 #>    120        0.0175             nan     0.1000   -0.0011 #>    140        0.0117             nan     0.1000    0.0002 #>    150        0.0088             nan     0.1000   -0.0008 #>  #> Warning: These variables have zero variances: rural, region #> Warning: variable 7: rural has no variation. #> Warning: variable 8: region has no variation. #> Iter   TrainDeviance   ValidDeviance   StepSize   Improve #>      1        1.3863             nan     0.1000    0.4398 #>      2        1.1277             nan     0.1000    0.2992 #>      3        0.9501             nan     0.1000    0.2094 #>      4        0.8182             nan     0.1000    0.1446 #>      5        0.7177             nan     0.1000    0.1503 #>      6        0.6235             nan     0.1000    0.0776 #>      7        0.5598             nan     0.1000    0.0694 #>      8        0.5141             nan     0.1000    0.0603 #>      9        0.4719             nan     0.1000    0.0461 #>     10        0.4336             nan     0.1000    0.0675 #>     20        0.1930             nan     0.1000    0.0036 #>     40        0.0607             nan     0.1000    0.0014 #>     60        0.0265             nan     0.1000   -0.0025 #>     80        0.0134             nan     0.1000   -0.0013 #>    100        0.0069             nan     0.1000   -0.0001 #>    120        0.0033             nan     0.1000    0.0000 #>    140        0.0018             nan     0.1000   -0.0007 #>    150        0.0015             nan     0.1000   -0.0001 #>  #> Warning: These variables have zero variances: rural, region #> Warning: variable 7: rural has no variation. #> Warning: variable 8: region has no variation. #> Iter   TrainDeviance   ValidDeviance   StepSize   Improve #>      1        1.3863             nan     0.1000    0.4847 #>      2        1.1191             nan     0.1000    0.2990 #>      3        0.9401             nan     0.1000    0.2030 #>      4        0.7963             nan     0.1000    0.1478 #>      5        0.6989             nan     0.1000    0.1142 #>      6        0.6194             nan     0.1000    0.1087 #>      7        0.5518             nan     0.1000    0.0898 #>      8        0.4874             nan     0.1000    0.0444 #>      9        0.4394             nan     0.1000    0.0428 #>     10        0.4084             nan     0.1000    0.0311 #>     20        0.1872             nan     0.1000    0.0100 #>     40        0.0664             nan     0.1000    0.0013 #>     60        0.0214             nan     0.1000   -0.0048 #>     80        0.0139             nan     0.1000   -0.0030 #>    100        0.0041             nan     0.1000    0.0000 #>    120        0.0029             nan     0.1000   -0.0004 #>    140        0.0015             nan     0.1000    0.0001 #>    150        0.0009             nan     0.1000   -0.0003 #>  #> Warning: These variables have zero variances: rural, region #> Warning: variable 7: rural has no variation. #> Warning: variable 8: region has no variation. #> Iter   TrainDeviance   ValidDeviance   StepSize   Improve #>      1        1.3863             nan     0.1000    0.4100 #>      2        1.1242             nan     0.1000    0.3213 #>      3        0.9429             nan     0.1000    0.2146 #>      4        0.8194             nan     0.1000    0.1674 #>      5        0.7192             nan     0.1000    0.1170 #>      6        0.6343             nan     0.1000    0.0846 #>      7        0.5738             nan     0.1000    0.0582 #>      8        0.5211             nan     0.1000    0.0556 #>      9        0.4809             nan     0.1000    0.0383 #>     10        0.4518             nan     0.1000    0.0425 #>     20        0.2794             nan     0.1000   -0.0093 #>     40        0.1829             nan     0.1000   -0.0084 #>     60        0.1355             nan     0.1000   -0.0080 #>     80        0.1019             nan     0.1000   -0.0078 #>    100        0.0726             nan     0.1000   -0.0087 #>    120        0.0538             nan     0.1000   -0.0058 #>    140        0.0434             nan     0.1000   -0.0066 #>    150        0.0407             nan     0.1000   -0.0081 #>  #> Warning: These variables have zero variances: rural, region #> Warning: variable 7: rural has no variation. #> Warning: variable 8: region has no variation. #> Iter   TrainDeviance   ValidDeviance   StepSize   Improve #>      1        1.3863             nan     0.1000    0.4294 #>      2        1.1324             nan     0.1000    0.3185 #>      3        0.9459             nan     0.1000    0.2185 #>      4        0.8170             nan     0.1000    0.1709 #>      5        0.7106             nan     0.1000    0.1046 #>      6        0.6369             nan     0.1000    0.0872 #>      7        0.5706             nan     0.1000    0.0722 #>      8        0.5177             nan     0.1000    0.0612 #>      9        0.4778             nan     0.1000    0.0371 #>     10        0.4396             nan     0.1000    0.0340 #>     20        0.2543             nan     0.1000   -0.0084 #>     40        0.1153             nan     0.1000   -0.0169 #>     60        0.0642             nan     0.1000   -0.0129 #>     80        0.0317             nan     0.1000   -0.0025 #>    100        0.0204             nan     0.1000   -0.0052 #>    120        0.0141             nan     0.1000   -0.0020 #>    140        0.0120             nan     0.1000   -0.0030 #>    150        0.0080             nan     0.1000   -0.0026 #>  #> Warning: These variables have zero variances: rural, region #> Warning: variable 7: rural has no variation. #> Warning: variable 8: region has no variation. #> Iter   TrainDeviance   ValidDeviance   StepSize   Improve #>      1        1.3863             nan     0.1000    0.4523 #>      2        1.1328             nan     0.1000    0.3073 #>      3        0.9637             nan     0.1000    0.2197 #>      4        0.8195             nan     0.1000    0.1484 #>      5        0.7165             nan     0.1000    0.1101 #>      6        0.6345             nan     0.1000    0.0933 #>      7        0.5719             nan     0.1000    0.0586 #>      8        0.5234             nan     0.1000    0.0704 #>      9        0.4750             nan     0.1000    0.0504 #>     10        0.4341             nan     0.1000    0.0391 #>     20        0.2426             nan     0.1000    0.0051 #>     40        0.1079             nan     0.1000   -0.0082 #>     60        0.0522             nan     0.1000   -0.0099 #>     80        0.0287             nan     0.1000   -0.0007 #>    100        0.0194             nan     0.1000   -0.0019 #>    120        0.0133             nan     0.1000   -0.0024 #>    140        0.0084             nan     0.1000   -0.0004 #>    150        0.0049             nan     0.1000   -0.0009 #>  #> Warning: These variables have zero variances: rural, region #> Warning: variable 7: rural has no variation. #> Warning: variable 8: region has no variation. #> Iter   TrainDeviance   ValidDeviance   StepSize   Improve #>      1        1.3863             nan     0.1000    0.4305 #>      2        1.1434             nan     0.1000    0.2669 #>      3        0.9726             nan     0.1000    0.2062 #>      4        0.8551             nan     0.1000    0.1511 #>      5        0.7640             nan     0.1000    0.1169 #>      6        0.6788             nan     0.1000    0.1070 #>      7        0.6156             nan     0.1000    0.0799 #>      8        0.5665             nan     0.1000    0.0614 #>      9        0.5233             nan     0.1000    0.0379 #>     10        0.4931             nan     0.1000    0.0329 #>     20        0.3280             nan     0.1000    0.0025 #>     40        0.1968             nan     0.1000    0.0065 #>     60        0.1306             nan     0.1000   -0.0081 #>     80        0.0869             nan     0.1000   -0.0045 #>    100        0.0630             nan     0.1000   -0.0043 #>    120        0.0441             nan     0.1000   -0.0031 #>    140        0.0336             nan     0.1000   -0.0028 #>    150        0.0302             nan     0.1000   -0.0023 #>  #> Warning: These variables have zero variances: rural, region #> Warning: variable 7: rural has no variation. #> Warning: variable 8: region has no variation. #> Iter   TrainDeviance   ValidDeviance   StepSize   Improve #>      1        1.3863             nan     0.1000    0.4438 #>      2        1.1257             nan     0.1000    0.2761 #>      3        0.9613             nan     0.1000    0.2098 #>      4        0.8329             nan     0.1000    0.1437 #>      5        0.7320             nan     0.1000    0.1188 #>      6        0.6552             nan     0.1000    0.0886 #>      7        0.5910             nan     0.1000    0.0775 #>      8        0.5295             nan     0.1000    0.0517 #>      9        0.4820             nan     0.1000    0.0372 #>     10        0.4429             nan     0.1000    0.0355 #>     20        0.2459             nan     0.1000   -0.0048 #>     40        0.1064             nan     0.1000   -0.0209 #>     60        0.0575             nan     0.1000   -0.0010 #>     80        0.0245             nan     0.1000   -0.0032 #>    100        0.0147             nan     0.1000   -0.0020 #>    120        0.0127             nan     0.1000   -0.0027 #>    140        0.0074             nan     0.1000   -0.0020 #>    150        0.0062             nan     0.1000   -0.0015 #>  #> Warning: These variables have zero variances: rural, region #> Warning: variable 7: rural has no variation. #> Warning: variable 8: region has no variation. #> Iter   TrainDeviance   ValidDeviance   StepSize   Improve #>      1        1.3863             nan     0.1000    0.4155 #>      2        1.1545             nan     0.1000    0.2937 #>      3        0.9678             nan     0.1000    0.2260 #>      4        0.8279             nan     0.1000    0.1570 #>      5        0.7297             nan     0.1000    0.1250 #>      6        0.6454             nan     0.1000    0.0818 #>      7        0.5847             nan     0.1000    0.0512 #>      8        0.5351             nan     0.1000    0.0573 #>      9        0.4886             nan     0.1000    0.0511 #>     10        0.4469             nan     0.1000    0.0260 #>     20        0.2270             nan     0.1000    0.0009 #>     40        0.0805             nan     0.1000   -0.0080 #>     60        0.0392             nan     0.1000   -0.0006 #>     80        0.0194             nan     0.1000   -0.0033 #>    100        0.0124             nan     0.1000   -0.0030 #>    120        0.0069             nan     0.1000   -0.0015 #>    140        0.0035             nan     0.1000   -0.0007 #>    150        0.0026             nan     0.1000   -0.0003 #>  #> Warning: These variables have zero variances: rural, region #> Warning: variable 7: rural has no variation. #> Warning: variable 8: region has no variation. #> Iter   TrainDeviance   ValidDeviance   StepSize   Improve #>      1        1.3863             nan     0.1000    0.3714 #>      2        1.1552             nan     0.1000    0.2216 #>      3        1.0040             nan     0.1000    0.1861 #>      4        0.8982             nan     0.1000    0.1327 #>      5        0.8184             nan     0.1000    0.0751 #>      6        0.7569             nan     0.1000    0.0794 #>      7        0.6993             nan     0.1000    0.0583 #>      8        0.6542             nan     0.1000    0.0200 #>      9        0.6210             nan     0.1000    0.0436 #>     10        0.5826             nan     0.1000    0.0254 #>     20        0.3838             nan     0.1000    0.0088 #>     40        0.2510             nan     0.1000   -0.0173 #>     60        0.1752             nan     0.1000   -0.0143 #>     80        0.1349             nan     0.1000   -0.0132 #>    100        0.1006             nan     0.1000   -0.0065 #>    120        0.0763             nan     0.1000   -0.0103 #>    140        0.0638             nan     0.1000   -0.0050 #>    150        0.0572             nan     0.1000   -0.0071 #>  #> Warning: These variables have zero variances: rural, region #> Warning: variable 7: rural has no variation. #> Warning: variable 8: region has no variation. #> Iter   TrainDeviance   ValidDeviance   StepSize   Improve #>      1        1.3863             nan     0.1000    0.3006 #>      2        1.1889             nan     0.1000    0.2690 #>      3        1.0179             nan     0.1000    0.2417 #>      4        0.8730             nan     0.1000    0.1305 #>      5        0.7775             nan     0.1000    0.0963 #>      6        0.7100             nan     0.1000    0.0680 #>      7        0.6574             nan     0.1000    0.0682 #>      8        0.6023             nan     0.1000    0.0602 #>      9        0.5531             nan     0.1000    0.0445 #>     10        0.5128             nan     0.1000    0.0600 #>     20        0.3043             nan     0.1000    0.0034 #>     40        0.1314             nan     0.1000   -0.0025 #>     60        0.0832             nan     0.1000   -0.0072 #>     80        0.0431             nan     0.1000   -0.0046 #>    100        0.0251             nan     0.1000   -0.0020 #>    120        0.0170             nan     0.1000   -0.0036 #>    140        0.0108             nan     0.1000   -0.0017 #>    150        0.0092             nan     0.1000   -0.0007 #>  #> Warning: These variables have zero variances: rural, region #> Warning: variable 7: rural has no variation. #> Warning: variable 8: region has no variation. #> Iter   TrainDeviance   ValidDeviance   StepSize   Improve #>      1        1.3863             nan     0.1000    0.4012 #>      2        1.1602             nan     0.1000    0.3336 #>      3        0.9819             nan     0.1000    0.1895 #>      4        0.8606             nan     0.1000    0.1371 #>      5        0.7670             nan     0.1000    0.1130 #>      6        0.6775             nan     0.1000    0.0863 #>      7        0.6133             nan     0.1000    0.0734 #>      8        0.5592             nan     0.1000    0.0386 #>      9        0.5110             nan     0.1000    0.0373 #>     10        0.4719             nan     0.1000    0.0363 #>     20        0.2707             nan     0.1000   -0.0010 #>     40        0.1251             nan     0.1000   -0.0059 #>     60        0.0613             nan     0.1000   -0.0076 #>     80        0.0398             nan     0.1000   -0.0097 #>    100        0.0289             nan     0.1000   -0.0066 #>    120        0.0188             nan     0.1000   -0.0061 #>    140        0.0093             nan     0.1000   -0.0018 #>    150        0.0069             nan     0.1000   -0.0010 #>  #> Warning: These variables have zero variances: rural, region #> Warning: variable 7: rural has no variation. #> Warning: variable 8: region has no variation. #> Iter   TrainDeviance   ValidDeviance   StepSize   Improve #>      1        1.3863             nan     0.1000    0.4992 #>      2        1.1146             nan     0.1000    0.2974 #>      3        0.9142             nan     0.1000    0.2045 #>      4        0.7906             nan     0.1000    0.1336 #>      5        0.6927             nan     0.1000    0.1071 #>      6        0.6193             nan     0.1000    0.0806 #>      7        0.5643             nan     0.1000    0.0660 #>      8        0.5221             nan     0.1000    0.0490 #>      9        0.4870             nan     0.1000    0.0133 #>     10        0.4530             nan     0.1000    0.0401 #>     20        0.2894             nan     0.1000   -0.0011 #>     40        0.1693             nan     0.1000   -0.0009 #>     60        0.0991             nan     0.1000   -0.0089 #>     80        0.0633             nan     0.1000   -0.0102 #>    100        0.0410             nan     0.1000   -0.0045 #>    120        0.0313             nan     0.1000   -0.0035 #>    140        0.0214             nan     0.1000   -0.0016 #>    150        0.0190             nan     0.1000   -0.0016 #>  #> Warning: These variables have zero variances: rural, region #> Warning: variable 7: rural has no variation. #> Warning: variable 8: region has no variation. #> Iter   TrainDeviance   ValidDeviance   StepSize   Improve #>      1        1.3863             nan     0.1000    0.4301 #>      2        1.1126             nan     0.1000    0.3155 #>      3        0.9286             nan     0.1000    0.2137 #>      4        0.8028             nan     0.1000    0.1725 #>      5        0.6892             nan     0.1000    0.1150 #>      6        0.6166             nan     0.1000    0.0608 #>      7        0.5626             nan     0.1000    0.0643 #>      8        0.5121             nan     0.1000    0.0586 #>      9        0.4730             nan     0.1000    0.0383 #>     10        0.4444             nan     0.1000    0.0217 #>     20        0.2356             nan     0.1000    0.0117 #>     40        0.0804             nan     0.1000   -0.0088 #>     60        0.0324             nan     0.1000   -0.0021 #>     80        0.0151             nan     0.1000   -0.0023 #>    100        0.0092             nan     0.1000   -0.0024 #>    120        0.0069             nan     0.1000    0.0001 #>    140        0.0069             nan     0.1000   -0.0037 #>    150        0.0045             nan     0.1000   -0.0007 #>  #> Warning: These variables have zero variances: rural, region #> Warning: variable 7: rural has no variation. #> Warning: variable 8: region has no variation. #> Iter   TrainDeviance   ValidDeviance   StepSize   Improve #>      1        1.3863             nan     0.1000    0.4424 #>      2        1.1151             nan     0.1000    0.3084 #>      3        0.9248             nan     0.1000    0.2097 #>      4        0.7915             nan     0.1000    0.1434 #>      5        0.6935             nan     0.1000    0.1147 #>      6        0.6169             nan     0.1000    0.0797 #>      7        0.5570             nan     0.1000    0.0804 #>      8        0.5053             nan     0.1000    0.0647 #>      9        0.4528             nan     0.1000    0.0654 #>     10        0.4111             nan     0.1000    0.0265 #>     20        0.2094             nan     0.1000    0.0163 #>     40        0.0764             nan     0.1000   -0.0128 #>     60        0.0281             nan     0.1000   -0.0046 #>     80        0.0120             nan     0.1000   -0.0001 #>    100        0.0048             nan     0.1000   -0.0004 #>    120        0.0036             nan     0.1000   -0.0018 #>    140        0.0039             nan     0.1000   -0.0018 #>    150        0.0052             nan     0.1000   -0.0000 #>  #> Warning: These variables have zero variances: rural, region #> Warning: variable 7: rural has no variation. #> Warning: variable 8: region has no variation. #> Iter   TrainDeviance   ValidDeviance   StepSize   Improve #>      1        1.3863             nan     0.1000    0.4819 #>      2        1.1078             nan     0.1000    0.3455 #>      3        0.8826             nan     0.1000    0.2405 #>      4        0.7378             nan     0.1000    0.1972 #>      5        0.6313             nan     0.1000    0.1283 #>      6        0.5501             nan     0.1000    0.0958 #>      7        0.4879             nan     0.1000    0.0767 #>      8        0.4304             nan     0.1000    0.0428 #>      9        0.3897             nan     0.1000    0.0545 #>     10        0.3515             nan     0.1000    0.0287 #>     20        0.1831             nan     0.1000    0.0003 #>     40        0.0814             nan     0.1000   -0.0041 #>     60        0.0374             nan     0.1000   -0.0018 #>     80        0.0180             nan     0.1000   -0.0004 #>    100        0.0099             nan     0.1000   -0.0014 #>    120        0.0064             nan     0.1000   -0.0004 #>    140        0.0040             nan     0.1000   -0.0002 #>    150        0.0039             nan     0.1000   -0.0001 #>  #> Warning: These variables have zero variances: rural, region #> Warning: variable 7: rural has no variation. #> Warning: variable 8: region has no variation. #> Iter   TrainDeviance   ValidDeviance   StepSize   Improve #>      1        1.3863             nan     0.1000    0.5045 #>      2        1.0942             nan     0.1000    0.3449 #>      3        0.8900             nan     0.1000    0.2447 #>      4        0.7432             nan     0.1000    0.1975 #>      5        0.6320             nan     0.1000    0.1425 #>      6        0.5443             nan     0.1000    0.0834 #>      7        0.4774             nan     0.1000    0.0801 #>      8        0.4272             nan     0.1000    0.0319 #>      9        0.3892             nan     0.1000    0.0506 #>     10        0.3546             nan     0.1000    0.0476 #>     20        0.1534             nan     0.1000    0.0134 #>     40        0.0386             nan     0.1000   -0.0009 #>     60        0.0104             nan     0.1000   -0.0014 #>     80        0.0066             nan     0.1000   -0.0012 #>    100        0.0020             nan     0.1000   -0.0002 #>    120        0.0008             nan     0.1000   -0.0002 #>    140        0.0005             nan     0.1000   -0.0001 #>    150        0.0003             nan     0.1000   -0.0000 #>  #> Warning: These variables have zero variances: rural, region #> Warning: variable 7: rural has no variation. #> Warning: variable 8: region has no variation. #> Iter   TrainDeviance   ValidDeviance   StepSize   Improve #>      1        1.3863             nan     0.1000    0.5023 #>      2        1.1096             nan     0.1000    0.2000 #>      3        0.9526             nan     0.1000    0.2847 #>      4        0.7922             nan     0.1000    0.2078 #>      5        0.6706             nan     0.1000    0.1490 #>      6        0.5745             nan     0.1000    0.1199 #>      7        0.4969             nan     0.1000    0.0768 #>      8        0.4383             nan     0.1000    0.0848 #>      9        0.3883             nan     0.1000    0.0698 #>     10        0.3435             nan     0.1000    0.0301 #>     20        0.1492             nan     0.1000    0.0164 #>     40        0.0294             nan     0.1000   -0.0021 #>     60        0.0088             nan     0.1000   -0.0020 #>     80        0.0037             nan     0.1000   -0.0002 #>    100        0.0016             nan     0.1000   -0.0004 #>    120        0.0010             nan     0.1000   -0.0004 #>    140        0.0009             nan     0.1000    0.0001 #>    150        0.0008             nan     0.1000   -0.0004 #>  #> Warning: These variables have zero variances: rural, region #> Warning: variable 7: rural has no variation. #> Warning: variable 8: region has no variation. #> Iter   TrainDeviance   ValidDeviance   StepSize   Improve #>      1        1.3863             nan     0.1000    0.4570 #>      2        1.1323             nan     0.1000    0.3092 #>      3        0.9553             nan     0.1000    0.2034 #>      4        0.8317             nan     0.1000    0.1544 #>      5        0.7380             nan     0.1000    0.1083 #>      6        0.6717             nan     0.1000    0.0905 #>      7        0.6121             nan     0.1000    0.0705 #>      8        0.5612             nan     0.1000    0.0610 #>      9        0.5169             nan     0.1000    0.0368 #>     10        0.4883             nan     0.1000    0.0351 #>     20        0.3329             nan     0.1000    0.0109 #>     40        0.2022             nan     0.1000   -0.0154 #>     60        0.1438             nan     0.1000   -0.0062 #>     80        0.1064             nan     0.1000   -0.0024 #>    100        0.0742             nan     0.1000   -0.0059 #>    120        0.0554             nan     0.1000   -0.0022 #>    140        0.0417             nan     0.1000   -0.0021 #>    150        0.0375             nan     0.1000   -0.0067 #>  #> Warning: These variables have zero variances: rural, region #> Warning: variable 7: rural has no variation. #> Warning: variable 8: region has no variation. #> Iter   TrainDeviance   ValidDeviance   StepSize   Improve #>      1        1.3863             nan     0.1000    0.3585 #>      2        1.1496             nan     0.1000    0.2671 #>      3        0.9674             nan     0.1000    0.1751 #>      4        0.8467             nan     0.1000    0.1449 #>      5        0.7467             nan     0.1000    0.1188 #>      6        0.6655             nan     0.1000    0.0802 #>      7        0.6119             nan     0.1000    0.0703 #>      8        0.5539             nan     0.1000    0.0668 #>      9        0.5086             nan     0.1000    0.0419 #>     10        0.4743             nan     0.1000    0.0464 #>     20        0.2566             nan     0.1000    0.0025 #>     40        0.1038             nan     0.1000   -0.0074 #>     60        0.0471             nan     0.1000   -0.0055 #>     80        0.0261             nan     0.1000   -0.0049 #>    100        0.0163             nan     0.1000   -0.0039 #>    120        0.0126             nan     0.1000   -0.0023 #>    140        0.0084             nan     0.1000   -0.0030 #>    150        0.0092             nan     0.1000   -0.0044 #>  #> Warning: These variables have zero variances: rural, region #> Warning: variable 7: rural has no variation. #> Warning: variable 8: region has no variation. #> Iter   TrainDeviance   ValidDeviance   StepSize   Improve #>      1        1.3863             nan     0.1000    0.4123 #>      2        1.1346             nan     0.1000    0.2913 #>      3        0.9513             nan     0.1000    0.1939 #>      4        0.8273             nan     0.1000    0.1408 #>      5        0.7343             nan     0.1000    0.1415 #>      6        0.6400             nan     0.1000    0.0852 #>      7        0.5796             nan     0.1000    0.0738 #>      8        0.5300             nan     0.1000    0.0457 #>      9        0.4912             nan     0.1000    0.0435 #>     10        0.4550             nan     0.1000    0.0423 #>     20        0.2497             nan     0.1000   -0.0244 #>     40        0.0796             nan     0.1000   -0.0030 #>     60        0.0416             nan     0.1000   -0.0054 #>     80        0.0210             nan     0.1000   -0.0032 #>    100        0.0113             nan     0.1000   -0.0012 #>    120        0.0076             nan     0.1000    0.0003 #>    140        0.0047             nan     0.1000   -0.0002 #>    150        0.0039             nan     0.1000   -0.0021 #>  #> Warning: These variables have zero variances: rural, region #> Warning: variable 7: rural has no variation. #> Warning: variable 8: region has no variation. #> Iter   TrainDeviance   ValidDeviance   StepSize   Improve #>      1        1.0986             nan     0.1000    0.2712 #>      2        0.9037             nan     0.1000    0.2182 #>      3        0.7685             nan     0.1000    0.1593 #>      4        0.6636             nan     0.1000    0.1137 #>      5        0.5940             nan     0.1000    0.0854 #>      6        0.5317             nan     0.1000    0.0681 #>      7        0.4894             nan     0.1000    0.0477 #>      8        0.4495             nan     0.1000    0.0129 #>      9        0.4277             nan     0.1000    0.0394 #>     10        0.4036             nan     0.1000    0.0166 #>     20        0.2905             nan     0.1000   -0.0061 #>     40        0.1931             nan     0.1000   -0.0103 #>     60        0.1430             nan     0.1000   -0.0255 #>     80        0.1126             nan     0.1000   -0.0064 #>    100        0.0870             nan     0.1000   -0.0214 #>    120        0.0624             nan     0.1000   -0.0108 #>    140        0.0459             nan     0.1000   -0.0026 #>    150        0.0412             nan     0.1000   -0.0057 #>  #> Warning: These variables have zero variances: rural, region #> Warning: variable 7: rural has no variation. #> Warning: variable 8: region has no variation. #> Iter   TrainDeviance   ValidDeviance   StepSize   Improve #>      1        1.0986             nan     0.1000    0.3366 #>      2        0.9065             nan     0.1000    0.2130 #>      3        0.7753             nan     0.1000    0.1608 #>      4        0.6736             nan     0.1000    0.1129 #>      5        0.5991             nan     0.1000    0.0807 #>      6        0.5330             nan     0.1000    0.0577 #>      7        0.4864             nan     0.1000    0.0527 #>      8        0.4495             nan     0.1000    0.0347 #>      9        0.4156             nan     0.1000    0.0432 #>     10        0.3833             nan     0.1000    0.0370 #>     20        0.2204             nan     0.1000    0.0097 #>     40        0.1007             nan     0.1000   -0.0007 #>     60        0.0557             nan     0.1000   -0.0089 #>     80        0.0297             nan     0.1000   -0.0028 #>    100        0.0180             nan     0.1000   -0.0005 #>    120        0.0131             nan     0.1000   -0.0006 #>    140        0.0099             nan     0.1000   -0.0016 #>    150        0.0070             nan     0.1000   -0.0008 #>  #> Warning: These variables have zero variances: rural, region #> Warning: variable 7: rural has no variation. #> Warning: variable 8: region has no variation. #> Iter   TrainDeviance   ValidDeviance   StepSize   Improve #>      1        1.0986             nan     0.1000    0.3048 #>      2        0.8967             nan     0.1000    0.2167 #>      3        0.7657             nan     0.1000    0.1683 #>      4        0.6662             nan     0.1000    0.1059 #>      5        0.5944             nan     0.1000    0.0938 #>      6        0.5318             nan     0.1000    0.0727 #>      7        0.4818             nan     0.1000    0.0235 #>      8        0.4429             nan     0.1000    0.0435 #>      9        0.4105             nan     0.1000    0.0107 #>     10        0.3837             nan     0.1000    0.0267 #>     20        0.2215             nan     0.1000   -0.0071 #>     40        0.1068             nan     0.1000   -0.0067 #>     60        0.0382             nan     0.1000   -0.0012 #>     80        0.0204             nan     0.1000   -0.0043 #>    100        0.0134             nan     0.1000   -0.0013 #>    120        0.0070             nan     0.1000   -0.0009 #>    140        0.0045             nan     0.1000   -0.0005 #>    150        0.0042             nan     0.1000   -0.0005 #>  #> Warning: These variables have zero variances: rural, region #> Warning: variable 7: rural has no variation. #> Warning: variable 8: region has no variation. #> Iter   TrainDeviance   ValidDeviance   StepSize   Improve #>      1        1.3863             nan     0.1000    0.4964 #>      2        1.1201             nan     0.1000    0.2581 #>      3        0.9616             nan     0.1000    0.1650 #>      4        0.8490             nan     0.1000    0.1807 #>      5        0.7492             nan     0.1000    0.1303 #>      6        0.6670             nan     0.1000    0.0723 #>      7        0.6131             nan     0.1000    0.0769 #>      8        0.5635             nan     0.1000    0.0474 #>      9        0.5246             nan     0.1000    0.0280 #>     10        0.4945             nan     0.1000    0.0374 #>     20        0.3268             nan     0.1000    0.0061 #>     40        0.2023             nan     0.1000   -0.0109 #>     60        0.1381             nan     0.1000   -0.0213 #>     80        0.1035             nan     0.1000   -0.0028 #>    100        0.0823             nan     0.1000   -0.0141 #>    120        0.0591             nan     0.1000   -0.0103 #>    140        0.0428             nan     0.1000   -0.0027 #>    150        0.0419             nan     0.1000   -0.0031 #>  #> Warning: These variables have zero variances: rural, region #> Warning: variable 7: rural has no variation. #> Warning: variable 8: region has no variation. #> Iter   TrainDeviance   ValidDeviance   StepSize   Improve #>      1        1.3863             nan     0.1000    0.3984 #>      2        1.1596             nan     0.1000    0.2899 #>      3        0.9829             nan     0.1000    0.2165 #>      4        0.8415             nan     0.1000    0.1548 #>      5        0.7396             nan     0.1000    0.0968 #>      6        0.6686             nan     0.1000    0.0768 #>      7        0.6070             nan     0.1000    0.0658 #>      8        0.5606             nan     0.1000    0.0479 #>      9        0.5222             nan     0.1000    0.0422 #>     10        0.4880             nan     0.1000    0.0285 #>     20        0.2708             nan     0.1000   -0.0061 #>     40        0.1184             nan     0.1000   -0.0017 #>     60        0.0559             nan     0.1000   -0.0048 #>     80        0.0341             nan     0.1000   -0.0041 #>    100        0.0180             nan     0.1000    0.0001 #>    120        0.0085             nan     0.1000   -0.0007 #>    140        0.0051             nan     0.1000   -0.0008 #>    150        0.0043             nan     0.1000   -0.0013 #>  #> Warning: These variables have zero variances: rural, region #> Warning: variable 7: rural has no variation. #> Warning: variable 8: region has no variation. #> Iter   TrainDeviance   ValidDeviance   StepSize   Improve #>      1        1.3863             nan     0.1000    0.4395 #>      2        1.1133             nan     0.1000    0.2815 #>      3        0.9535             nan     0.1000    0.2100 #>      4        0.8258             nan     0.1000    0.1517 #>      5        0.7316             nan     0.1000    0.0993 #>      6        0.6543             nan     0.1000    0.0855 #>      7        0.5944             nan     0.1000    0.0542 #>      8        0.5501             nan     0.1000    0.0432 #>      9        0.5078             nan     0.1000    0.0703 #>     10        0.4635             nan     0.1000    0.0388 #>     20        0.2589             nan     0.1000   -0.0056 #>     40        0.1047             nan     0.1000   -0.0039 #>     60        0.0452             nan     0.1000   -0.0015 #>     80        0.0236             nan     0.1000   -0.0051 #>    100        0.0113             nan     0.1000   -0.0041 #>    120        0.0076             nan     0.1000   -0.0019 #>    140        0.0076             nan     0.1000   -0.0006 #>    150        0.0050             nan     0.1000   -0.0011 #>  #> Warning: These variables have zero variances: rural, region #> Warning: variable 7: rural has no variation. #> Warning: variable 8: region has no variation. #> Iter   TrainDeviance   ValidDeviance   StepSize   Improve #>      1        1.3863             nan     0.1000    0.5291 #>      2        1.0958             nan     0.1000    0.3347 #>      3        0.9028             nan     0.1000    0.2454 #>      4        0.7651             nan     0.1000    0.1769 #>      5        0.6645             nan     0.1000    0.1269 #>      6        0.5813             nan     0.1000    0.0741 #>      7        0.5277             nan     0.1000    0.0543 #>      8        0.4817             nan     0.1000    0.0614 #>      9        0.4440             nan     0.1000    0.0336 #>     10        0.4097             nan     0.1000    0.0332 #>     20        0.2583             nan     0.1000   -0.0109 #>     40        0.1363             nan     0.1000   -0.0139 #>     60        0.0920             nan     0.1000   -0.0157 #>     80        0.0695             nan     0.1000   -0.0169 #>    100        0.0431             nan     0.1000   -0.0031 #>    120        0.0372             nan     0.1000   -0.0053 #>    140        0.0301             nan     0.1000   -0.0011 #>    150        0.0281             nan     0.1000   -0.0063 #>  #> Warning: These variables have zero variances: rural, region #> Warning: variable 7: rural has no variation. #> Warning: variable 8: region has no variation. #> Iter   TrainDeviance   ValidDeviance   StepSize   Improve #>      1        1.3863             nan     0.1000    0.4964 #>      2        1.0992             nan     0.1000    0.3350 #>      3        0.9044             nan     0.1000    0.2364 #>      4        0.7696             nan     0.1000    0.1752 #>      5        0.6673             nan     0.1000    0.1276 #>      6        0.5826             nan     0.1000    0.0924 #>      7        0.5187             nan     0.1000    0.0758 #>      8        0.4651             nan     0.1000    0.0492 #>      9        0.4232             nan     0.1000    0.0521 #>     10        0.3823             nan     0.1000    0.0282 #>     20        0.1879             nan     0.1000   -0.0101 #>     40        0.0776             nan     0.1000   -0.0040 #>     60        0.0377             nan     0.1000   -0.0058 #>     80        0.0244             nan     0.1000   -0.0034 #>    100        0.0130             nan     0.1000   -0.0021 #>    120        0.0076             nan     0.1000   -0.0012 #>    140        0.0060             nan     0.1000   -0.0004 #>    150        0.0050             nan     0.1000   -0.0016 #>  #> Warning: These variables have zero variances: rural, region #> Warning: variable 7: rural has no variation. #> Warning: variable 8: region has no variation. #> Iter   TrainDeviance   ValidDeviance   StepSize   Improve #>      1        1.3863             nan     0.1000    0.5144 #>      2        1.0880             nan     0.1000    0.3390 #>      3        0.8927             nan     0.1000    0.2392 #>      4        0.7507             nan     0.1000    0.1676 #>      5        0.6454             nan     0.1000    0.1216 #>      6        0.5682             nan     0.1000    0.0680 #>      7        0.5083             nan     0.1000    0.0746 #>      8        0.4527             nan     0.1000    0.0507 #>      9        0.4110             nan     0.1000    0.0500 #>     10        0.3748             nan     0.1000    0.0393 #>     20        0.1989             nan     0.1000   -0.0014 #>     40        0.0815             nan     0.1000   -0.0111 #>     60        0.0448             nan     0.1000   -0.0070 #>     80        0.0271             nan     0.1000   -0.0043 #>    100        0.0193             nan     0.1000   -0.0077 #>    120        0.0141             nan     0.1000   -0.0032 #>    140        0.0074             nan     0.1000   -0.0012 #>    150        0.0055             nan     0.1000   -0.0010 #>  #> Warning: These variables have zero variances: rural, region #> Warning: variable 7: rural has no variation. #> Warning: variable 8: region has no variation. #> Iter   TrainDeviance   ValidDeviance   StepSize   Improve #>      1        1.3863             nan     0.1000    0.3297 #>      2        1.1724             nan     0.1000    0.2228 #>      3        1.0064             nan     0.1000    0.1756 #>      4        0.9065             nan     0.1000    0.1467 #>      5        0.8265             nan     0.1000    0.1147 #>      6        0.7623             nan     0.1000    0.0826 #>      7        0.7123             nan     0.1000    0.0401 #>      8        0.6692             nan     0.1000    0.0516 #>      9        0.6293             nan     0.1000    0.0357 #>     10        0.5925             nan     0.1000    0.0268 #>     20        0.4184             nan     0.1000   -0.0104 #>     40        0.2731             nan     0.1000   -0.0179 #>     60        0.1933             nan     0.1000   -0.0028 #>     80        0.1425             nan     0.1000   -0.0205 #>    100        0.1098             nan     0.1000   -0.0049 #>    120        0.0843             nan     0.1000   -0.0051 #>    140        0.0664             nan     0.1000   -0.0024 #>    150        0.0584             nan     0.1000   -0.0024 #>  #> Warning: These variables have zero variances: rural, region #> Warning: variable 7: rural has no variation. #> Warning: variable 8: region has no variation. #> Iter   TrainDeviance   ValidDeviance   StepSize   Improve #>      1        1.3863             nan     0.1000    0.3054 #>      2        1.1697             nan     0.1000    0.2909 #>      3        1.0095             nan     0.1000    0.2062 #>      4        0.8783             nan     0.1000    0.1462 #>      5        0.7928             nan     0.1000    0.1409 #>      6        0.7104             nan     0.1000    0.1051 #>      7        0.6464             nan     0.1000    0.0523 #>      8        0.5994             nan     0.1000    0.0177 #>      9        0.5575             nan     0.1000    0.0378 #>     10        0.5186             nan     0.1000    0.0295 #>     20        0.3086             nan     0.1000   -0.0085 #>     40        0.1667             nan     0.1000   -0.0128 #>     60        0.0899             nan     0.1000   -0.0102 #>     80        0.0524             nan     0.1000   -0.0084 #>    100        0.0361             nan     0.1000   -0.0031 #>    120        0.0202             nan     0.1000   -0.0006 #>    140        0.0125             nan     0.1000   -0.0009 #>    150        0.0106             nan     0.1000   -0.0016 #>  #> Warning: These variables have zero variances: rural, region #> Warning: variable 7: rural has no variation. #> Warning: variable 8: region has no variation. #> Iter   TrainDeviance   ValidDeviance   StepSize   Improve #>      1        1.3863             nan     0.1000    0.4220 #>      2        1.1451             nan     0.1000    0.2448 #>      3        0.9794             nan     0.1000    0.1838 #>      4        0.8687             nan     0.1000    0.1282 #>      5        0.7847             nan     0.1000    0.1126 #>      6        0.7044             nan     0.1000    0.0993 #>      7        0.6420             nan     0.1000    0.0447 #>      8        0.5927             nan     0.1000    0.0650 #>      9        0.5445             nan     0.1000    0.0375 #>     10        0.5045             nan     0.1000    0.0556 #>     20        0.2804             nan     0.1000    0.0090 #>     40        0.1150             nan     0.1000   -0.0080 #>     60        0.0540             nan     0.1000   -0.0013 #>     80        0.0270             nan     0.1000    0.0005 #>    100        0.0148             nan     0.1000   -0.0021 #>    120        0.0108             nan     0.1000   -0.0011 #>    140        0.0070             nan     0.1000   -0.0001 #>    150        0.0056             nan     0.1000   -0.0014 #>  #> Warning: These variables have zero variances: rural, region #> Warning: variable 7: rural has no variation. #> Warning: variable 8: region has no variation. #> Iter   TrainDeviance   ValidDeviance   StepSize   Improve #>      1        1.3863             nan     0.1000    0.4813 #>      2        1.1302             nan     0.1000    0.3256 #>      3        0.9527             nan     0.1000    0.2304 #>      4        0.8153             nan     0.1000    0.1709 #>      5        0.7235             nan     0.1000    0.1129 #>      6        0.6520             nan     0.1000    0.0897 #>      7        0.5978             nan     0.1000    0.0752 #>      8        0.5497             nan     0.1000    0.0565 #>      9        0.5089             nan     0.1000    0.0196 #>     10        0.4753             nan     0.1000    0.0354 #>     20        0.3170             nan     0.1000   -0.0055 #>     40        0.2042             nan     0.1000   -0.0102 #>     60        0.1469             nan     0.1000   -0.0084 #>     80        0.1088             nan     0.1000   -0.0123 #>    100        0.0843             nan     0.1000   -0.0054 #>    120        0.0667             nan     0.1000   -0.0071 #>    140        0.0534             nan     0.1000   -0.0054 #>    150        0.0457             nan     0.1000   -0.0052 #>  #> Warning: These variables have zero variances: rural, region #> Warning: variable 7: rural has no variation. #> Warning: variable 8: region has no variation. #> Iter   TrainDeviance   ValidDeviance   StepSize   Improve #>      1        1.3863             nan     0.1000    0.4502 #>      2        1.1187             nan     0.1000    0.3049 #>      3        0.9351             nan     0.1000    0.2065 #>      4        0.8115             nan     0.1000    0.1450 #>      5        0.7245             nan     0.1000    0.0995 #>      6        0.6484             nan     0.1000    0.1027 #>      7        0.5854             nan     0.1000    0.0806 #>      8        0.5331             nan     0.1000    0.0529 #>      9        0.4906             nan     0.1000    0.0349 #>     10        0.4596             nan     0.1000    0.0216 #>     20        0.2697             nan     0.1000   -0.0031 #>     40        0.1310             nan     0.1000   -0.0108 #>     60        0.0750             nan     0.1000   -0.0078 #>     80        0.0473             nan     0.1000   -0.0035 #>    100        0.0325             nan     0.1000   -0.0030 #>    120        0.0245             nan     0.1000   -0.0082 #>    140        0.0181             nan     0.1000   -0.0024 #>    150        0.0124             nan     0.1000   -0.0004 #>  #> Warning: These variables have zero variances: rural, region #> Warning: variable 7: rural has no variation. #> Warning: variable 8: region has no variation. #> Iter   TrainDeviance   ValidDeviance   StepSize   Improve #>      1        1.3863             nan     0.1000    0.4674 #>      2        1.1267             nan     0.1000    0.2835 #>      3        0.9469             nan     0.1000    0.2164 #>      4        0.8166             nan     0.1000    0.1284 #>      5        0.7139             nan     0.1000    0.1183 #>      6        0.6389             nan     0.1000    0.0708 #>      7        0.5874             nan     0.1000    0.0683 #>      8        0.5418             nan     0.1000    0.0491 #>      9        0.5034             nan     0.1000    0.0260 #>     10        0.4677             nan     0.1000    0.0328 #>     20        0.2445             nan     0.1000   -0.0066 #>     40        0.1254             nan     0.1000   -0.0121 #>     60        0.0549             nan     0.1000   -0.0050 #>     80        0.0304             nan     0.1000   -0.0043 #>    100        0.0228             nan     0.1000   -0.0013 #>    120        0.0158             nan     0.1000   -0.0031 #>    140        0.0124             nan     0.1000   -0.0023 #>    150        0.0105             nan     0.1000   -0.0037 #>  #> Warning: These variables have zero variances: rural, region #> Warning: variable 7: rural has no variation. #> Warning: variable 8: region has no variation. #> Iter   TrainDeviance   ValidDeviance   StepSize   Improve #>      1        1.3863             nan     0.1000    0.3597 #>      2        1.1406             nan     0.1000    0.2623 #>      3        0.9820             nan     0.1000    0.1941 #>      4        0.8588             nan     0.1000    0.1360 #>      5        0.7706             nan     0.1000    0.1069 #>      6        0.7092             nan     0.1000    0.0861 #>      7        0.6482             nan     0.1000    0.0613 #>      8        0.6018             nan     0.1000    0.0434 #>      9        0.5662             nan     0.1000    0.0370 #>     10        0.5342             nan     0.1000    0.0367 #>     20        0.3619             nan     0.1000   -0.0071 #>     40        0.2192             nan     0.1000   -0.0138 #>     60        0.1396             nan     0.1000   -0.0017 #>     80        0.0961             nan     0.1000   -0.0040 #>    100        0.0652             nan     0.1000   -0.0017 #>    120        0.0526             nan     0.1000   -0.0076 #>    140        0.0343             nan     0.1000   -0.0005 #>    150        0.0297             nan     0.1000   -0.0003 #>  #> Warning: These variables have zero variances: rural, region #> Warning: variable 7: rural has no variation. #> Warning: variable 8: region has no variation. #> Iter   TrainDeviance   ValidDeviance   StepSize   Improve #>      1        1.3863             nan     0.1000    0.4302 #>      2        1.1307             nan     0.1000    0.2441 #>      3        0.9692             nan     0.1000    0.1842 #>      4        0.8486             nan     0.1000    0.1344 #>      5        0.7639             nan     0.1000    0.1309 #>      6        0.6921             nan     0.1000    0.1018 #>      7        0.6275             nan     0.1000    0.0824 #>      8        0.5772             nan     0.1000    0.0430 #>      9        0.5368             nan     0.1000    0.0504 #>     10        0.4922             nan     0.1000    0.0016 #>     20        0.2776             nan     0.1000   -0.0000 #>     40        0.1133             nan     0.1000   -0.0071 #>     60        0.0532             nan     0.1000   -0.0006 #>     80        0.0245             nan     0.1000   -0.0012 #>    100        0.0114             nan     0.1000   -0.0001 #>    120        0.0059             nan     0.1000   -0.0010 #>    140        0.0036             nan     0.1000   -0.0003 #>    150        0.0028             nan     0.1000   -0.0001 #>  #> Warning: These variables have zero variances: rural, region #> Warning: variable 7: rural has no variation. #> Warning: variable 8: region has no variation. #> Iter   TrainDeviance   ValidDeviance   StepSize   Improve #>      1        1.3863             nan     0.1000    0.3760 #>      2        1.1461             nan     0.1000    0.2610 #>      3        0.9817             nan     0.1000    0.2138 #>      4        0.8499             nan     0.1000    0.1479 #>      5        0.7513             nan     0.1000    0.0958 #>      6        0.6780             nan     0.1000    0.0821 #>      7        0.6103             nan     0.1000    0.0783 #>      8        0.5589             nan     0.1000    0.0455 #>      9        0.5189             nan     0.1000    0.0547 #>     10        0.4749             nan     0.1000    0.0298 #>     20        0.2643             nan     0.1000    0.0076 #>     40        0.0887             nan     0.1000    0.0003 #>     60        0.0366             nan     0.1000   -0.0014 #>     80        0.0148             nan     0.1000   -0.0003 #>    100        0.0075             nan     0.1000   -0.0003 #>    120        0.0041             nan     0.1000   -0.0005 #>    140        0.0018             nan     0.1000   -0.0001 #>    150        0.0011             nan     0.1000   -0.0003 #>  #> Warning: These variables have zero variances: rural, region #> Warning: variable 7: rural has no variation. #> Warning: variable 8: region has no variation. #> Iter   TrainDeviance   ValidDeviance   StepSize   Improve #>      1        1.0986             nan     0.1000    0.3443 #>      2        0.8710             nan     0.1000    0.2279 #>      3        0.7179             nan     0.1000    0.1905 #>      4        0.6005             nan     0.1000    0.1300 #>      5        0.5105             nan     0.1000    0.0801 #>      6        0.4483             nan     0.1000    0.0850 #>      7        0.3935             nan     0.1000    0.0513 #>      8        0.3525             nan     0.1000    0.0336 #>      9        0.3198             nan     0.1000    0.0380 #>     10        0.2921             nan     0.1000    0.0216 #>     20        0.1553             nan     0.1000   -0.0055 #>     40        0.0655             nan     0.1000   -0.0007 #>     60        0.0327             nan     0.1000   -0.0011 #>     80        0.0174             nan     0.1000   -0.0011 #>    100        0.0092             nan     0.1000   -0.0005 #>    120        0.0056             nan     0.1000   -0.0008 #>    140        0.0035             nan     0.1000   -0.0004 #>    150        0.0026             nan     0.1000   -0.0002 #>  #> Warning: These variables have zero variances: rural, region #> Warning: variable 7: rural has no variation. #> Warning: variable 8: region has no variation. #> Iter   TrainDeviance   ValidDeviance   StepSize   Improve #>      1        1.0986             nan     0.1000    0.3816 #>      2        0.8682             nan     0.1000    0.2624 #>      3        0.7153             nan     0.1000    0.1312 #>      4        0.6098             nan     0.1000    0.1300 #>      5        0.5238             nan     0.1000    0.1192 #>      6        0.4466             nan     0.1000    0.0753 #>      7        0.3924             nan     0.1000    0.0606 #>      8        0.3497             nan     0.1000    0.0488 #>      9        0.3132             nan     0.1000    0.0372 #>     10        0.2837             nan     0.1000    0.0220 #>     20        0.1339             nan     0.1000   -0.0107 #>     40        0.0345             nan     0.1000   -0.0043 #>     60        0.0128             nan     0.1000   -0.0029 #>     80        0.0066             nan     0.1000   -0.0005 #>    100        0.0036             nan     0.1000   -0.0013 #>    120        0.0021             nan     0.1000   -0.0006 #>    140        0.0009             nan     0.1000   -0.0001 #>    150        0.0006             nan     0.1000   -0.0001 #>  #> Warning: These variables have zero variances: rural, region #> Warning: variable 7: rural has no variation. #> Warning: variable 8: region has no variation. #> Iter   TrainDeviance   ValidDeviance   StepSize   Improve #>      1        1.0986             nan     0.1000    0.3359 #>      2        0.8726             nan     0.1000    0.2663 #>      3        0.7223             nan     0.1000    0.1832 #>      4        0.6031             nan     0.1000    0.1060 #>      5        0.5190             nan     0.1000    0.1192 #>      6        0.4501             nan     0.1000    0.0865 #>      7        0.3884             nan     0.1000    0.0395 #>      8        0.3475             nan     0.1000    0.0455 #>      9        0.3081             nan     0.1000    0.0205 #>     10        0.2822             nan     0.1000    0.0132 #>     20        0.1336             nan     0.1000    0.0051 #>     40        0.0367             nan     0.1000   -0.0024 #>     60        0.0161             nan     0.1000   -0.0042 #>     80        0.0091             nan     0.1000   -0.0025 #>    100        0.0050             nan     0.1000   -0.0024 #>    120        0.0044             nan     0.1000   -0.0019 #>    140        0.0032             nan     0.1000   -0.0003 #>    150        0.0039             nan     0.1000   -0.0021 #>  #> Warning: These variables have zero variances: rural, region #> Warning: variable 7: rural has no variation. #> Warning: variable 8: region has no variation. #> Iter   TrainDeviance   ValidDeviance   StepSize   Improve #>      1        0.6931             nan     0.1000    0.1736 #>      2        0.5577             nan     0.1000    0.1374 #>      3        0.4654             nan     0.1000    0.0975 #>      4        0.4027             nan     0.1000    0.0722 #>      5        0.3540             nan     0.1000    0.0442 #>      6        0.3121             nan     0.1000    0.0345 #>      7        0.2750             nan     0.1000    0.0191 #>      8        0.2511             nan     0.1000    0.0283 #>      9        0.2247             nan     0.1000    0.0031 #>     10        0.2133             nan     0.1000    0.0129 #>     20        0.1258             nan     0.1000   -0.0061 #>     40        0.0685             nan     0.1000   -0.0063 #>     60        0.0484             nan     0.1000    0.0025 #>     80        0.0308             nan     0.1000   -0.0039 #>    100        0.0210             nan     0.1000   -0.0027 #>    120        0.0175             nan     0.1000   -0.0030 #>    140        0.0166             nan     0.1000   -0.0042 #>    150        0.0136             nan     0.1000   -0.0005 #>  #> Warning: These variables have zero variances: rural, region #> Warning: variable 7: rural has no variation. #> Warning: variable 8: region has no variation. #> Iter   TrainDeviance   ValidDeviance   StepSize   Improve #>      1        0.6931             nan     0.1000    0.1949 #>      2        0.5543             nan     0.1000    0.1352 #>      3        0.4676             nan     0.1000    0.0882 #>      4        0.3962             nan     0.1000    0.0700 #>      5        0.3482             nan     0.1000    0.0513 #>      6        0.3064             nan     0.1000    0.0358 #>      7        0.2634             nan     0.1000    0.0297 #>      8        0.2403             nan     0.1000    0.0224 #>      9        0.2197             nan     0.1000    0.0258 #>     10        0.1988             nan     0.1000    0.0140 #>     20        0.1008             nan     0.1000   -0.0037 #>     40        0.0365             nan     0.1000   -0.0043 #>     60        0.0213             nan     0.1000   -0.0053 #>     80        0.0111             nan     0.1000   -0.0019 #>    100        0.0068             nan     0.1000   -0.0024 #>    120        0.0043             nan     0.1000   -0.0009 #>    140        0.0028             nan     0.1000    0.0003 #>    150        0.0026             nan     0.1000   -0.0012 #>  #> Warning: These variables have zero variances: rural, region #> Warning: variable 7: rural has no variation. #> Warning: variable 8: region has no variation. #> Iter   TrainDeviance   ValidDeviance   StepSize   Improve #>      1        0.6931             nan     0.1000    0.1770 #>      2        0.5569             nan     0.1000    0.0926 #>      3        0.4725             nan     0.1000    0.0880 #>      4        0.4047             nan     0.1000    0.0745 #>      5        0.3426             nan     0.1000    0.0470 #>      6        0.3006             nan     0.1000    0.0443 #>      7        0.2687             nan     0.1000    0.0307 #>      8        0.2435             nan     0.1000    0.0147 #>      9        0.2253             nan     0.1000    0.0075 #>     10        0.2072             nan     0.1000    0.0225 #>     20        0.0910             nan     0.1000    0.0004 #>     40        0.0360             nan     0.1000   -0.0009 #>     60        0.0201             nan     0.1000   -0.0012 #>     80        0.0097             nan     0.1000   -0.0000 #>    100        0.0066             nan     0.1000   -0.0011 #>    120        0.0042             nan     0.1000   -0.0013 #>    140        0.0021             nan     0.1000   -0.0006 #>    150        0.0016             nan     0.1000   -0.0004 #>  #> Warning: These variables have zero variances: rural, region #> Warning: variable 7: rural has no variation. #> Warning: variable 8: region has no variation. #> Iter   TrainDeviance   ValidDeviance   StepSize   Improve #>      1        1.3863             nan     0.1000    0.4062 #>      2        1.1391             nan     0.1000    0.2949 #>      3        0.9671             nan     0.1000    0.1995 #>      4        0.8420             nan     0.1000    0.1377 #>      5        0.7548             nan     0.1000    0.1133 #>      6        0.6721             nan     0.1000    0.0771 #>      7        0.6063             nan     0.1000    0.0629 #>      8        0.5643             nan     0.1000    0.0302 #>      9        0.5259             nan     0.1000    0.0504 #>     10        0.4923             nan     0.1000    0.0275 #>     20        0.3335             nan     0.1000   -0.0130 #>     40        0.1973             nan     0.1000   -0.0132 #>     60        0.1269             nan     0.1000   -0.0073 #>     80        0.0891             nan     0.1000   -0.0061 #>    100        0.0631             nan     0.1000   -0.0075 #>    120        0.0471             nan     0.1000   -0.0058 #>    140        0.0352             nan     0.1000   -0.0018 #>    150        0.0303             nan     0.1000   -0.0036 #>  #> Warning: These variables have zero variances: rural, region #> Warning: variable 7: rural has no variation. #> Warning: variable 8: region has no variation. #> Iter   TrainDeviance   ValidDeviance   StepSize   Improve #>      1        1.3863             nan     0.1000    0.3487 #>      2        1.1616             nan     0.1000    0.2939 #>      3        0.9843             nan     0.1000    0.2113 #>      4        0.8544             nan     0.1000    0.1427 #>      5        0.7584             nan     0.1000    0.1171 #>      6        0.6843             nan     0.1000    0.0832 #>      7        0.6214             nan     0.1000    0.0626 #>      8        0.5616             nan     0.1000    0.0595 #>      9        0.5187             nan     0.1000    0.0663 #>     10        0.4705             nan     0.1000    0.0544 #>     20        0.2605             nan     0.1000    0.0037 #>     40        0.1186             nan     0.1000   -0.0127 #>     60        0.0577             nan     0.1000   -0.0023 #>     80        0.0241             nan     0.1000   -0.0021 #>    100        0.0164             nan     0.1000   -0.0024 #>    120        0.0103             nan     0.1000   -0.0019 #>    140        0.0105             nan     0.1000   -0.0010 #>    150        0.0066             nan     0.1000   -0.0003 #>  #> Warning: These variables have zero variances: rural, region #> Warning: variable 7: rural has no variation. #> Warning: variable 8: region has no variation. #> Iter   TrainDeviance   ValidDeviance   StepSize   Improve #>      1        1.3863             nan     0.1000    0.3753 #>      2        1.1501             nan     0.1000    0.2397 #>      3        0.9692             nan     0.1000    0.1545 #>      4        0.8472             nan     0.1000    0.1445 #>      5        0.7503             nan     0.1000    0.1129 #>      6        0.6780             nan     0.1000    0.1069 #>      7        0.6014             nan     0.1000    0.0707 #>      8        0.5502             nan     0.1000    0.0660 #>      9        0.4942             nan     0.1000    0.0520 #>     10        0.4556             nan     0.1000    0.0320 #>     20        0.2326             nan     0.1000    0.0116 #>     40        0.0976             nan     0.1000   -0.0006 #>     60        0.0421             nan     0.1000   -0.0038 #>     80        0.0224             nan     0.1000   -0.0019 #>    100        0.0105             nan     0.1000    0.0000 #>    120        0.0092             nan     0.1000   -0.0012 #>    140        0.0052             nan     0.1000   -0.0016 #>    150        0.0051             nan     0.1000   -0.0013 #>  #> Warning: These variables have zero variances: rural, region #> Warning: variable 7: rural has no variation. #> Warning: variable 8: region has no variation. #> Iter   TrainDeviance   ValidDeviance   StepSize   Improve #>      1        1.3863             nan     0.1000    0.4811 #>      2        1.1108             nan     0.1000    0.3440 #>      3        0.9107             nan     0.1000    0.2336 #>      4        0.7766             nan     0.1000    0.1644 #>      5        0.6632             nan     0.1000    0.1412 #>      6        0.5794             nan     0.1000    0.0807 #>      7        0.5123             nan     0.1000    0.0825 #>      8        0.4591             nan     0.1000    0.0703 #>      9        0.4154             nan     0.1000    0.0305 #>     10        0.3832             nan     0.1000    0.0466 #>     20        0.2180             nan     0.1000   -0.0011 #>     40        0.1253             nan     0.1000   -0.0215 #>     60        0.0788             nan     0.1000   -0.0058 #>     80        0.0492             nan     0.1000    0.0016 #>    100        0.0324             nan     0.1000   -0.0030 #>    120        0.0221             nan     0.1000   -0.0054 #>    140        0.0155             nan     0.1000   -0.0001 #>    150        0.0124             nan     0.1000   -0.0005 #>  #> Warning: These variables have zero variances: rural, region #> Warning: variable 7: rural has no variation. #> Warning: variable 8: region has no variation. #> Iter   TrainDeviance   ValidDeviance   StepSize   Improve #>      1        1.3863             nan     0.1000    0.4154 #>      2        1.1203             nan     0.1000    0.3464 #>      3        0.9054             nan     0.1000    0.2358 #>      4        0.7709             nan     0.1000    0.1638 #>      5        0.6613             nan     0.1000    0.1232 #>      6        0.5770             nan     0.1000    0.0876 #>      7        0.5120             nan     0.1000    0.0772 #>      8        0.4528             nan     0.1000    0.0582 #>      9        0.4105             nan     0.1000    0.0351 #>     10        0.3786             nan     0.1000    0.0597 #>     20        0.1800             nan     0.1000    0.0075 #>     40        0.0761             nan     0.1000    0.0002 #>     60        0.0270             nan     0.1000   -0.0052 #>     80        0.0154             nan     0.1000   -0.0000 #>    100        0.0069             nan     0.1000   -0.0008 #>    120        0.0048             nan     0.1000   -0.0008 #>    140        0.0029             nan     0.1000   -0.0001 #>    150        0.0023             nan     0.1000   -0.0007 #>  #> Warning: These variables have zero variances: rural, region #> Warning: variable 7: rural has no variation. #> Warning: variable 8: region has no variation. #> Iter   TrainDeviance   ValidDeviance   StepSize   Improve #>      1        1.3863             nan     0.1000    0.4784 #>      2        1.1108             nan     0.1000    0.3108 #>      3        0.9154             nan     0.1000    0.2573 #>      4        0.7605             nan     0.1000    0.1531 #>      5        0.6592             nan     0.1000    0.1397 #>      6        0.5727             nan     0.1000    0.0892 #>      7        0.4980             nan     0.1000    0.0608 #>      8        0.4399             nan     0.1000    0.0384 #>      9        0.3987             nan     0.1000    0.0533 #>     10        0.3585             nan     0.1000    0.0446 #>     20        0.1784             nan     0.1000    0.0058 #>     40        0.0682             nan     0.1000   -0.0013 #>     60        0.0223             nan     0.1000    0.0008 #>     80        0.0110             nan     0.1000   -0.0002 #>    100        0.0035             nan     0.1000   -0.0002 #>    120        0.0019             nan     0.1000   -0.0001 #>    140        0.0011             nan     0.1000   -0.0000 #>    150        0.0007             nan     0.1000   -0.0001 #>  #> Warning: These variables have zero variances: rural, region #> Warning: variable 7: rural has no variation. #> Warning: variable 8: region has no variation. #> Iter   TrainDeviance   ValidDeviance   StepSize   Improve #>      1        1.3863             nan     0.1000    0.4259 #>      2        1.1366             nan     0.1000    0.2751 #>      3        0.9724             nan     0.1000    0.2144 #>      4        0.8541             nan     0.1000    0.1607 #>      5        0.7569             nan     0.1000    0.1155 #>      6        0.6926             nan     0.1000    0.0739 #>      7        0.6302             nan     0.1000    0.0495 #>      8        0.5893             nan     0.1000    0.0370 #>      9        0.5600             nan     0.1000    0.0053 #>     10        0.5288             nan     0.1000    0.0129 #>     20        0.3698             nan     0.1000   -0.0219 #>     40        0.2321             nan     0.1000   -0.0036 #>     60        0.1607             nan     0.1000   -0.0049 #>     80        0.1163             nan     0.1000   -0.0222 #>    100        0.0899             nan     0.1000   -0.0055 #>    120        0.0650             nan     0.1000   -0.0038 #>    140        0.0522             nan     0.1000   -0.0023 #>    150        0.0458             nan     0.1000   -0.0042 #>  #> Warning: These variables have zero variances: rural, region #> Warning: variable 7: rural has no variation. #> Warning: variable 8: region has no variation. #> Iter   TrainDeviance   ValidDeviance   StepSize   Improve #>      1        1.3863             nan     0.1000    0.3799 #>      2        1.1538             nan     0.1000    0.3003 #>      3        0.9720             nan     0.1000    0.2353 #>      4        0.8444             nan     0.1000    0.1493 #>      5        0.7504             nan     0.1000    0.1425 #>      6        0.6687             nan     0.1000    0.0977 #>      7        0.6025             nan     0.1000    0.0595 #>      8        0.5517             nan     0.1000    0.0485 #>      9        0.5089             nan     0.1000    0.0435 #>     10        0.4720             nan     0.1000    0.0274 #>     20        0.2734             nan     0.1000    0.0131 #>     40        0.1196             nan     0.1000   -0.0112 #>     60        0.0525             nan     0.1000   -0.0026 #>     80        0.0290             nan     0.1000   -0.0008 #>    100        0.0145             nan     0.1000   -0.0011 #>    120        0.0089             nan     0.1000   -0.0015 #>    140        0.0072             nan     0.1000   -0.0018 #>    150        0.0068             nan     0.1000   -0.0003 #>  #> Warning: These variables have zero variances: rural, region #> Warning: variable 7: rural has no variation. #> Warning: variable 8: region has no variation. #> Iter   TrainDeviance   ValidDeviance   StepSize   Improve #>      1        1.3863             nan     0.1000    0.4651 #>      2        1.1266             nan     0.1000    0.2822 #>      3        0.9595             nan     0.1000    0.1982 #>      4        0.8356             nan     0.1000    0.1254 #>      5        0.7355             nan     0.1000    0.1197 #>      6        0.6558             nan     0.1000    0.0815 #>      7        0.5961             nan     0.1000    0.0549 #>      8        0.5520             nan     0.1000    0.0724 #>      9        0.5002             nan     0.1000    0.0244 #>     10        0.4688             nan     0.1000    0.0453 #>     20        0.2592             nan     0.1000    0.0077 #>     40        0.1047             nan     0.1000   -0.0079 #>     60        0.0447             nan     0.1000   -0.0024 #>     80        0.0231             nan     0.1000   -0.0036 #>    100        0.0140             nan     0.1000   -0.0022 #>    120        0.0104             nan     0.1000   -0.0019 #>    140        0.0082             nan     0.1000   -0.0020 #>    150        0.0068             nan     0.1000   -0.0018 #>  #> Warning: These variables have zero variances: rural, region #> Warning: variable 7: rural has no variation. #> Warning: variable 8: region has no variation. #> Iter   TrainDeviance   ValidDeviance   StepSize   Improve #>      1        1.3863             nan     0.1000    0.5189 #>      2        1.0942             nan     0.1000    0.3390 #>      3        0.9009             nan     0.1000    0.2309 #>      4        0.7600             nan     0.1000    0.1711 #>      5        0.6525             nan     0.1000    0.1319 #>      6        0.5665             nan     0.1000    0.0765 #>      7        0.5137             nan     0.1000    0.0507 #>      8        0.4610             nan     0.1000    0.0708 #>      9        0.4168             nan     0.1000    0.0478 #>     10        0.3795             nan     0.1000    0.0397 #>     20        0.1926             nan     0.1000   -0.0036 #>     40        0.0916             nan     0.1000   -0.0025 #>     60        0.0425             nan     0.1000   -0.0045 #>     80        0.0231             nan     0.1000   -0.0028 #>    100        0.0131             nan     0.1000   -0.0023 #>    120        0.0082             nan     0.1000   -0.0006 #>    140        0.0047             nan     0.1000   -0.0002 #>    150        0.0035             nan     0.1000    0.0001 #>  #> Warning: These variables have zero variances: rural, region #> Warning: variable 7: rural has no variation. #> Warning: variable 8: region has no variation. #> Iter   TrainDeviance   ValidDeviance   StepSize   Improve #>      1        1.3863             nan     0.1000    0.5470 #>      2        1.0948             nan     0.1000    0.3293 #>      3        0.9061             nan     0.1000    0.2433 #>      4        0.7571             nan     0.1000    0.1805 #>      5        0.6527             nan     0.1000    0.1349 #>      6        0.5663             nan     0.1000    0.1107 #>      7        0.4983             nan     0.1000    0.0898 #>      8        0.4380             nan     0.1000    0.0599 #>      9        0.3918             nan     0.1000    0.0538 #>     10        0.3550             nan     0.1000    0.0425 #>     20        0.1527             nan     0.1000    0.0047 #>     40        0.0501             nan     0.1000   -0.0075 #>     60        0.0248             nan     0.1000   -0.0003 #>     80        0.0094             nan     0.1000   -0.0031 #>    100        0.0075             nan     0.1000   -0.0017 #>    120        0.0047             nan     0.1000   -0.0004 #>    140        0.0019             nan     0.1000   -0.0004 #>    150        0.0017             nan     0.1000   -0.0003 #>  #> Warning: These variables have zero variances: rural, region #> Warning: variable 7: rural has no variation. #> Warning: variable 8: region has no variation. #> Iter   TrainDeviance   ValidDeviance   StepSize   Improve #>      1        1.3863             nan     0.1000    0.5172 #>      2        1.0877             nan     0.1000    0.3249 #>      3        0.8966             nan     0.1000    0.2199 #>      4        0.7630             nan     0.1000    0.1762 #>      5        0.6590             nan     0.1000    0.1253 #>      6        0.5704             nan     0.1000    0.0976 #>      7        0.5034             nan     0.1000    0.0697 #>      8        0.4530             nan     0.1000    0.0705 #>      9        0.4062             nan     0.1000    0.0572 #>     10        0.3602             nan     0.1000    0.0492 #>     20        0.1521             nan     0.1000    0.0101 #>     40        0.0369             nan     0.1000   -0.0025 #>     60        0.0174             nan     0.1000   -0.0018 #>     80        0.0057             nan     0.1000   -0.0002 #>    100        0.0019             nan     0.1000   -0.0001 #>    120        0.0006             nan     0.1000   -0.0001 #>    140        0.0004             nan     0.1000   -0.0000 #>    150        0.0003             nan     0.1000   -0.0001 #>  #> Warning: These variables have zero variances: rural, region #> Warning: variable 7: rural has no variation. #> Warning: variable 8: region has no variation. #> Iter   TrainDeviance   ValidDeviance   StepSize   Improve #>      1        1.3863             nan     0.1000    0.4170 #>      2        1.1432             nan     0.1000    0.2734 #>      3        0.9686             nan     0.1000    0.1983 #>      4        0.8425             nan     0.1000    0.1364 #>      5        0.7537             nan     0.1000    0.0935 #>      6        0.6825             nan     0.1000    0.0820 #>      7        0.6257             nan     0.1000    0.0461 #>      8        0.5848             nan     0.1000    0.0238 #>      9        0.5485             nan     0.1000    0.0376 #>     10        0.5147             nan     0.1000    0.0338 #>     20        0.3569             nan     0.1000   -0.0436 #>     40        0.2406             nan     0.1000    0.0013 #>     60        0.1693             nan     0.1000   -0.0125 #>     80        0.1275             nan     0.1000   -0.0192 #>    100        0.1036             nan     0.1000   -0.0053 #>    120        0.0875             nan     0.1000   -0.0060 #>    140        0.0672             nan     0.1000   -0.0053 #>    150        0.0610             nan     0.1000   -0.0061 #>  #> Warning: These variables have zero variances: rural, region #> Warning: variable 7: rural has no variation. #> Warning: variable 8: region has no variation. #> Iter   TrainDeviance   ValidDeviance   StepSize   Improve #>      1        1.3863             nan     0.1000    0.4324 #>      2        1.1479             nan     0.1000    0.2394 #>      3        0.9796             nan     0.1000    0.2040 #>      4        0.8631             nan     0.1000    0.1517 #>      5        0.7625             nan     0.1000    0.1137 #>      6        0.6857             nan     0.1000    0.0771 #>      7        0.6281             nan     0.1000    0.0582 #>      8        0.5809             nan     0.1000    0.0533 #>      9        0.5351             nan     0.1000    0.0312 #>     10        0.5013             nan     0.1000    0.0244 #>     20        0.2967             nan     0.1000   -0.0009 #>     40        0.1495             nan     0.1000   -0.0112 #>     60        0.0837             nan     0.1000   -0.0082 #>     80        0.0609             nan     0.1000   -0.0091 #>    100        0.0321             nan     0.1000   -0.0053 #>    120        0.0254             nan     0.1000   -0.0044 #>    140        0.0150             nan     0.1000   -0.0003 #>    150        0.0131             nan     0.1000   -0.0037 #>  #> Warning: These variables have zero variances: rural, region #> Warning: variable 7: rural has no variation. #> Warning: variable 8: region has no variation. #> Iter   TrainDeviance   ValidDeviance   StepSize   Improve #>      1        1.3863             nan     0.1000    0.4332 #>      2        1.1411             nan     0.1000    0.2476 #>      3        0.9719             nan     0.1000    0.2183 #>      4        0.8372             nan     0.1000    0.1269 #>      5        0.7447             nan     0.1000    0.0944 #>      6        0.6709             nan     0.1000    0.0794 #>      7        0.6093             nan     0.1000    0.0649 #>      8        0.5601             nan     0.1000    0.0619 #>      9        0.5206             nan     0.1000    0.0351 #>     10        0.4903             nan     0.1000    0.0248 #>     20        0.2724             nan     0.1000    0.0025 #>     40        0.1389             nan     0.1000   -0.0077 #>     60        0.0717             nan     0.1000   -0.0050 #>     80        0.0364             nan     0.1000   -0.0045 #>    100        0.0204             nan     0.1000   -0.0030 #>    120        0.0156             nan     0.1000   -0.0022 #>    140        0.0102             nan     0.1000   -0.0019 #>    150        0.0073             nan     0.1000   -0.0021 #>  #> Warning: These variables have zero variances: rural, region #> Warning: variable 7: rural has no variation. #> Warning: variable 8: region has no variation. #> Iter   TrainDeviance   ValidDeviance   StepSize   Improve #>      1        1.3863             nan     0.1000    0.4066 #>      2        1.1383             nan     0.1000    0.3257 #>      3        0.9522             nan     0.1000    0.2088 #>      4        0.8282             nan     0.1000    0.1540 #>      5        0.7351             nan     0.1000    0.0853 #>      6        0.6682             nan     0.1000    0.0651 #>      7        0.6080             nan     0.1000    0.0682 #>      8        0.5544             nan     0.1000    0.0407 #>      9        0.5193             nan     0.1000    0.0453 #>     10        0.4776             nan     0.1000    0.0316 #>     20        0.2883             nan     0.1000   -0.0133 #>     40        0.1456             nan     0.1000   -0.0118 #>     50        0.1095             nan     0.1000   -0.0190 #>  #> Warning: variable 7: rural has no variation. #> Warning: variable 8: region has no variation. #> Iter   TrainDeviance   ValidDeviance   StepSize   Improve #>      1        1.3863             nan     0.0010    0.0045 #>      2        1.3839             nan     0.0010    0.0055 #>      3        1.3811             nan     0.0010    0.0053 #>      4        1.3781             nan     0.0010    0.0050 #>      5        1.3754             nan     0.0010    0.0051 #>      6        1.3728             nan     0.0010    0.0049 #>      7        1.3699             nan     0.0010    0.0053 #>      8        1.3672             nan     0.0010    0.0053 #>      9        1.3645             nan     0.0010    0.0052 #>     10        1.3615             nan     0.0010    0.0051 #>     20        1.3349             nan     0.0010    0.0047 #>     40        1.2854             nan     0.0010    0.0044 #>     60        1.2394             nan     0.0010    0.0041 #>     80        1.1962             nan     0.0010    0.0034 #>    100        1.1562             nan     0.0010    0.0039 #>  #> Warning: No observation for response level(s): Informal #> Warning: The following classes were not found in 'response': Informal. BchMk.GBM$finalModel #> A gradient boosted model with multinomial loss function. #> 50 iterations were performed. #> There were 12 predictors of which 8 had non-zero influence. BchMk.GBM$Roc$auc #> Multi-class area under the curve: 0.6958 # }"},{"path":"/reference/GLM_Model.html","id":null,"dir":"Reference","previous_headings":"","what":"Generalized Linear Model — GLM_Model","title":"Generalized Linear Model — GLM_Model","text":"Generalized Linear Model","code":""},{"path":"/reference/GLM_Model.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generalized Linear Model — GLM_Model","text":"","code":"GLM_Model(Data, xvar, yvar)"},{"path":"/reference/GLM_Model.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generalized Linear Model — GLM_Model","text":"Data name Dataset. xvar X variables. yvar Y variable.","code":""},{"path":"/reference/GLM_Model.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generalized Linear Model — GLM_Model","text":"output  GLM_Model.","code":""},{"path":"/reference/GLM_Model.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Generalized Linear Model — GLM_Model","text":"Let y vector response variable accessing credit applicant \\(n\\), \\(y_{}=1\\)  applicant-\\(\\) access credit, zero otherwise. Furthermore, let let \\(\\bold{x} = x_{ij}\\),  \\(=1,\\ldots,n\\) \\(j=1,\\ldots,p\\) characteristics applicants. log-odds can define : $$log(\\frac{\\pi_{}}{1-\\pi_{}}) = \\beta_{0}+\\bold{x}_{\\bold{}}\\beta = \\beta_{0}+\\sum_{=1}^{p}\\beta_{}\\bold{x}_{}$$ \\(\\beta_{0}\\) intercept, \\(\\beta = (\\beta_{1},\\ldots, \\beta_{p})\\)  \\(p\\) \\(x\\) \\(1\\) vector coefficients \t     \\(\\bold{x_{}}\\) \\(i_{th}\\) row  x.","code":""},{"path":"/reference/GLM_Model.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generalized Linear Model — GLM_Model","text":"","code":"yvar <- c(\"multi.level\") sample_data <- sample_data[c(1:750),] xvar <- c(\"sex\", \"married\", \"age\", \"havejob\", \"educ\", \"political.afl\", \"rural\", \"region\", \"fin.intermdiaries\", \"fin.knowldge\", \"income\") BchMk.GLM <- GLM_Model(sample_data, c(xvar, \"networth\"), yvar ) #> + Fold01: parameter=none  #> - Fold01: parameter=none  #> + Fold02: parameter=none  #> - Fold02: parameter=none  #> + Fold03: parameter=none  #> - Fold03: parameter=none  #> + Fold04: parameter=none  #> - Fold04: parameter=none  #> + Fold05: parameter=none  #> - Fold05: parameter=none  #> + Fold06: parameter=none  #> - Fold06: parameter=none  #> + Fold07: parameter=none  #> - Fold07: parameter=none  #> + Fold08: parameter=none  #> - Fold08: parameter=none  #> + Fold09: parameter=none  #> - Fold09: parameter=none  #> + Fold10: parameter=none  #> - Fold10: parameter=none  #> Aggregating results #> Fitting final model on full training set #> Warning: glm.fit: algorithm did not converge BchMk.GLM$finalModel #>  #> Call:  glm(formula = Data.sub.train[, yvar] ~ ., family = binomial(link = \"logit\"),  #>     data = Data.sub.train) #>  #> Coefficients: #>       (Intercept)                sex            married                age   #>         -1.209619          -0.089582          -0.174058          -0.814252   #>           havejob               educ      political.afl              rural   #>          0.124936           0.004939          -0.014143          -0.217215   #>            region  fin.intermdiaries       fin.knowldge             income   #>          0.064235          -0.094970           0.119354           0.738557   #>          networth   #>          0.257018   #>  #> Degrees of Freedom: 600 Total (i.e. Null);  588 Residual #> Null Deviance:\t    690.4  #> Residual Deviance: 584.3 \tAIC: 610.3 BchMk.GLM$Roc$auc #> Multi-class area under the curve: 0.7196"},{"path":"/reference/MLM_Model.html","id":null,"dir":"Reference","previous_headings":"","what":"Multinominal Logistic Model — MLM_Model","title":"Multinominal Logistic Model — MLM_Model","text":"Multinominal Logistic Model","code":""},{"path":"/reference/MLM_Model.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Multinominal Logistic Model — MLM_Model","text":"","code":"MLM_Model(Data, xvar, yvar)"},{"path":"/reference/MLM_Model.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Multinominal Logistic Model — MLM_Model","text":"Data name Dataset. xvar X variables. yvar Y variable.","code":""},{"path":"/reference/MLM_Model.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Multinominal Logistic Model — MLM_Model","text":"output  MLM_Model.","code":""},{"path":"/reference/MLM_Model.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Multinominal Logistic Model — MLM_Model","text":"Multi-nominal model generalized form generalized logistic model can define $$\\pi_{}^{h} = P(y_{}^{h} = 1 | \\bold{x}_{\\bold{}}^{h})$$ \\(h\\) presents class labels (\"1--h\") basis input vector \\(x_j\\), case \\(x_j\\) loan types (\"Formal Loan\", \"Informal Loan\", \"Loan\", \"Loan\").  Furthermore, \\(y_{}^h =  1\\)weight w    \\(x_j\\) corresponds belong class  \\(y_{}^h=0\\) otherwise.   \\(\\) \\(\\\\) \\(1,\\ldots,h\\)   weight vectors w^corresponds class \\(\\). set \\({\\bold{{w}}^{h}} = 0\\) parameters learned weight vectors w^\\(\\) \\(\\\\) \\(1,\\ldots,h-1\\) . class probabilities must satisfy $$\\sum_{=1}^{h} P(y_{}^{h} = 1 | \\bold{x}_{\\bold{}}^{h}, \\bold{w}) = 1.$$","code":""},{"path":"/reference/MLM_Model.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Multinominal Logistic Model — MLM_Model","text":"","code":"yvar <- c(\"Loan.Type\") sample_data <- sample_data[c(1:750),] xvar <- c(\"sex\", \"married\", \"age\", \"havejob\", \"educ\", \"political.afl\", \"rural\", \"region\", \"fin.intermdiaries\", \"fin.knowldge\", \"income\") BchMk.MLM <- MLM_Model(sample_data, c(xvar, \"networth\"), yvar ) #> + Fold01: decay=0e+00  #> # weights:  56 (39 variable) #> initial  value 749.985249  #> iter  10 value 506.209628 #> iter  20 value 384.236762 #> iter  30 value 360.833421 #> iter  40 value 355.450144 #> iter  50 value 355.287585 #> final  value 355.287545  #> converged #> - Fold01: decay=0e+00  #> + Fold01: decay=1e-01  #> # weights:  56 (39 variable) #> initial  value 749.985249  #> iter  10 value 423.839563 #> iter  20 value 386.597518 #> iter  30 value 361.164027 #> iter  40 value 358.967298 #> iter  50 value 358.913005 #> iter  50 value 358.913003 #> iter  50 value 358.913003 #> final  value 358.913003  #> converged #> - Fold01: decay=1e-01  #> + Fold01: decay=1e-04  #> # weights:  56 (39 variable) #> initial  value 749.985249  #> iter  10 value 506.221433 #> iter  20 value 384.250118 #> iter  30 value 360.830019 #> iter  40 value 355.452252 #> iter  50 value 355.291436 #> final  value 355.291396  #> converged #> - Fold01: decay=1e-04  #> + Fold02: decay=0e+00  #> # weights:  56 (39 variable) #> initial  value 748.598955  #> iter  10 value 498.747959 #> iter  20 value 379.009462 #> iter  30 value 357.084414 #> iter  40 value 349.201025 #> iter  50 value 349.101543 #> final  value 349.101388  #> converged #> - Fold02: decay=0e+00  #> + Fold02: decay=1e-01  #> # weights:  56 (39 variable) #> initial  value 748.598955  #> iter  10 value 412.721055 #> iter  20 value 381.893023 #> iter  30 value 354.877541 #> iter  40 value 352.900082 #> iter  50 value 352.805489 #> final  value 352.805135  #> converged #> - Fold02: decay=1e-01  #> + Fold02: decay=1e-04  #> # weights:  56 (39 variable) #> initial  value 748.598955  #> iter  10 value 498.757182 #> iter  20 value 379.018312 #> iter  30 value 357.085160 #> iter  40 value 349.205828 #> iter  50 value 349.105470 #> final  value 349.105316  #> converged #> - Fold02: decay=1e-04  #> + Fold03: decay=0e+00  #> # weights:  56 (39 variable) #> initial  value 748.598955  #> iter  10 value 498.409018 #> iter  20 value 383.451954 #> iter  30 value 357.141126 #> iter  40 value 352.817845 #> iter  50 value 352.691687 #> final  value 352.691659  #> converged #> - Fold03: decay=0e+00  #> + Fold03: decay=1e-01  #> # weights:  56 (39 variable) #> initial  value 748.598955  #> iter  10 value 421.405176 #> iter  20 value 379.169416 #> iter  30 value 359.467486 #> iter  40 value 356.364762 #> iter  50 value 356.333645 #> final  value 356.333626  #> converged #> - Fold03: decay=1e-01  #> + Fold03: decay=1e-04  #> # weights:  56 (39 variable) #> initial  value 748.598955  #> iter  10 value 498.418913 #> iter  20 value 383.438290 #> iter  30 value 357.146499 #> iter  40 value 352.828589 #> iter  50 value 352.695620 #> final  value 352.695541  #> converged #> - Fold03: decay=1e-04  #> + Fold04: decay=0e+00  #> # weights:  56 (39 variable) #> initial  value 751.371544  #> iter  10 value 518.981204 #> iter  20 value 390.214534 #> iter  30 value 361.720979 #> iter  40 value 357.293998 #> iter  50 value 357.054862 #> final  value 357.052165  #> converged #> - Fold04: decay=0e+00  #> + Fold04: decay=1e-01  #> # weights:  56 (39 variable) #> initial  value 751.371544  #> iter  10 value 528.822078 #> iter  20 value 398.135469 #> iter  30 value 365.460839 #> iter  40 value 360.614925 #> iter  50 value 360.495299 #> final  value 360.494767  #> converged #> - Fold04: decay=1e-01  #> + Fold04: decay=1e-04  #> # weights:  56 (39 variable) #> initial  value 751.371544  #> iter  10 value 518.993295 #> iter  20 value 390.221812 #> iter  30 value 361.728448 #> iter  40 value 357.298728 #> iter  50 value 357.058474 #> final  value 357.055812  #> converged #> - Fold04: decay=1e-04  #> + Fold05: decay=0e+00  #> # weights:  56 (39 variable) #> initial  value 751.371544  #> iter  10 value 422.878970 #> iter  20 value 384.295152 #> iter  30 value 360.292707 #> iter  40 value 354.408399 #> iter  50 value 354.240640 #> final  value 354.240611  #> converged #> - Fold05: decay=0e+00  #> + Fold05: decay=1e-01  #> # weights:  56 (39 variable) #> initial  value 751.371544  #> iter  10 value 377.255718 #> iter  20 value 359.094104 #> iter  30 value 358.090313 #> iter  40 value 358.036940 #> iter  50 value 358.036468 #> final  value 358.036420  #> converged #> - Fold05: decay=1e-01  #> + Fold05: decay=1e-04  #> # weights:  56 (39 variable) #> initial  value 751.371544  #> iter  10 value 422.892258 #> iter  20 value 384.299811 #> iter  30 value 360.308523 #> iter  40 value 354.415214 #> iter  50 value 354.244765 #> final  value 354.244748  #> converged #> - Fold05: decay=1e-04  #> + Fold06: decay=0e+00  #> # weights:  56 (39 variable) #> initial  value 751.371544  #> iter  10 value 489.664491 #> iter  20 value 391.701341 #> iter  30 value 357.648510 #> iter  40 value 349.322942 #> iter  50 value 349.123978 #> final  value 349.123955  #> converged #> - Fold06: decay=0e+00  #> + Fold06: decay=1e-01  #> # weights:  56 (39 variable) #> initial  value 751.371544  #> iter  10 value 501.909649 #> iter  20 value 395.018203 #> iter  30 value 359.433062 #> iter  40 value 353.221205 #> iter  50 value 352.997757 #> final  value 352.997690  #> converged #> - Fold06: decay=1e-01  #> + Fold06: decay=1e-04  #> # weights:  56 (39 variable) #> initial  value 751.371544  #> iter  10 value 489.677751 #> iter  20 value 391.700725 #> iter  30 value 357.639310 #> iter  40 value 349.338781 #> iter  50 value 349.128140 #> final  value 349.128111  #> converged #> - Fold06: decay=1e-04  #> + Fold07: decay=0e+00  #> # weights:  56 (39 variable) #> initial  value 748.598955  #> iter  10 value 483.532925 #> iter  20 value 388.721848 #> iter  30 value 365.509561 #> iter  40 value 355.510824 #> iter  50 value 354.609250 #> final  value 354.607977  #> converged #> - Fold07: decay=0e+00  #> + Fold07: decay=1e-01  #> # weights:  56 (39 variable) #> initial  value 748.598955  #> iter  10 value 492.222394 #> iter  20 value 395.522132 #> iter  30 value 362.437336 #> iter  40 value 358.054768 #> iter  50 value 358.018657 #> iter  50 value 358.018654 #> iter  50 value 358.018654 #> final  value 358.018654  #> converged #> - Fold07: decay=1e-01  #> + Fold07: decay=1e-04  #> # weights:  56 (39 variable) #> initial  value 748.598955  #> iter  10 value 483.542583 #> iter  20 value 388.734866 #> iter  30 value 365.511493 #> iter  40 value 355.537534 #> iter  50 value 354.612885 #> final  value 354.611572  #> converged #> - Fold07: decay=1e-04  #> + Fold08: decay=0e+00  #> # weights:  56 (39 variable) #> initial  value 749.985249  #> iter  10 value 366.582717 #> iter  20 value 350.036047 #> iter  30 value 348.868897 #> iter  40 value 348.761028 #> iter  50 value 348.759044 #> iter  50 value 348.759043 #> iter  50 value 348.759043 #> final  value 348.759043  #> converged #> - Fold08: decay=0e+00  #> + Fold08: decay=1e-01  #> # weights:  56 (39 variable) #> initial  value 749.985249  #> iter  10 value 368.589255 #> iter  20 value 353.334020 #> iter  30 value 352.416076 #> iter  40 value 352.362775 #> final  value 352.361244  #> converged #> - Fold08: decay=1e-01  #> + Fold08: decay=1e-04  #> # weights:  56 (39 variable) #> initial  value 749.985249  #> iter  10 value 366.584744 #> iter  20 value 350.039458 #> iter  30 value 348.872670 #> iter  40 value 348.764828 #> iter  50 value 348.762843 #> iter  50 value 348.762842 #> iter  50 value 348.762842 #> final  value 348.762842  #> converged #> - Fold08: decay=1e-04  #> + Fold09: decay=0e+00  #> # weights:  56 (39 variable) #> initial  value 749.985249  #> iter  10 value 409.398734 #> iter  20 value 375.297070 #> iter  30 value 359.304512 #> iter  40 value 356.792742 #> iter  50 value 356.757998 #> iter  50 value 356.757997 #> iter  50 value 356.757997 #> final  value 356.757997  #> converged #> - Fold09: decay=0e+00  #> + Fold09: decay=1e-01  #> # weights:  56 (39 variable) #> initial  value 749.985249  #> iter  10 value 421.580286 #> iter  20 value 377.497320 #> iter  30 value 365.023804 #> iter  40 value 360.630833 #> iter  50 value 360.344404 #> final  value 360.344347  #> converged #> - Fold09: decay=1e-01  #> + Fold09: decay=1e-04  #> # weights:  56 (39 variable) #> initial  value 749.985249  #> iter  10 value 409.411216 #> iter  20 value 375.305341 #> iter  30 value 359.322243 #> iter  40 value 356.810266 #> iter  50 value 356.775496 #> iter  60 value 356.762665 #> final  value 356.762306  #> converged #> - Fold09: decay=1e-04  #> + Fold10: decay=0e+00  #> # weights:  56 (39 variable) #> initial  value 748.598955  #> iter  10 value 367.735182 #> iter  20 value 353.413040 #> iter  30 value 352.265766 #> iter  40 value 352.091900 #> final  value 352.089949  #> converged #> - Fold10: decay=0e+00  #> + Fold10: decay=1e-01  #> # weights:  56 (39 variable) #> initial  value 748.598955  #> iter  10 value 369.785750 #> iter  20 value 356.404982 #> iter  30 value 355.479847 #> iter  40 value 355.357065 #> final  value 355.355443  #> converged #> - Fold10: decay=1e-01  #> + Fold10: decay=1e-04  #> # weights:  56 (39 variable) #> initial  value 748.598955  #> iter  10 value 367.737250 #> iter  20 value 353.416103 #> iter  30 value 352.269077 #> iter  40 value 352.095282 #> final  value 352.093331  #> converged #> - Fold10: decay=1e-04  #> Aggregating results #> Selecting tuning parameters #> Fitting decay = 1e-04 on full training set #> # weights:  56 (39 variable) #> initial  value 833.162911  #> iter  10 value 412.580108 #> iter  20 value 395.484826 #> iter  30 value 394.474574 #> iter  40 value 394.410878 #> final  value 394.410325  #> converged BchMk.MLM$finalModel #> Call: #> nnet::multinom(formula = .outcome ~ ., data = dat, decay = param$decay) #>  #> Coefficients: #>          (Intercept)         sex    married        age    havejob        educ #> Formal     -2.698662 -0.21865806  0.2956626 -1.0447791 0.21556715  0.18303709 #> Informal   -2.788642 -0.17594671 -0.1016013 -0.6373116 0.07139939 -0.05253701 #> L.Both     -3.406405  0.01156829 -0.2244586 -1.1008824 0.18481408  0.30394865 #>          political.afl      rural       region fin.intermdiaries fin.knowldge #> Formal      0.25801825  0.3551217 -0.246815286        0.04362295   0.23032226 #> Informal   -0.34335288 -0.1917323  0.105678333       -0.13223849   0.16049012 #> L.Both      0.07191478 -0.4018127 -0.008530078        0.23821083   0.04082711 #>              income   networth #> Formal    0.7105534  0.3769751 #> Informal -1.9799224 -1.2142562 #> L.Both    0.4025622  0.2727291 #>  #> Residual Deviance: 788.8207  #> AIC: 866.8207  BchMk.MLM$Roc$auc #> Multi-class area under the curve: 0.7342"},{"path":"/reference/RF_Model.html","id":null,"dir":"Reference","previous_headings":"","what":"Random Forest — RF_Model","title":"Random Forest — RF_Model","text":"Random Forest","code":""},{"path":"/reference/RF_Model.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Random Forest — RF_Model","text":"","code":"RF_Model(Data, xvar, yvar)"},{"path":"/reference/RF_Model.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Random Forest — RF_Model","text":"Data name Dataset. xvar X variables. yvar Y variable.","code":""},{"path":"/reference/RF_Model.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Random Forest — RF_Model","text":"output  RF_Model.","code":""},{"path":"/reference/RF_Model.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Random Forest — RF_Model","text":"Rather considering random sample \\(m\\) predictors total \\(p\\) predictors split, random forest consider majority \\(p\\) predictors, considers split fresh sample  \\(m_{try}\\) usually set  \\(m_{try} \\approx \\sqrt{p}\\) Random forests de-correlate trees considering  \\(m_{try} \\approx \\sqrt{p}\\) show improvement bagged trees  \\(m = p\\).","code":""},{"path":"/reference/RF_Model.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Random Forest — RF_Model","text":"","code":"# \\donttest{ sample_data <- sample_data[c(1:750),] yvar <- c(\"Loan.Type\") xvar <- c(\"sex\", \"married\", \"age\", \"havejob\", \"educ\", \"political.afl\", \"rural\", \"region\", \"fin.intermdiaries\", \"fin.knowldge\", \"income\") BchMk.RF <- RF_Model(sample_data, c(xvar, \"networth\"), yvar ) #> + Fold01: mtry= 2  #> - Fold01: mtry= 2  #> + Fold01: mtry= 7  #> - Fold01: mtry= 7  #> + Fold01: mtry=12  #> - Fold01: mtry=12  #> + Fold02: mtry= 2  #> - Fold02: mtry= 2  #> + Fold02: mtry= 7  #> - Fold02: mtry= 7  #> + Fold02: mtry=12  #> - Fold02: mtry=12  #> + Fold03: mtry= 2  #> - Fold03: mtry= 2  #> + Fold03: mtry= 7  #> - Fold03: mtry= 7  #> + Fold03: mtry=12  #> - Fold03: mtry=12  #> + Fold04: mtry= 2  #> - Fold04: mtry= 2  #> + Fold04: mtry= 7  #> - Fold04: mtry= 7  #> + Fold04: mtry=12  #> - Fold04: mtry=12  #> + Fold05: mtry= 2  #> - Fold05: mtry= 2  #> + Fold05: mtry= 7  #> - Fold05: mtry= 7  #> + Fold05: mtry=12  #> - Fold05: mtry=12  #> + Fold06: mtry= 2  #> - Fold06: mtry= 2  #> + Fold06: mtry= 7  #> - Fold06: mtry= 7  #> + Fold06: mtry=12  #> - Fold06: mtry=12  #> + Fold07: mtry= 2  #> - Fold07: mtry= 2  #> + Fold07: mtry= 7  #> - Fold07: mtry= 7  #> + Fold07: mtry=12  #> - Fold07: mtry=12  #> + Fold08: mtry= 2  #> - Fold08: mtry= 2  #> + Fold08: mtry= 7  #> - Fold08: mtry= 7  #> + Fold08: mtry=12  #> - Fold08: mtry=12  #> + Fold09: mtry= 2  #> - Fold09: mtry= 2  #> + Fold09: mtry= 7  #> - Fold09: mtry= 7  #> + Fold09: mtry=12  #> - Fold09: mtry=12  #> + Fold10: mtry= 2  #> - Fold10: mtry= 2  #> + Fold10: mtry= 7  #> - Fold10: mtry= 7  #> + Fold10: mtry=12  #> - Fold10: mtry=12  #> Aggregating results #> Selecting tuning parameters #> Fitting mtry = 2 on full training set BchMk.RF #> Random Forest  #>  #> 601 samples #>  12 predictor #>   4 classes: 'No.Loan', 'Formal', 'Informal', 'L.Both'  #>  #> Pre-processing: centered (12), scaled (12)  #> Resampling: Cross-Validated (10 fold)  #> Summary of sample sizes: 540, 541, 541, 541, 539, 540, ...  #> Resampling results across tuning parameters: #>  #>   mtry  Accuracy   Kappa     #>    2    0.7738569  0.2399421 #>    7    0.7587457  0.2597588 #>   12    0.7489370  0.2526176 #>  #> Accuracy was used to select the optimal model using the largest value. #> The final value used for the model was mtry = 2.  # }"},{"path":"/reference/sample_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Sample data for analysis.\r\n\r\nA dataset containing information of access to credit. — sample_data","title":"Sample data for analysis.\r\n\r\nA dataset containing information of access to credit. — sample_data","text":"Sample data analysis. dataset containing information access credit.","code":""},{"path":"/reference/sample_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sample data for analysis.\r\n\r\nA dataset containing information of access to credit. — sample_data","text":"","code":"sample_data"},{"path":"/reference/sample_data.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Sample data for analysis.\r\n\r\nA dataset containing information of access to credit. — sample_data","text":"data_frame 53940 rows 10 variables: x1 hhid, household id number x2 swgt, survey weight x3 region, 3 factor level, west, east, center x4 .Loan, household loan x5 Formal, household formal loan x6 , household loan x7 Informal, household informal loan x8 sex, household male y1 Loan.Type, 4 factor level type loan y2 multi.level, 2 factor level household access loan ","code":""}]
