[{"path":"https://seymakalay.github.io/pomodoro/articles/Pomodoro_Vignette.html","id":"estimate_models","dir":"Articles","previous_headings":"","what":"Estimate_Models","title":"Pomodoro_Vignette","text":"Estimate_Models function considers exog xadd variables set multiple models based selected exog xadd. one hand exog subtract selected vector dataset run model dataset splits exog. hand xadd add selected vectors run model. dnames unique values exog save model estimates name.","code":"sample_data <- sample_data[c(1:750),] yvar <- c(\"Loan.Type\") xvar <- c(\"sex\", \"married\", \"age\", \"havejob\", \"educ\", \"political.afl\", \"rural\", \"region\", \"fin.intermdiaries\", \"fin.knowldge\", \"income\") CCP.RF <- Estimate_Models(sample_data, yvar, xvec = xvar, exog = \"political.afl\", xadd = c(\"networth\", \"networth_homequity\", \"liquid.assets\"), type = \"RF\", dnames = c(\"0\",\"1\")) #> + Fold01: mtry= 2  #> - Fold01: mtry= 2  #> + Fold01: mtry= 6  #> - Fold01: mtry= 6  #> + Fold01: mtry=11  #> - Fold01: mtry=11  #> + Fold02: mtry= 2  #> - Fold02: mtry= 2  #> + Fold02: mtry= 6  #> - Fold02: mtry= 6  #> + Fold02: mtry=11  #> - Fold02: mtry=11  #> + Fold03: mtry= 2  #> - Fold03: mtry= 2  #> + Fold03: mtry= 6  #> - Fold03: mtry= 6  #> + Fold03: mtry=11  #> - Fold03: mtry=11  #> + Fold04: mtry= 2  #> - Fold04: mtry= 2  #> + Fold04: mtry= 6  #> - Fold04: mtry= 6  #> + Fold04: mtry=11  #> - Fold04: mtry=11  #> + Fold05: mtry= 2  #> - Fold05: mtry= 2  #> + Fold05: mtry= 6  #> - Fold05: mtry= 6  #> + Fold05: mtry=11  #> - Fold05: mtry=11  #> + Fold06: mtry= 2  #> - Fold06: mtry= 2  #> + Fold06: mtry= 6  #> - Fold06: mtry= 6  #> + Fold06: mtry=11  #> - Fold06: mtry=11  #> + Fold07: mtry= 2  #> - Fold07: mtry= 2  #> + Fold07: mtry= 6  #> - Fold07: mtry= 6  #> + Fold07: mtry=11  #> - Fold07: mtry=11  #> + Fold08: mtry= 2  #> - Fold08: mtry= 2  #> + Fold08: mtry= 6  #> - Fold08: mtry= 6  #> + Fold08: mtry=11  #> - Fold08: mtry=11  #> + Fold09: mtry= 2  #> - Fold09: mtry= 2  #> + Fold09: mtry= 6  #> - Fold09: mtry= 6  #> + Fold09: mtry=11  #> - Fold09: mtry=11  #> + Fold10: mtry= 2  #> - Fold10: mtry= 2  #> + Fold10: mtry= 6  #> - Fold10: mtry= 6  #> + Fold10: mtry=11  #> - Fold10: mtry=11  #> Aggregating results #> Selecting tuning parameters #> Fitting mtry = 11 on full training set #> + Fold01: mtry= 2  #> - Fold01: mtry= 2  #> + Fold01: mtry= 6  #> - Fold01: mtry= 6  #> + Fold01: mtry=11  #> - Fold01: mtry=11  #> + Fold02: mtry= 2  #> - Fold02: mtry= 2  #> + Fold02: mtry= 6  #> - Fold02: mtry= 6  #> + Fold02: mtry=11  #> - Fold02: mtry=11  #> + Fold03: mtry= 2  #> - Fold03: mtry= 2  #> + Fold03: mtry= 6  #> - Fold03: mtry= 6  #> + Fold03: mtry=11  #> - Fold03: mtry=11  #> + Fold04: mtry= 2  #> - Fold04: mtry= 2  #> + Fold04: mtry= 6  #> - Fold04: mtry= 6  #> + Fold04: mtry=11  #> - Fold04: mtry=11  #> + Fold05: mtry= 2  #> - Fold05: mtry= 2  #> + Fold05: mtry= 6  #> - Fold05: mtry= 6  #> + Fold05: mtry=11  #> - Fold05: mtry=11  #> + Fold06: mtry= 2  #> - Fold06: mtry= 2  #> + Fold06: mtry= 6  #> - Fold06: mtry= 6  #> + Fold06: mtry=11  #> - Fold06: mtry=11  #> + Fold07: mtry= 2  #> - Fold07: mtry= 2  #> + Fold07: mtry= 6  #> - Fold07: mtry= 6  #> + Fold07: mtry=11  #> - Fold07: mtry=11  #> + Fold08: mtry= 2  #> - Fold08: mtry= 2  #> + Fold08: mtry= 6  #> - Fold08: mtry= 6  #> + Fold08: mtry=11  #> - Fold08: mtry=11  #> + Fold09: mtry= 2  #> - Fold09: mtry= 2  #> + Fold09: mtry= 6  #> - Fold09: mtry= 6  #> + Fold09: mtry=11  #> - Fold09: mtry=11  #> + Fold10: mtry= 2  #> - Fold10: mtry= 2  #> + Fold10: mtry= 6  #> - Fold10: mtry= 6  #> + Fold10: mtry=11  #> - Fold10: mtry=11  #> Aggregating results #> Selecting tuning parameters #> Fitting mtry = 2 on full training set #> + Fold01: mtry= 2  #> - Fold01: mtry= 2  #> + Fold01: mtry= 6  #> - Fold01: mtry= 6  #> + Fold01: mtry=11  #> - Fold01: mtry=11  #> + Fold02: mtry= 2  #> - Fold02: mtry= 2  #> + Fold02: mtry= 6  #> - Fold02: mtry= 6  #> + Fold02: mtry=11  #> - Fold02: mtry=11  #> + Fold03: mtry= 2  #> - Fold03: mtry= 2  #> + Fold03: mtry= 6  #> - Fold03: mtry= 6  #> + Fold03: mtry=11  #> - Fold03: mtry=11  #> + Fold04: mtry= 2  #> - Fold04: mtry= 2  #> + Fold04: mtry= 6  #> - Fold04: mtry= 6  #> + Fold04: mtry=11  #> - Fold04: mtry=11  #> + Fold05: mtry= 2  #> - Fold05: mtry= 2  #> + Fold05: mtry= 6  #> - Fold05: mtry= 6  #> + Fold05: mtry=11  #> - Fold05: mtry=11  #> + Fold06: mtry= 2  #> - Fold06: mtry= 2  #> + Fold06: mtry= 6  #> - Fold06: mtry= 6  #> + Fold06: mtry=11  #> - Fold06: mtry=11  #> + Fold07: mtry= 2  #> - Fold07: mtry= 2  #> + Fold07: mtry= 6  #> - Fold07: mtry= 6  #> + Fold07: mtry=11  #> - Fold07: mtry=11  #> + Fold08: mtry= 2  #> - Fold08: mtry= 2  #> + Fold08: mtry= 6  #> - Fold08: mtry= 6  #> + Fold08: mtry=11  #> - Fold08: mtry=11  #> + Fold09: mtry= 2  #> - Fold09: mtry= 2  #> + Fold09: mtry= 6  #> - Fold09: mtry= 6  #> + Fold09: mtry=11  #> - Fold09: mtry=11  #> + Fold10: mtry= 2  #> - Fold10: mtry= 2  #> + Fold10: mtry= 6  #> - Fold10: mtry= 6  #> + Fold10: mtry=11  #> - Fold10: mtry=11  #> Aggregating results #> Selecting tuning parameters #> Fitting mtry = 6 on full training set #> + Fold01: mtry= 2  #> - Fold01: mtry= 2  #> + Fold01: mtry= 6  #> - Fold01: mtry= 6  #> + Fold01: mtry=11  #> - Fold01: mtry=11  #> + Fold02: mtry= 2  #> - Fold02: mtry= 2  #> + Fold02: mtry= 6  #> - Fold02: mtry= 6  #> + Fold02: mtry=11  #> - Fold02: mtry=11  #> + Fold03: mtry= 2  #> - Fold03: mtry= 2  #> + Fold03: mtry= 6  #> - Fold03: mtry= 6  #> + Fold03: mtry=11  #> - Fold03: mtry=11  #> + Fold04: mtry= 2  #> - Fold04: mtry= 2  #> + Fold04: mtry= 6  #> - Fold04: mtry= 6  #> + Fold04: mtry=11  #> - Fold04: mtry=11  #> + Fold05: mtry= 2  #> - Fold05: mtry= 2  #> + Fold05: mtry= 6  #> - Fold05: mtry= 6  #> + Fold05: mtry=11  #> - Fold05: mtry=11  #> + Fold06: mtry= 2  #> - Fold06: mtry= 2  #> + Fold06: mtry= 6  #> - Fold06: mtry= 6  #> + Fold06: mtry=11  #> - Fold06: mtry=11  #> + Fold07: mtry= 2  #> - Fold07: mtry= 2  #> + Fold07: mtry= 6  #> - Fold07: mtry= 6  #> + Fold07: mtry=11  #> - Fold07: mtry=11  #> + Fold08: mtry= 2  #> - Fold08: mtry= 2  #> + Fold08: mtry= 6  #> - Fold08: mtry= 6  #> + Fold08: mtry=11  #> - Fold08: mtry=11  #> + Fold09: mtry= 2  #> - Fold09: mtry= 2  #> + Fold09: mtry= 6  #> - Fold09: mtry= 6  #> + Fold09: mtry=11  #> - Fold09: mtry=11  #> + Fold10: mtry= 2  #> - Fold10: mtry= 2  #> + Fold10: mtry= 6  #> - Fold10: mtry= 6  #> + Fold10: mtry=11  #> - Fold10: mtry=11  #> Aggregating results #> Selecting tuning parameters #> Fitting mtry = 2 on full training set #> + Fold01: mtry= 2  #> - Fold01: mtry= 2  #> + Fold01: mtry= 6  #> - Fold01: mtry= 6  #> + Fold01: mtry=11  #> - Fold01: mtry=11  #> + Fold02: mtry= 2  #> - Fold02: mtry= 2  #> + Fold02: mtry= 6  #> - Fold02: mtry= 6  #> + Fold02: mtry=11  #> - Fold02: mtry=11  #> + Fold03: mtry= 2  #> - Fold03: mtry= 2  #> + Fold03: mtry= 6  #> - Fold03: mtry= 6  #> + Fold03: mtry=11  #> - Fold03: mtry=11  #> + Fold04: mtry= 2  #> - Fold04: mtry= 2  #> + Fold04: mtry= 6  #> - Fold04: mtry= 6  #> + Fold04: mtry=11  #> - Fold04: mtry=11  #> + Fold05: mtry= 2  #> - Fold05: mtry= 2  #> + Fold05: mtry= 6  #> - Fold05: mtry= 6  #> + Fold05: mtry=11  #> - Fold05: mtry=11  #> + Fold06: mtry= 2  #> - Fold06: mtry= 2  #> + Fold06: mtry= 6  #> - Fold06: mtry= 6  #> + Fold06: mtry=11  #> - Fold06: mtry=11  #> + Fold07: mtry= 2  #> - Fold07: mtry= 2  #> + Fold07: mtry= 6  #> - Fold07: mtry= 6  #> + Fold07: mtry=11  #> - Fold07: mtry=11  #> + Fold08: mtry= 2  #> - Fold08: mtry= 2  #> + Fold08: mtry= 6  #> - Fold08: mtry= 6  #> + Fold08: mtry=11  #> - Fold08: mtry=11  #> + Fold09: mtry= 2  #> - Fold09: mtry= 2  #> + Fold09: mtry= 6  #> - Fold09: mtry= 6  #> + Fold09: mtry=11  #> - Fold09: mtry=11  #> + Fold10: mtry= 2  #> - Fold10: mtry= 2  #> + Fold10: mtry= 6  #> - Fold10: mtry= 6  #> + Fold10: mtry=11  #> - Fold10: mtry=11  #> Aggregating results #> Selecting tuning parameters #> Fitting mtry = 2 on full training set #> + Fold01: mtry= 2  #> - Fold01: mtry= 2  #> + Fold01: mtry= 6  #> - Fold01: mtry= 6  #> + Fold01: mtry=11  #> - Fold01: mtry=11  #> + Fold02: mtry= 2  #> - Fold02: mtry= 2  #> + Fold02: mtry= 6  #> - Fold02: mtry= 6  #> + Fold02: mtry=11  #> - Fold02: mtry=11  #> + Fold03: mtry= 2  #> - Fold03: mtry= 2  #> + Fold03: mtry= 6  #> - Fold03: mtry= 6  #> + Fold03: mtry=11  #> - Fold03: mtry=11  #> + Fold04: mtry= 2  #> - Fold04: mtry= 2  #> + Fold04: mtry= 6  #> - Fold04: mtry= 6  #> + Fold04: mtry=11  #> - Fold04: mtry=11  #> + Fold05: mtry= 2  #> - Fold05: mtry= 2  #> + Fold05: mtry= 6  #> - Fold05: mtry= 6  #> + Fold05: mtry=11  #> - Fold05: mtry=11  #> + Fold06: mtry= 2  #> - Fold06: mtry= 2  #> + Fold06: mtry= 6  #> - Fold06: mtry= 6  #> + Fold06: mtry=11  #> - Fold06: mtry=11  #> + Fold07: mtry= 2  #> - Fold07: mtry= 2  #> + Fold07: mtry= 6  #> - Fold07: mtry= 6  #> + Fold07: mtry=11  #> - Fold07: mtry=11  #> + Fold08: mtry= 2  #> - Fold08: mtry= 2  #> + Fold08: mtry= 6  #> - Fold08: mtry= 6  #> + Fold08: mtry=11  #> - Fold08: mtry=11  #> + Fold09: mtry= 2  #> - Fold09: mtry= 2  #> + Fold09: mtry= 6  #> - Fold09: mtry= 6  #> + Fold09: mtry=11  #> - Fold09: mtry=11  #> + Fold10: mtry= 2  #> - Fold10: mtry= 2  #> + Fold10: mtry= 6  #> - Fold10: mtry= 6  #> + Fold10: mtry=11  #> - Fold10: mtry=11  #> Aggregating results #> Selecting tuning parameters #> Fitting mtry = 2 on full training set #> + Fold01: mtry= 2  #> - Fold01: mtry= 2  #> + Fold01: mtry= 6  #> - Fold01: mtry= 6  #> + Fold01: mtry=11  #> - Fold01: mtry=11  #> + Fold02: mtry= 2  #> - Fold02: mtry= 2  #> + Fold02: mtry= 6  #> - Fold02: mtry= 6  #> + Fold02: mtry=11  #> - Fold02: mtry=11  #> + Fold03: mtry= 2  #> - Fold03: mtry= 2  #> + Fold03: mtry= 6  #> - Fold03: mtry= 6  #> + Fold03: mtry=11  #> - Fold03: mtry=11  #> + Fold04: mtry= 2  #> - Fold04: mtry= 2  #> + Fold04: mtry= 6  #> - Fold04: mtry= 6  #> + Fold04: mtry=11  #> - Fold04: mtry=11  #> + Fold05: mtry= 2  #> - Fold05: mtry= 2  #> + Fold05: mtry= 6  #> - Fold05: mtry= 6  #> + Fold05: mtry=11  #> - Fold05: mtry=11  #> + Fold06: mtry= 2  #> - Fold06: mtry= 2  #> + Fold06: mtry= 6  #> - Fold06: mtry= 6  #> + Fold06: mtry=11  #> - Fold06: mtry=11  #> + Fold07: mtry= 2  #> - Fold07: mtry= 2  #> + Fold07: mtry= 6  #> - Fold07: mtry= 6  #> + Fold07: mtry=11  #> - Fold07: mtry=11  #> + Fold08: mtry= 2  #> - Fold08: mtry= 2  #> + Fold08: mtry= 6  #> - Fold08: mtry= 6  #> + Fold08: mtry=11  #> - Fold08: mtry=11  #> + Fold09: mtry= 2  #> - Fold09: mtry= 2  #> + Fold09: mtry= 6  #> - Fold09: mtry= 6  #> + Fold09: mtry=11  #> - Fold09: mtry=11  #> + Fold10: mtry= 2  #> - Fold10: mtry= 2  #> + Fold10: mtry= 6  #> - Fold10: mtry= 6  #> + Fold10: mtry=11  #> - Fold10: mtry=11  #> Aggregating results #> Selecting tuning parameters #> Fitting mtry = 2 on full training set #> + Fold01: mtry= 2  #> - Fold01: mtry= 2  #> + Fold01: mtry= 6  #> - Fold01: mtry= 6  #> + Fold01: mtry=11  #> - Fold01: mtry=11  #> + Fold02: mtry= 2  #> - Fold02: mtry= 2  #> + Fold02: mtry= 6  #> - Fold02: mtry= 6  #> + Fold02: mtry=11  #> - Fold02: mtry=11  #> + Fold03: mtry= 2  #> - Fold03: mtry= 2  #> + Fold03: mtry= 6  #> - Fold03: mtry= 6  #> + Fold03: mtry=11  #> - Fold03: mtry=11  #> + Fold04: mtry= 2  #> - Fold04: mtry= 2  #> + Fold04: mtry= 6  #> - Fold04: mtry= 6  #> + Fold04: mtry=11  #> - Fold04: mtry=11  #> + Fold05: mtry= 2  #> - Fold05: mtry= 2  #> + Fold05: mtry= 6  #> - Fold05: mtry= 6  #> + Fold05: mtry=11  #> - Fold05: mtry=11  #> + Fold06: mtry= 2  #> - Fold06: mtry= 2  #> + Fold06: mtry= 6  #> - Fold06: mtry= 6  #> + Fold06: mtry=11  #> - Fold06: mtry=11  #> + Fold07: mtry= 2  #> - Fold07: mtry= 2  #> + Fold07: mtry= 6  #> - Fold07: mtry= 6  #> + Fold07: mtry=11  #> - Fold07: mtry=11  #> + Fold08: mtry= 2  #> - Fold08: mtry= 2  #> + Fold08: mtry= 6  #> - Fold08: mtry= 6  #> + Fold08: mtry=11  #> - Fold08: mtry=11  #> + Fold09: mtry= 2  #> - Fold09: mtry= 2  #> + Fold09: mtry= 6  #> - Fold09: mtry= 6  #> + Fold09: mtry=11  #> - Fold09: mtry=11  #> + Fold10: mtry= 2  #> - Fold10: mtry= 2  #> + Fold10: mtry= 6  #> - Fold10: mtry= 6  #> + Fold10: mtry=11  #> - Fold10: mtry=11  #> Aggregating results #> Selecting tuning parameters #> Fitting mtry = 2 on full training set #> + Fold01: mtry= 2  #> - Fold01: mtry= 2  #> + Fold01: mtry= 6  #> - Fold01: mtry= 6  #> + Fold01: mtry=11  #> - Fold01: mtry=11  #> + Fold02: mtry= 2  #> - Fold02: mtry= 2  #> + Fold02: mtry= 6  #> - Fold02: mtry= 6  #> + Fold02: mtry=11  #> - Fold02: mtry=11  #> + Fold03: mtry= 2  #> - Fold03: mtry= 2  #> + Fold03: mtry= 6  #> - Fold03: mtry= 6  #> + Fold03: mtry=11  #> - Fold03: mtry=11  #> + Fold04: mtry= 2  #> - Fold04: mtry= 2  #> + Fold04: mtry= 6  #> - Fold04: mtry= 6  #> + Fold04: mtry=11  #> - Fold04: mtry=11  #> + Fold05: mtry= 2  #> - Fold05: mtry= 2  #> + Fold05: mtry= 6  #> - Fold05: mtry= 6  #> + Fold05: mtry=11  #> - Fold05: mtry=11  #> + Fold06: mtry= 2  #> - Fold06: mtry= 2  #> + Fold06: mtry= 6  #> - Fold06: mtry= 6  #> + Fold06: mtry=11  #> - Fold06: mtry=11  #> + Fold07: mtry= 2  #> - Fold07: mtry= 2  #> + Fold07: mtry= 6  #> - Fold07: mtry= 6  #> + Fold07: mtry=11  #> - Fold07: mtry=11  #> + Fold08: mtry= 2  #> - Fold08: mtry= 2  #> + Fold08: mtry= 6  #> - Fold08: mtry= 6  #> + Fold08: mtry=11  #> - Fold08: mtry=11  #> + Fold09: mtry= 2  #> - Fold09: mtry= 2  #> + Fold09: mtry= 6  #> - Fold09: mtry= 6  #> + Fold09: mtry=11  #> - Fold09: mtry=11  #> + Fold10: mtry= 2  #> - Fold10: mtry= 2  #> + Fold10: mtry= 6  #> - Fold10: mtry= 6  #> + Fold10: mtry=11  #> - Fold10: mtry=11  #> Aggregating results #> Selecting tuning parameters #> Fitting mtry = 2 on full training set"},{"path":"https://seymakalay.github.io/pomodoro/articles/Pomodoro_Vignette.html","id":"combined_performance","dir":"Articles","previous_headings":"","what":"Combined_Performance","title":"Pomodoro_Vignette","text":"Estimate_Models gives results based splits exog. Combined_Performance prints total performance splits.","code":"Sub.CCP.RF <- list(Mdl.1 = CCP.RF$EstMdl$`D.1+networth`, Mdl.0 = CCP.RF$EstMdl$`D.0+networth`) CCP.NoCCP.RF <- Combined_Performance (Sub.CCP.RF)"},{"path":"https://seymakalay.github.io/pomodoro/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Seyma Kalay. Maintainer.","code":""},{"path":"https://seymakalay.github.io/pomodoro/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Kalay S (2022). pomodoro: Predictive Power Linear Tree Modeling. https://github.com/seymakalay/pomodoro, https://seymakalay.github.io/pomodoro/.","code":"@Manual{,   title = {pomodoro: Predictive Power of Linear and Tree Modeling},   author = {Seyma Kalay},   year = {2022},   note = {https://github.com/seymakalay/pomodoro, https://seymakalay.github.io/pomodoro/}, }"},{"path":"https://seymakalay.github.io/pomodoro/index.html","id":"pomodoro","dir":"","previous_headings":"","what":"Predictive Power of Linear and Tree Modeling","title":"Predictive Power of Linear and Tree Modeling","text":"goal pomodoro provide functions make predictive modeling easy.","code":""},{"path":"https://seymakalay.github.io/pomodoro/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Predictive Power of Linear and Tree Modeling","text":"can install released version pomodoro CRAN :","code":"install.packages(\"pomodoro\") library(pomodoro)"},{"path":"https://seymakalay.github.io/pomodoro/index.html","id":"overview","dir":"","previous_headings":"","what":"Overview","title":"Predictive Power of Linear and Tree Modeling","text":"Runs bagging, boosting, random forest, multinominal logistic logistic models. purpose package report predictive modelling results ease.","code":""},{"path":"https://seymakalay.github.io/pomodoro/reference/BAG_Model.html","id":null,"dir":"Reference","previous_headings":"","what":"Bagging Model — BAG_Model","title":"Bagging Model — BAG_Model","text":"Bagging Model","code":""},{"path":"https://seymakalay.github.io/pomodoro/reference/BAG_Model.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Bagging Model — BAG_Model","text":"","code":"BAG_Model(Data, xvar, yvar)"},{"path":"https://seymakalay.github.io/pomodoro/reference/BAG_Model.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Bagging Model — BAG_Model","text":"Data name Dataset. xvar X variables. yvar Y variable.","code":""},{"path":"https://seymakalay.github.io/pomodoro/reference/BAG_Model.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Bagging Model — BAG_Model","text":"output  BAG_Model.","code":""},{"path":"https://seymakalay.github.io/pomodoro/reference/BAG_Model.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Bagging Model — BAG_Model","text":"Decision trees suffer high variance (split training data-set randomly two parts set decision tree parts, results might quite different). Bagging ensemble procedure reduces variance increases prediction accuracy statistical learning method considering many training sets (\\(\\hat{f}^{1}(x),\\hat{f}^{2}(x),\\ldots,\\hat{f}^{B}(x)\\)) population. Since can multiple training-sets, single training data-set, can generate \\(B\\) different bootstrapped training data-sets (\\(\\hat{f}^{*1}(x), \\hat{f}^{*2}(x), \\ldots,\\hat{f}^{*B}(x)\\)) \\(B\\) trees take majority vote. Therefore, bagging classification problem  defined  $$\\hat{f}(x)=arg\\max_{k}\\hat{f}^{*b}(x)$$","code":""},{"path":"https://seymakalay.github.io/pomodoro/reference/BAG_Model.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Bagging Model — BAG_Model","text":"","code":"# \\donttest{ yvar <- c(\"Loan.Type\") sample_data <- sample_data[c(1:750),] xvar <- c(\"sex\", \"married\", \"age\", \"havejob\", \"educ\", \"political.afl\", \"rural\", \"region\", \"fin.intermdiaries\", \"fin.knowldge\", \"income\") BchMk.BAG <- BAG_Model(sample_data, c(xvar, \"networth\"), yvar ) #> Loading required package: ggplot2 #> Loading required package: lattice #> + Fold01: parameter=none  #> - Fold01: parameter=none  #> + Fold02: parameter=none  #> - Fold02: parameter=none  #> + Fold03: parameter=none  #> - Fold03: parameter=none  #> + Fold04: parameter=none  #> - Fold04: parameter=none  #> + Fold05: parameter=none  #> - Fold05: parameter=none  #> + Fold06: parameter=none  #> - Fold06: parameter=none  #> + Fold07: parameter=none  #> - Fold07: parameter=none  #> + Fold08: parameter=none  #> - Fold08: parameter=none  #> + Fold09: parameter=none  #> - Fold09: parameter=none  #> + Fold10: parameter=none  #> - Fold10: parameter=none  #> Aggregating results #> Fitting final model on full training set BchMk.BAG$Roc$auc #> Multi-class area under the curve: 0.6906 # }"},{"path":"https://seymakalay.github.io/pomodoro/reference/Combined_Performance.html","id":null,"dir":"Reference","previous_headings":"","what":"Combined Performance of the Data Splits — Combined_Performance","title":"Combined Performance of the Data Splits — Combined_Performance","text":"Combined Performance Data Splits","code":""},{"path":"https://seymakalay.github.io/pomodoro/reference/Combined_Performance.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Combined Performance of the Data Splits — Combined_Performance","text":"","code":"Combined_Performance(Sub.Est.Mdls)"},{"path":"https://seymakalay.github.io/pomodoro/reference/Combined_Performance.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Combined Performance of the Data Splits — Combined_Performance","text":"Sub.Est.Mdls total perfomance exog.","code":""},{"path":"https://seymakalay.github.io/pomodoro/reference/Combined_Performance.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Combined Performance of the Data Splits — Combined_Performance","text":"output  Combined_Performance.","code":""},{"path":"https://seymakalay.github.io/pomodoro/reference/Combined_Performance.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Combined Performance of the Data Splits — Combined_Performance","text":"","code":"# \\donttest{ sample_data <- sample_data[c(1:750),] yvar <- c(\"Loan.Type\") xvar <- c(\"sex\", \"married\", \"age\", \"havejob\", \"educ\", \"political.afl\", \"rural\", \"region\", \"fin.intermdiaries\", \"fin.knowldge\", \"income\") CCP.RF <- Estimate_Models(sample_data, yvar, xvec = xvar, exog = \"political.afl\", xadd = c(\"networth\", \"networth_homequity\", \"liquid.assets\"), type = \"RF\", dnames = c(\"0\",\"1\")) #> + Fold01: mtry= 2  #> - Fold01: mtry= 2  #> + Fold01: mtry= 6  #> - Fold01: mtry= 6  #> + Fold01: mtry=11  #> - Fold01: mtry=11  #> + Fold02: mtry= 2  #> - Fold02: mtry= 2  #> + Fold02: mtry= 6  #> - Fold02: mtry= 6  #> + Fold02: mtry=11  #> - Fold02: mtry=11  #> + Fold03: mtry= 2  #> - Fold03: mtry= 2  #> + Fold03: mtry= 6  #> - Fold03: mtry= 6  #> + Fold03: mtry=11  #> - Fold03: mtry=11  #> + Fold04: mtry= 2  #> - Fold04: mtry= 2  #> + Fold04: mtry= 6  #> - Fold04: mtry= 6  #> + Fold04: mtry=11  #> - Fold04: mtry=11  #> + Fold05: mtry= 2  #> - Fold05: mtry= 2  #> + Fold05: mtry= 6  #> - Fold05: mtry= 6  #> + Fold05: mtry=11  #> - Fold05: mtry=11  #> + Fold06: mtry= 2  #> - Fold06: mtry= 2  #> + Fold06: mtry= 6  #> - Fold06: mtry= 6  #> + Fold06: mtry=11  #> - Fold06: mtry=11  #> + Fold07: mtry= 2  #> - Fold07: mtry= 2  #> + Fold07: mtry= 6  #> - Fold07: mtry= 6  #> + Fold07: mtry=11  #> - Fold07: mtry=11  #> + Fold08: mtry= 2  #> - Fold08: mtry= 2  #> + Fold08: mtry= 6  #> - Fold08: mtry= 6  #> + Fold08: mtry=11  #> - Fold08: mtry=11  #> + Fold09: mtry= 2  #> - Fold09: mtry= 2  #> + Fold09: mtry= 6  #> - Fold09: mtry= 6  #> + Fold09: mtry=11  #> - Fold09: mtry=11  #> + Fold10: mtry= 2  #> - Fold10: mtry= 2  #> + Fold10: mtry= 6  #> - Fold10: mtry= 6  #> + Fold10: mtry=11  #> - Fold10: mtry=11  #> Aggregating results #> Selecting tuning parameters #> Fitting mtry = 2 on full training set #> + Fold01: mtry= 2  #> - Fold01: mtry= 2  #> + Fold01: mtry= 6  #> - Fold01: mtry= 6  #> + Fold01: mtry=11  #> - Fold01: mtry=11  #> + Fold02: mtry= 2  #> - Fold02: mtry= 2  #> + Fold02: mtry= 6  #> - Fold02: mtry= 6  #> + Fold02: mtry=11  #> - Fold02: mtry=11  #> + Fold03: mtry= 2  #> - Fold03: mtry= 2  #> + Fold03: mtry= 6  #> - Fold03: mtry= 6  #> + Fold03: mtry=11  #> - Fold03: mtry=11  #> + Fold04: mtry= 2  #> - Fold04: mtry= 2  #> + Fold04: mtry= 6  #> - Fold04: mtry= 6  #> + Fold04: mtry=11  #> - Fold04: mtry=11  #> + Fold05: mtry= 2  #> - Fold05: mtry= 2  #> + Fold05: mtry= 6  #> - Fold05: mtry= 6  #> + Fold05: mtry=11  #> - Fold05: mtry=11  #> + Fold06: mtry= 2  #> - Fold06: mtry= 2  #> + Fold06: mtry= 6  #> - Fold06: mtry= 6  #> + Fold06: mtry=11  #> - Fold06: mtry=11  #> + Fold07: mtry= 2  #> - Fold07: mtry= 2  #> + Fold07: mtry= 6  #> - Fold07: mtry= 6  #> + Fold07: mtry=11  #> - Fold07: mtry=11  #> + Fold08: mtry= 2  #> - Fold08: mtry= 2  #> + Fold08: mtry= 6  #> - Fold08: mtry= 6  #> + Fold08: mtry=11  #> - Fold08: mtry=11  #> + Fold09: mtry= 2  #> - Fold09: mtry= 2  #> + Fold09: mtry= 6  #> - Fold09: mtry= 6  #> + Fold09: mtry=11  #> - Fold09: mtry=11  #> + Fold10: mtry= 2  #> - Fold10: mtry= 2  #> + Fold10: mtry= 6  #> - Fold10: mtry= 6  #> + Fold10: mtry=11  #> - Fold10: mtry=11  #> Aggregating results #> Selecting tuning parameters #> Fitting mtry = 2 on full training set #> + Fold01: mtry= 2  #> - Fold01: mtry= 2  #> + Fold01: mtry= 6  #> - Fold01: mtry= 6  #> + Fold01: mtry=11  #> - Fold01: mtry=11  #> + Fold02: mtry= 2  #> - Fold02: mtry= 2  #> + Fold02: mtry= 6  #> - Fold02: mtry= 6  #> + Fold02: mtry=11  #> - Fold02: mtry=11  #> + Fold03: mtry= 2  #> - Fold03: mtry= 2  #> + Fold03: mtry= 6  #> - Fold03: mtry= 6  #> + Fold03: mtry=11  #> - Fold03: mtry=11  #> + Fold04: mtry= 2  #> - Fold04: mtry= 2  #> + Fold04: mtry= 6  #> - Fold04: mtry= 6  #> + Fold04: mtry=11  #> - Fold04: mtry=11  #> + Fold05: mtry= 2  #> - Fold05: mtry= 2  #> + Fold05: mtry= 6  #> - Fold05: mtry= 6  #> + Fold05: mtry=11  #> - Fold05: mtry=11  #> + Fold06: mtry= 2  #> - Fold06: mtry= 2  #> + Fold06: mtry= 6  #> - Fold06: mtry= 6  #> + Fold06: mtry=11  #> - Fold06: mtry=11  #> + Fold07: mtry= 2  #> - Fold07: mtry= 2  #> + Fold07: mtry= 6  #> - Fold07: mtry= 6  #> + Fold07: mtry=11  #> - Fold07: mtry=11  #> + Fold08: mtry= 2  #> - Fold08: mtry= 2  #> + Fold08: mtry= 6  #> - Fold08: mtry= 6  #> + Fold08: mtry=11  #> - Fold08: mtry=11  #> + Fold09: mtry= 2  #> - Fold09: mtry= 2  #> + Fold09: mtry= 6  #> - Fold09: mtry= 6  #> + Fold09: mtry=11  #> - Fold09: mtry=11  #> + Fold10: mtry= 2  #> - Fold10: mtry= 2  #> + Fold10: mtry= 6  #> - Fold10: mtry= 6  #> + Fold10: mtry=11  #> - Fold10: mtry=11  #> Aggregating results #> Selecting tuning parameters #> Fitting mtry = 6 on full training set #> + Fold01: mtry= 2  #> - Fold01: mtry= 2  #> + Fold01: mtry= 6  #> - Fold01: mtry= 6  #> + Fold01: mtry=11  #> - Fold01: mtry=11  #> + Fold02: mtry= 2  #> - Fold02: mtry= 2  #> + Fold02: mtry= 6  #> - Fold02: mtry= 6  #> + Fold02: mtry=11  #> - Fold02: mtry=11  #> + Fold03: mtry= 2  #> - Fold03: mtry= 2  #> + Fold03: mtry= 6  #> - Fold03: mtry= 6  #> + Fold03: mtry=11  #> - Fold03: mtry=11  #> + Fold04: mtry= 2  #> - Fold04: mtry= 2  #> + Fold04: mtry= 6  #> - Fold04: mtry= 6  #> + Fold04: mtry=11  #> - Fold04: mtry=11  #> + Fold05: mtry= 2  #> - Fold05: mtry= 2  #> + Fold05: mtry= 6  #> - Fold05: mtry= 6  #> + Fold05: mtry=11  #> - Fold05: mtry=11  #> + Fold06: mtry= 2  #> - Fold06: mtry= 2  #> + Fold06: mtry= 6  #> - Fold06: mtry= 6  #> + Fold06: mtry=11  #> - Fold06: mtry=11  #> + Fold07: mtry= 2  #> - Fold07: mtry= 2  #> + Fold07: mtry= 6  #> - Fold07: mtry= 6  #> + Fold07: mtry=11  #> - Fold07: mtry=11  #> + Fold08: mtry= 2  #> - Fold08: mtry= 2  #> + Fold08: mtry= 6  #> - Fold08: mtry= 6  #> + Fold08: mtry=11  #> - Fold08: mtry=11  #> + Fold09: mtry= 2  #> - Fold09: mtry= 2  #> + Fold09: mtry= 6  #> - Fold09: mtry= 6  #> + Fold09: mtry=11  #> - Fold09: mtry=11  #> + Fold10: mtry= 2  #> - Fold10: mtry= 2  #> + Fold10: mtry= 6  #> - Fold10: mtry= 6  #> + Fold10: mtry=11  #> - Fold10: mtry=11  #> Aggregating results #> Selecting tuning parameters #> Fitting mtry = 2 on full training set #> + Fold01: mtry= 2  #> - Fold01: mtry= 2  #> + Fold01: mtry= 6  #> - Fold01: mtry= 6  #> + Fold01: mtry=11  #> - Fold01: mtry=11  #> + Fold02: mtry= 2  #> - Fold02: mtry= 2  #> + Fold02: mtry= 6  #> - Fold02: mtry= 6  #> + Fold02: mtry=11  #> - Fold02: mtry=11  #> + Fold03: mtry= 2  #> - Fold03: mtry= 2  #> + Fold03: mtry= 6  #> - Fold03: mtry= 6  #> + Fold03: mtry=11  #> - Fold03: mtry=11  #> + Fold04: mtry= 2  #> - Fold04: mtry= 2  #> + Fold04: mtry= 6  #> - Fold04: mtry= 6  #> + Fold04: mtry=11  #> - Fold04: mtry=11  #> + Fold05: mtry= 2  #> - Fold05: mtry= 2  #> + Fold05: mtry= 6  #> - Fold05: mtry= 6  #> + Fold05: mtry=11  #> - Fold05: mtry=11  #> + Fold06: mtry= 2  #> - Fold06: mtry= 2  #> + Fold06: mtry= 6  #> - Fold06: mtry= 6  #> + Fold06: mtry=11  #> - Fold06: mtry=11  #> + Fold07: mtry= 2  #> - Fold07: mtry= 2  #> + Fold07: mtry= 6  #> - Fold07: mtry= 6  #> + Fold07: mtry=11  #> - Fold07: mtry=11  #> + Fold08: mtry= 2  #> - Fold08: mtry= 2  #> + Fold08: mtry= 6  #> - Fold08: mtry= 6  #> + Fold08: mtry=11  #> - Fold08: mtry=11  #> + Fold09: mtry= 2  #> - Fold09: mtry= 2  #> + Fold09: mtry= 6  #> - Fold09: mtry= 6  #> + Fold09: mtry=11  #> - Fold09: mtry=11  #> + Fold10: mtry= 2  #> - Fold10: mtry= 2  #> + Fold10: mtry= 6  #> - Fold10: mtry= 6  #> + Fold10: mtry=11  #> - Fold10: mtry=11  #> Aggregating results #> Selecting tuning parameters #> Fitting mtry = 2 on full training set #> + Fold01: mtry= 2  #> - Fold01: mtry= 2  #> + Fold01: mtry= 6  #> - Fold01: mtry= 6  #> + Fold01: mtry=11  #> - Fold01: mtry=11  #> + Fold02: mtry= 2  #> - Fold02: mtry= 2  #> + Fold02: mtry= 6  #> - Fold02: mtry= 6  #> + Fold02: mtry=11  #> - Fold02: mtry=11  #> + Fold03: mtry= 2  #> - Fold03: mtry= 2  #> + Fold03: mtry= 6  #> - Fold03: mtry= 6  #> + Fold03: mtry=11  #> - Fold03: mtry=11  #> + Fold04: mtry= 2  #> - Fold04: mtry= 2  #> + Fold04: mtry= 6  #> - Fold04: mtry= 6  #> + Fold04: mtry=11  #> - Fold04: mtry=11  #> + Fold05: mtry= 2  #> - Fold05: mtry= 2  #> + Fold05: mtry= 6  #> - Fold05: mtry= 6  #> + Fold05: mtry=11  #> - Fold05: mtry=11  #> + Fold06: mtry= 2  #> - Fold06: mtry= 2  #> + Fold06: mtry= 6  #> - Fold06: mtry= 6  #> + Fold06: mtry=11  #> - Fold06: mtry=11  #> + Fold07: mtry= 2  #> - Fold07: mtry= 2  #> + Fold07: mtry= 6  #> - Fold07: mtry= 6  #> + Fold07: mtry=11  #> - Fold07: mtry=11  #> + Fold08: mtry= 2  #> - Fold08: mtry= 2  #> + Fold08: mtry= 6  #> - Fold08: mtry= 6  #> + Fold08: mtry=11  #> - Fold08: mtry=11  #> + Fold09: mtry= 2  #> - Fold09: mtry= 2  #> + Fold09: mtry= 6  #> - Fold09: mtry= 6  #> + Fold09: mtry=11  #> - Fold09: mtry=11  #> + Fold10: mtry= 2  #> - Fold10: mtry= 2  #> + Fold10: mtry= 6  #> - Fold10: mtry= 6  #> + Fold10: mtry=11  #> - Fold10: mtry=11  #> Aggregating results #> Selecting tuning parameters #> Fitting mtry = 2 on full training set #> + Fold01: mtry= 2  #> - Fold01: mtry= 2  #> + Fold01: mtry= 6  #> - Fold01: mtry= 6  #> + Fold01: mtry=11  #> - Fold01: mtry=11  #> + Fold02: mtry= 2  #> - Fold02: mtry= 2  #> + Fold02: mtry= 6  #> - Fold02: mtry= 6  #> + Fold02: mtry=11  #> - Fold02: mtry=11  #> + Fold03: mtry= 2  #> - Fold03: mtry= 2  #> + Fold03: mtry= 6  #> - Fold03: mtry= 6  #> + Fold03: mtry=11  #> - Fold03: mtry=11  #> + Fold04: mtry= 2  #> - Fold04: mtry= 2  #> + Fold04: mtry= 6  #> - Fold04: mtry= 6  #> + Fold04: mtry=11  #> - Fold04: mtry=11  #> + Fold05: mtry= 2  #> - Fold05: mtry= 2  #> + Fold05: mtry= 6  #> - Fold05: mtry= 6  #> + Fold05: mtry=11  #> - Fold05: mtry=11  #> + Fold06: mtry= 2  #> - Fold06: mtry= 2  #> + Fold06: mtry= 6  #> - Fold06: mtry= 6  #> + Fold06: mtry=11  #> - Fold06: mtry=11  #> + Fold07: mtry= 2  #> - Fold07: mtry= 2  #> + Fold07: mtry= 6  #> - Fold07: mtry= 6  #> + Fold07: mtry=11  #> - Fold07: mtry=11  #> + Fold08: mtry= 2  #> - Fold08: mtry= 2  #> + Fold08: mtry= 6  #> - Fold08: mtry= 6  #> + Fold08: mtry=11  #> - Fold08: mtry=11  #> + Fold09: mtry= 2  #> - Fold09: mtry= 2  #> + Fold09: mtry= 6  #> - Fold09: mtry= 6  #> + Fold09: mtry=11  #> - Fold09: mtry=11  #> + Fold10: mtry= 2  #> - Fold10: mtry= 2  #> + Fold10: mtry= 6  #> - Fold10: mtry= 6  #> + Fold10: mtry=11  #> - Fold10: mtry=11  #> Aggregating results #> Selecting tuning parameters #> Fitting mtry = 2 on full training set #> + Fold01: mtry= 2  #> - Fold01: mtry= 2  #> + Fold01: mtry= 6  #> - Fold01: mtry= 6  #> + Fold01: mtry=11  #> - Fold01: mtry=11  #> + Fold02: mtry= 2  #> - Fold02: mtry= 2  #> + Fold02: mtry= 6  #> - Fold02: mtry= 6  #> + Fold02: mtry=11  #> - Fold02: mtry=11  #> + Fold03: mtry= 2  #> - Fold03: mtry= 2  #> + Fold03: mtry= 6  #> - Fold03: mtry= 6  #> + Fold03: mtry=11  #> - Fold03: mtry=11  #> + Fold04: mtry= 2  #> - Fold04: mtry= 2  #> + Fold04: mtry= 6  #> - Fold04: mtry= 6  #> + Fold04: mtry=11  #> - Fold04: mtry=11  #> + Fold05: mtry= 2  #> - Fold05: mtry= 2  #> + Fold05: mtry= 6  #> - Fold05: mtry= 6  #> + Fold05: mtry=11  #> - Fold05: mtry=11  #> + Fold06: mtry= 2  #> - Fold06: mtry= 2  #> + Fold06: mtry= 6  #> - Fold06: mtry= 6  #> + Fold06: mtry=11  #> - Fold06: mtry=11  #> + Fold07: mtry= 2  #> - Fold07: mtry= 2  #> + Fold07: mtry= 6  #> - Fold07: mtry= 6  #> + Fold07: mtry=11  #> - Fold07: mtry=11  #> + Fold08: mtry= 2  #> - Fold08: mtry= 2  #> + Fold08: mtry= 6  #> - Fold08: mtry= 6  #> + Fold08: mtry=11  #> - Fold08: mtry=11  #> + Fold09: mtry= 2  #> - Fold09: mtry= 2  #> + Fold09: mtry= 6  #> - Fold09: mtry= 6  #> + Fold09: mtry=11  #> - Fold09: mtry=11  #> + Fold10: mtry= 2  #> - Fold10: mtry= 2  #> + Fold10: mtry= 6  #> - Fold10: mtry= 6  #> + Fold10: mtry=11  #> - Fold10: mtry=11  #> Aggregating results #> Selecting tuning parameters #> Fitting mtry = 2 on full training set #> + Fold01: mtry= 2  #> - Fold01: mtry= 2  #> + Fold01: mtry= 6  #> - Fold01: mtry= 6  #> + Fold01: mtry=11  #> - Fold01: mtry=11  #> + Fold02: mtry= 2  #> - Fold02: mtry= 2  #> + Fold02: mtry= 6  #> - Fold02: mtry= 6  #> + Fold02: mtry=11  #> - Fold02: mtry=11  #> + Fold03: mtry= 2  #> - Fold03: mtry= 2  #> + Fold03: mtry= 6  #> - Fold03: mtry= 6  #> + Fold03: mtry=11  #> - Fold03: mtry=11  #> + Fold04: mtry= 2  #> - Fold04: mtry= 2  #> + Fold04: mtry= 6  #> - Fold04: mtry= 6  #> + Fold04: mtry=11  #> - Fold04: mtry=11  #> + Fold05: mtry= 2  #> - Fold05: mtry= 2  #> + Fold05: mtry= 6  #> - Fold05: mtry= 6  #> + Fold05: mtry=11  #> - Fold05: mtry=11  #> + Fold06: mtry= 2  #> - Fold06: mtry= 2  #> + Fold06: mtry= 6  #> - Fold06: mtry= 6  #> + Fold06: mtry=11  #> - Fold06: mtry=11  #> + Fold07: mtry= 2  #> - Fold07: mtry= 2  #> + Fold07: mtry= 6  #> - Fold07: mtry= 6  #> + Fold07: mtry=11  #> - Fold07: mtry=11  #> + Fold08: mtry= 2  #> - Fold08: mtry= 2  #> + Fold08: mtry= 6  #> - Fold08: mtry= 6  #> + Fold08: mtry=11  #> - Fold08: mtry=11  #> + Fold09: mtry= 2  #> - Fold09: mtry= 2  #> + Fold09: mtry= 6  #> - Fold09: mtry= 6  #> + Fold09: mtry=11  #> - Fold09: mtry=11  #> + Fold10: mtry= 2  #> - Fold10: mtry= 2  #> + Fold10: mtry= 6  #> - Fold10: mtry= 6  #> + Fold10: mtry=11  #> - Fold10: mtry=11  #> Aggregating results #> Selecting tuning parameters #> Fitting mtry = 2 on full training set Sub.CCP.RF <- list (Mdl.1 = CCP.RF$EstMdl$`D.1+networth`, Mdl.0 = CCP.RF$EstMdl$`D.0+networth`) CCP.NoCCP.RF <- Combined_Performance (Sub.CCP.RF) # }"},{"path":"https://seymakalay.github.io/pomodoro/reference/Estimate_Models.html","id":null,"dir":"Reference","previous_headings":"","what":"Results of the Each Data and Data Splits — Estimate_Models","title":"Results of the Each Data and Data Splits — Estimate_Models","text":"Results Data Data Splits","code":""},{"path":"https://seymakalay.github.io/pomodoro/reference/Estimate_Models.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Results of the Each Data and Data Splits — Estimate_Models","text":"","code":"Estimate_Models(DataSet, yvar, exog = NULL, xvec, xadd, type, dnames)"},{"path":"https://seymakalay.github.io/pomodoro/reference/Estimate_Models.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Results of the Each Data and Data Splits — Estimate_Models","text":"DataSet name Dataset. yvar Y variable. exog vector subtract calculation. xvec vector variables used. xadd additional vector used. type can RF, GLM, MLM, BAG, GBM. dnames unique values exog.","code":""},{"path":"https://seymakalay.github.io/pomodoro/reference/Estimate_Models.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Results of the Each Data and Data Splits — Estimate_Models","text":"output  Estimate_Models.","code":""},{"path":"https://seymakalay.github.io/pomodoro/reference/Estimate_Models.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Results of the Each Data and Data Splits — Estimate_Models","text":"","code":"# \\donttest{ sample_data <- sample_data[c(1:750),] m2.xvar0 <- c(\"sex\",\"married\",\"age\",\"havejob\",\"educ\",\"rural\",\"region\",\"income\") CCP.RF <- Estimate_Models(sample_data, yvar = c(\"Loan.Type\"), exog = \"political.afl\", xvec = m2.xvar0, xadd = \"networth\", type = \"RF\", dnames = c(\"0\",\"1\")) #> + Fold01: mtry=2  #> - Fold01: mtry=2  #> + Fold01: mtry=5  #> - Fold01: mtry=5  #> + Fold01: mtry=9  #> - Fold01: mtry=9  #> + Fold02: mtry=2  #> - Fold02: mtry=2  #> + Fold02: mtry=5  #> - Fold02: mtry=5  #> + Fold02: mtry=9  #> - Fold02: mtry=9  #> + Fold03: mtry=2  #> - Fold03: mtry=2  #> + Fold03: mtry=5  #> - Fold03: mtry=5  #> + Fold03: mtry=9  #> - Fold03: mtry=9  #> + Fold04: mtry=2  #> - Fold04: mtry=2  #> + Fold04: mtry=5  #> - Fold04: mtry=5  #> + Fold04: mtry=9  #> - Fold04: mtry=9  #> + Fold05: mtry=2  #> - Fold05: mtry=2  #> + Fold05: mtry=5  #> - Fold05: mtry=5  #> + Fold05: mtry=9  #> - Fold05: mtry=9  #> + Fold06: mtry=2  #> - Fold06: mtry=2  #> + Fold06: mtry=5  #> - Fold06: mtry=5  #> + Fold06: mtry=9  #> - Fold06: mtry=9  #> + Fold07: mtry=2  #> - Fold07: mtry=2  #> + Fold07: mtry=5  #> - Fold07: mtry=5  #> + Fold07: mtry=9  #> - Fold07: mtry=9  #> + Fold08: mtry=2  #> - Fold08: mtry=2  #> + Fold08: mtry=5  #> - Fold08: mtry=5  #> + Fold08: mtry=9  #> - Fold08: mtry=9  #> + Fold09: mtry=2  #> - Fold09: mtry=2  #> + Fold09: mtry=5  #> - Fold09: mtry=5  #> + Fold09: mtry=9  #> - Fold09: mtry=9  #> + Fold10: mtry=2  #> - Fold10: mtry=2  #> + Fold10: mtry=5  #> - Fold10: mtry=5  #> + Fold10: mtry=9  #> - Fold10: mtry=9  #> Aggregating results #> Selecting tuning parameters #> Fitting mtry = 2 on full training set #> + Fold01: mtry=2  #> - Fold01: mtry=2  #> + Fold01: mtry=5  #> - Fold01: mtry=5  #> + Fold01: mtry=9  #> - Fold01: mtry=9  #> + Fold02: mtry=2  #> - Fold02: mtry=2  #> + Fold02: mtry=5  #> - Fold02: mtry=5  #> + Fold02: mtry=9  #> - Fold02: mtry=9  #> + Fold03: mtry=2  #> - Fold03: mtry=2  #> + Fold03: mtry=5  #> - Fold03: mtry=5  #> + Fold03: mtry=9  #> - Fold03: mtry=9  #> + Fold04: mtry=2  #> - Fold04: mtry=2  #> + Fold04: mtry=5  #> - Fold04: mtry=5  #> + Fold04: mtry=9  #> - Fold04: mtry=9  #> + Fold05: mtry=2  #> - Fold05: mtry=2  #> + Fold05: mtry=5  #> - Fold05: mtry=5  #> + Fold05: mtry=9  #> - Fold05: mtry=9  #> + Fold06: mtry=2  #> - Fold06: mtry=2  #> + Fold06: mtry=5  #> - Fold06: mtry=5  #> + Fold06: mtry=9  #> - Fold06: mtry=9  #> + Fold07: mtry=2  #> - Fold07: mtry=2  #> + Fold07: mtry=5  #> - Fold07: mtry=5  #> + Fold07: mtry=9  #> - Fold07: mtry=9  #> + Fold08: mtry=2  #> - Fold08: mtry=2  #> + Fold08: mtry=5  #> - Fold08: mtry=5  #> + Fold08: mtry=9  #> - Fold08: mtry=9  #> + Fold09: mtry=2  #> - Fold09: mtry=2  #> + Fold09: mtry=5  #> - Fold09: mtry=5  #> + Fold09: mtry=9  #> - Fold09: mtry=9  #> + Fold10: mtry=2  #> - Fold10: mtry=2  #> + Fold10: mtry=5  #> - Fold10: mtry=5  #> + Fold10: mtry=9  #> - Fold10: mtry=9  #> Aggregating results #> Selecting tuning parameters #> Fitting mtry = 2 on full training set #> + Fold01: mtry=2  #> - Fold01: mtry=2  #> + Fold01: mtry=5  #> - Fold01: mtry=5  #> + Fold01: mtry=9  #> - Fold01: mtry=9  #> + Fold02: mtry=2  #> - Fold02: mtry=2  #> + Fold02: mtry=5  #> - Fold02: mtry=5  #> + Fold02: mtry=9  #> - Fold02: mtry=9  #> + Fold03: mtry=2  #> - Fold03: mtry=2  #> + Fold03: mtry=5  #> - Fold03: mtry=5  #> + Fold03: mtry=9  #> - Fold03: mtry=9  #> + Fold04: mtry=2  #> - Fold04: mtry=2  #> + Fold04: mtry=5  #> - Fold04: mtry=5  #> + Fold04: mtry=9  #> - Fold04: mtry=9  #> + Fold05: mtry=2  #> - Fold05: mtry=2  #> + Fold05: mtry=5  #> - Fold05: mtry=5  #> + Fold05: mtry=9  #> - Fold05: mtry=9  #> + Fold06: mtry=2  #> - Fold06: mtry=2  #> + Fold06: mtry=5  #> - Fold06: mtry=5  #> + Fold06: mtry=9  #> - Fold06: mtry=9  #> + Fold07: mtry=2  #> - Fold07: mtry=2  #> + Fold07: mtry=5  #> - Fold07: mtry=5  #> + Fold07: mtry=9  #> - Fold07: mtry=9  #> + Fold08: mtry=2  #> - Fold08: mtry=2  #> + Fold08: mtry=5  #> - Fold08: mtry=5  #> + Fold08: mtry=9  #> - Fold08: mtry=9  #> + Fold09: mtry=2  #> - Fold09: mtry=2  #> + Fold09: mtry=5  #> - Fold09: mtry=5  #> + Fold09: mtry=9  #> - Fold09: mtry=9  #> + Fold10: mtry=2  #> - Fold10: mtry=2  #> + Fold10: mtry=5  #> - Fold10: mtry=5  #> + Fold10: mtry=9  #> - Fold10: mtry=9  #> Aggregating results #> Selecting tuning parameters #> Fitting mtry = 2 on full training set # }"},{"path":"https://seymakalay.github.io/pomodoro/reference/GBM_Model.html","id":null,"dir":"Reference","previous_headings":"","what":"Gradient Boosting Model — GBM_Model","title":"Gradient Boosting Model — GBM_Model","text":"Gradient Boosting Model","code":""},{"path":"https://seymakalay.github.io/pomodoro/reference/GBM_Model.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Gradient Boosting Model — GBM_Model","text":"","code":"GBM_Model(Data, xvar, yvar)"},{"path":"https://seymakalay.github.io/pomodoro/reference/GBM_Model.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Gradient Boosting Model — GBM_Model","text":"Data name Dataset. xvar X variables. yvar Y variable.","code":""},{"path":"https://seymakalay.github.io/pomodoro/reference/GBM_Model.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Gradient Boosting Model — GBM_Model","text":"output  GBM_Model.","code":""},{"path":"https://seymakalay.github.io/pomodoro/reference/GBM_Model.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Gradient Boosting Model — GBM_Model","text":"Unlike bagging trees, boosting use bootstrap sampling, rather tree fit using information previous trees. event probability stochastic gradient boosting model given $$\\hat{\\pi_i} = \\frac{1}{1 + exp[-f(x)]^\\prime}$$  \\(f(x)\\) range \\([-\\infty,\\infty]\\) initial estimate model  \\(f^{(0)}_i=log(\\frac{\\pi_{}}{1-\\pi_{}})\\),  \\(\\hat{\\pi}\\) estimated sample proportion single class training set.","code":""},{"path":"https://seymakalay.github.io/pomodoro/reference/GBM_Model.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Gradient Boosting Model — GBM_Model","text":"","code":"# \\donttest{ yvar <- c(\"Loan.Type\") sample_data <- sample_data[c(1:120),] xvar <- c(\"sex\", \"married\", \"age\", \"havejob\", \"educ\", \"political.afl\", \"rural\", \"region\", \"fin.intermdiaries\", \"fin.knowldge\", \"income\") BchMk.GBM <- GBM_Model(sample_data, c(xvar, \"networth\"), yvar ) #> Warning: Some classes have a single record ( Informal ) and these will be selected for the sample #> Warning: These variables have zero variances: rural, region #> Warning: These variables have zero variances: rural, region #> Warning: variable 7: rural has no variation. #> Warning: variable 8: region has no variation. #> Iter   TrainDeviance   ValidDeviance   StepSize   Improve #>      1        1.3863            -nan     0.1000    0.4451 #>      2        1.1181            -nan     0.1000    0.2803 #>      3        0.9499            -nan     0.1000    0.2197 #>      4        0.8114            -nan     0.1000    0.1658 #>      5        0.7131            -nan     0.1000    0.1324 #>      6        0.6353            -nan     0.1000    0.0998 #>      7        0.5693            -nan     0.1000    0.0719 #>      8        0.5193            -nan     0.1000    0.0557 #>      9        0.4743            -nan     0.1000    0.0378 #>     10        0.4426            -nan     0.1000    0.0481 #>     20        0.2567            -nan     0.1000   -0.0048 #>     40        0.1432            -nan     0.1000   -0.0128 #>     60        0.0979            -nan     0.1000   -0.0126 #>     80        0.0629            -nan     0.1000   -0.0038 #>    100        0.0431            -nan     0.1000   -0.0041 #>    120        0.0330            -nan     0.1000   -0.0037 #>    140        0.0227            -nan     0.1000   -0.0026 #>    150        0.0231            -nan     0.1000   -0.0013 #>  #> Warning: These variables have zero variances: rural, region #> Warning: variable 7: rural has no variation. #> Warning: variable 8: region has no variation. #> Iter   TrainDeviance   ValidDeviance   StepSize   Improve #>      1        1.3863            -nan     0.1000    0.4354 #>      2        1.1311            -nan     0.1000    0.3092 #>      3        0.9478            -nan     0.1000    0.2252 #>      4        0.8088            -nan     0.1000    0.1692 #>      5        0.7103            -nan     0.1000    0.1022 #>      6        0.6313            -nan     0.1000    0.1112 #>      7        0.5639            -nan     0.1000    0.0734 #>      8        0.5017            -nan     0.1000    0.0693 #>      9        0.4572            -nan     0.1000    0.0494 #>     10        0.4193            -nan     0.1000    0.0479 #>     20        0.2095            -nan     0.1000    0.0038 #>     40        0.0737            -nan     0.1000   -0.0116 #>     60        0.0379            -nan     0.1000   -0.0015 #>     80        0.0185            -nan     0.1000   -0.0011 #>    100        0.0104            -nan     0.1000   -0.0010 #>    120        0.0053            -nan     0.1000   -0.0009 #>    140        0.0029            -nan     0.1000   -0.0001 #>    150        0.0029            -nan     0.1000   -0.0002 #>  #> Warning: These variables have zero variances: rural, region #> Warning: variable 7: rural has no variation. #> Warning: variable 8: region has no variation. #> Iter   TrainDeviance   ValidDeviance   StepSize   Improve #>      1        1.3863            -nan     0.1000    0.4799 #>      2        1.1018            -nan     0.1000    0.3101 #>      3        0.9192            -nan     0.1000    0.1985 #>      4        0.7951            -nan     0.1000    0.1765 #>      5        0.6882            -nan     0.1000    0.1270 #>      6        0.6069            -nan     0.1000    0.0892 #>      7        0.5446            -nan     0.1000    0.0635 #>      8        0.4976            -nan     0.1000    0.0738 #>      9        0.4472            -nan     0.1000    0.0424 #>     10        0.4103            -nan     0.1000    0.0291 #>     20        0.2252            -nan     0.1000    0.0170 #>     40        0.0827            -nan     0.1000   -0.0073 #>     60        0.0291            -nan     0.1000   -0.0034 #>     80        0.0148            -nan     0.1000   -0.0044 #>    100        0.0077            -nan     0.1000   -0.0006 #>    120        0.0039            -nan     0.1000   -0.0002 #>    140        0.0019            -nan     0.1000   -0.0007 #>    150        0.0019            -nan     0.1000   -0.0004 #>  #> Warning: These variables have zero variances: rural, region #> Warning: variable 7: rural has no variation. #> Warning: variable 8: region has no variation. #> Iter   TrainDeviance   ValidDeviance   StepSize   Improve #>      1        1.3863            -nan     0.1000    0.4916 #>      2        1.1202            -nan     0.1000    0.3538 #>      3        0.9190            -nan     0.1000    0.2374 #>      4        0.7782            -nan     0.1000    0.1730 #>      5        0.6618            -nan     0.1000    0.1223 #>      6        0.5903            -nan     0.1000    0.0764 #>      7        0.5303            -nan     0.1000    0.0782 #>      8        0.4853            -nan     0.1000    0.0519 #>      9        0.4468            -nan     0.1000    0.0337 #>     10        0.4188            -nan     0.1000    0.0232 #>     20        0.2602            -nan     0.1000   -0.0032 #>     40        0.1427            -nan     0.1000   -0.0021 #>     60        0.1000            -nan     0.1000   -0.0067 #>     80        0.0610            -nan     0.1000   -0.0104 #>    100        0.0406            -nan     0.1000   -0.0012 #>    120        0.0330            -nan     0.1000   -0.0048 #>    140        0.0249            -nan     0.1000   -0.0010 #>    150        0.0211            -nan     0.1000   -0.0027 #>  #> Warning: These variables have zero variances: rural, region #> Warning: variable 7: rural has no variation. #> Warning: variable 8: region has no variation. #> Iter   TrainDeviance   ValidDeviance   StepSize   Improve #>      1        1.3863            -nan     0.1000    0.4714 #>      2        1.1227            -nan     0.1000    0.3599 #>      3        0.9216            -nan     0.1000    0.2456 #>      4        0.7710            -nan     0.1000    0.1739 #>      5        0.6629            -nan     0.1000    0.1324 #>      6        0.5729            -nan     0.1000    0.0986 #>      7        0.5132            -nan     0.1000    0.0643 #>      8        0.4635            -nan     0.1000    0.0526 #>      9        0.4267            -nan     0.1000    0.0307 #>     10        0.3935            -nan     0.1000    0.0412 #>     20        0.2236            -nan     0.1000    0.0060 #>     40        0.0958            -nan     0.1000   -0.0093 #>     60        0.0497            -nan     0.1000   -0.0077 #>     80        0.0315            -nan     0.1000   -0.0036 #>    100        0.0167            -nan     0.1000   -0.0030 #>    120        0.0096            -nan     0.1000   -0.0004 #>    140        0.0062            -nan     0.1000   -0.0004 #>    150        0.0049            -nan     0.1000   -0.0010 #>  #> Warning: These variables have zero variances: rural, region #> Warning: variable 7: rural has no variation. #> Warning: variable 8: region has no variation. #> Iter   TrainDeviance   ValidDeviance   StepSize   Improve #>      1        1.3863            -nan     0.1000    0.5414 #>      2        1.0882            -nan     0.1000    0.3380 #>      3        0.8922            -nan     0.1000    0.2342 #>      4        0.7533            -nan     0.1000    0.1830 #>      5        0.6537            -nan     0.1000    0.1273 #>      6        0.5697            -nan     0.1000    0.0785 #>      7        0.5127            -nan     0.1000    0.0764 #>      8        0.4593            -nan     0.1000    0.0519 #>      9        0.4165            -nan     0.1000    0.0491 #>     10        0.3874            -nan     0.1000    0.0169 #>     20        0.1998            -nan     0.1000   -0.0065 #>     40        0.0773            -nan     0.1000   -0.0044 #>     60        0.0399            -nan     0.1000   -0.0045 #>     80        0.0258            -nan     0.1000   -0.0031 #>    100        0.0163            -nan     0.1000   -0.0044 #>    120        0.0078            -nan     0.1000   -0.0010 #>    140        0.0050            -nan     0.1000   -0.0012 #>    150        0.0043            -nan     0.1000   -0.0004 #>  #> Warning: These variables have zero variances: rural, region #> Warning: variable 7: rural has no variation. #> Warning: variable 8: region has no variation. #> Iter   TrainDeviance   ValidDeviance   StepSize   Improve #>      1        1.3863            -nan     0.1000    0.3853 #>      2        1.1457            -nan     0.1000    0.2888 #>      3        0.9719            -nan     0.1000    0.2090 #>      4        0.8305            -nan     0.1000    0.1677 #>      5        0.7265            -nan     0.1000    0.1220 #>      6        0.6446            -nan     0.1000    0.1031 #>      7        0.5795            -nan     0.1000    0.0830 #>      8        0.5313            -nan     0.1000    0.0691 #>      9        0.4882            -nan     0.1000    0.0457 #>     10        0.4551            -nan     0.1000    0.0078 #>     20        0.2630            -nan     0.1000   -0.0073 #>     40        0.1364            -nan     0.1000   -0.0110 #>     60        0.0882            -nan     0.1000   -0.0097 #>     80        0.0616            -nan     0.1000   -0.0147 #>    100        0.0457            -nan     0.1000   -0.0067 #>    120        0.0324            -nan     0.1000   -0.0051 #>    140        0.0310            -nan     0.1000   -0.0010 #>    150        0.0259            -nan     0.1000   -0.0021 #>  #> Warning: These variables have zero variances: rural, region #> Warning: variable 7: rural has no variation. #> Warning: variable 8: region has no variation. #> Iter   TrainDeviance   ValidDeviance   StepSize   Improve #>      1        1.3863            -nan     0.1000    0.4150 #>      2        1.1340            -nan     0.1000    0.2457 #>      3        0.9760            -nan     0.1000    0.2486 #>      4        0.8285            -nan     0.1000    0.1746 #>      5        0.7212            -nan     0.1000    0.1195 #>      6        0.6325            -nan     0.1000    0.0840 #>      7        0.5652            -nan     0.1000    0.0690 #>      8        0.5105            -nan     0.1000    0.0554 #>      9        0.4632            -nan     0.1000    0.0574 #>     10        0.4213            -nan     0.1000    0.0448 #>     20        0.2157            -nan     0.1000   -0.0066 #>     40        0.0970            -nan     0.1000   -0.0024 #>     60        0.0353            -nan     0.1000   -0.0015 #>     80        0.0169            -nan     0.1000   -0.0019 #>    100        0.0100            -nan     0.1000   -0.0002 #>    120        0.0055            -nan     0.1000   -0.0019 #>    140        0.0029            -nan     0.1000   -0.0003 #>    150        0.0021            -nan     0.1000   -0.0000 #>  #> Warning: These variables have zero variances: rural, region #> Warning: variable 7: rural has no variation. #> Warning: variable 8: region has no variation. #> Iter   TrainDeviance   ValidDeviance   StepSize   Improve #>      1        1.3863            -nan     0.1000    0.3971 #>      2        1.1323            -nan     0.1000    0.3372 #>      3        0.9454            -nan     0.1000    0.2076 #>      4        0.8194            -nan     0.1000    0.1686 #>      5        0.7056            -nan     0.1000    0.1047 #>      6        0.6343            -nan     0.1000    0.1097 #>      7        0.5610            -nan     0.1000    0.0867 #>      8        0.5025            -nan     0.1000    0.0712 #>      9        0.4510            -nan     0.1000    0.0147 #>     10        0.4165            -nan     0.1000    0.0578 #>     20        0.1904            -nan     0.1000    0.0059 #>     40        0.0748            -nan     0.1000   -0.0055 #>     60        0.0325            -nan     0.1000   -0.0078 #>     80        0.0125            -nan     0.1000   -0.0026 #>    100        0.0060            -nan     0.1000   -0.0007 #>    120        0.0031            -nan     0.1000   -0.0012 #>    140        0.0022            -nan     0.1000   -0.0003 #>    150        0.0019            -nan     0.1000   -0.0007 #>  #> Warning: These variables have zero variances: rural, region #> Warning: variable 7: rural has no variation. #> Warning: variable 8: region has no variation. #> Iter   TrainDeviance   ValidDeviance   StepSize   Improve #>      1        1.3863            -nan     0.1000    0.3999 #>      2        1.1336            -nan     0.1000    0.2621 #>      3        0.9563            -nan     0.1000    0.1674 #>      4        0.8240            -nan     0.1000    0.1516 #>      5        0.7275            -nan     0.1000    0.1194 #>      6        0.6539            -nan     0.1000    0.0924 #>      7        0.5940            -nan     0.1000    0.0578 #>      8        0.5516            -nan     0.1000    0.0353 #>      9        0.5079            -nan     0.1000    0.0270 #>     10        0.4763            -nan     0.1000    0.0260 #>     20        0.3403            -nan     0.1000   -0.0036 #>     40        0.2344            -nan     0.1000   -0.0097 #>     60        0.1730            -nan     0.1000   -0.0103 #>     80        0.1298            -nan     0.1000   -0.0108 #>    100        0.0956            -nan     0.1000   -0.0076 #>    120        0.0761            -nan     0.1000   -0.0068 #>    140        0.0582            -nan     0.1000   -0.0051 #>    150        0.0522            -nan     0.1000   -0.0037 #>  #> Warning: These variables have zero variances: rural, region #> Warning: variable 7: rural has no variation. #> Warning: variable 8: region has no variation. #> Iter   TrainDeviance   ValidDeviance   StepSize   Improve #>      1        1.3863            -nan     0.1000    0.4694 #>      2        1.1179            -nan     0.1000    0.2780 #>      3        0.9493            -nan     0.1000    0.2164 #>      4        0.8205            -nan     0.1000    0.1570 #>      5        0.7181            -nan     0.1000    0.1226 #>      6        0.6511            -nan     0.1000    0.1079 #>      7        0.5901            -nan     0.1000    0.0662 #>      8        0.5427            -nan     0.1000    0.0605 #>      9        0.4953            -nan     0.1000    0.0509 #>     10        0.4630            -nan     0.1000    0.0309 #>     20        0.2861            -nan     0.1000   -0.0099 #>     40        0.1494            -nan     0.1000   -0.0130 #>     60        0.0988            -nan     0.1000   -0.0087 #>     80        0.0534            -nan     0.1000   -0.0100 #>    100        0.0306            -nan     0.1000   -0.0031 #>    120        0.0167            -nan     0.1000   -0.0023 #>    140        0.0132            -nan     0.1000   -0.0015 #>    150        0.0118            -nan     0.1000   -0.0009 #>  #> Warning: These variables have zero variances: rural, region #> Warning: variable 7: rural has no variation. #> Warning: variable 8: region has no variation. #> Iter   TrainDeviance   ValidDeviance   StepSize   Improve #>      1        1.3863            -nan     0.1000    0.4308 #>      2        1.1414            -nan     0.1000    0.2866 #>      3        0.9626            -nan     0.1000    0.1776 #>      4        0.8422            -nan     0.1000    0.1413 #>      5        0.7375            -nan     0.1000    0.1099 #>      6        0.6672            -nan     0.1000    0.0954 #>      7        0.5999            -nan     0.1000    0.0845 #>      8        0.5404            -nan     0.1000    0.0648 #>      9        0.4910            -nan     0.1000    0.0249 #>     10        0.4591            -nan     0.1000    0.0319 #>     20        0.2840            -nan     0.1000   -0.0019 #>     40        0.1303            -nan     0.1000   -0.0156 #>     60        0.0609            -nan     0.1000   -0.0084 #>     80        0.0349            -nan     0.1000   -0.0017 #>    100        0.0183            -nan     0.1000   -0.0020 #>    120        0.0123            -nan     0.1000   -0.0003 #>    140        0.0084            -nan     0.1000   -0.0004 #>    150        0.0065            -nan     0.1000   -0.0026 #>  #> Warning: These variables have zero variances: rural, region #> Warning: variable 7: rural has no variation. #> Warning: variable 8: region has no variation. #> Iter   TrainDeviance   ValidDeviance   StepSize   Improve #>      1        1.0986            -nan     0.1000    0.3132 #>      2        0.9053            -nan     0.1000    0.1785 #>      3        0.7708            -nan     0.1000    0.1456 #>      4        0.6683            -nan     0.1000    0.1224 #>      5        0.5872            -nan     0.1000    0.1001 #>      6        0.5263            -nan     0.1000    0.0773 #>      7        0.4775            -nan     0.1000    0.0634 #>      8        0.4380            -nan     0.1000    0.0294 #>      9        0.4122            -nan     0.1000    0.0279 #>     10        0.3861            -nan     0.1000    0.0151 #>     20        0.2512            -nan     0.1000    0.0045 #>     40        0.1492            -nan     0.1000   -0.0069 #>     60        0.1032            -nan     0.1000   -0.0188 #>     80        0.0704            -nan     0.1000   -0.0031 #>    100        0.0526            -nan     0.1000   -0.0023 #>    120        0.0391            -nan     0.1000   -0.0057 #>    140        0.0298            -nan     0.1000   -0.0000 #>    150        0.0262            -nan     0.1000   -0.0018 #>  #> Warning: These variables have zero variances: rural, region #> Warning: variable 7: rural has no variation. #> Warning: variable 8: region has no variation. #> Iter   TrainDeviance   ValidDeviance   StepSize   Improve #>      1        1.0986            -nan     0.1000    0.2560 #>      2        0.9072            -nan     0.1000    0.2354 #>      3        0.7629            -nan     0.1000    0.1580 #>      4        0.6600            -nan     0.1000    0.1297 #>      5        0.5808            -nan     0.1000    0.0923 #>      6        0.5149            -nan     0.1000    0.0795 #>      7        0.4589            -nan     0.1000    0.0480 #>      8        0.4191            -nan     0.1000    0.0430 #>      9        0.3881            -nan     0.1000    0.0334 #>     10        0.3584            -nan     0.1000    0.0194 #>     20        0.2058            -nan     0.1000   -0.0080 #>     40        0.0918            -nan     0.1000   -0.0045 #>     60        0.0492            -nan     0.1000   -0.0044 #>     80        0.0274            -nan     0.1000   -0.0008 #>    100        0.0155            -nan     0.1000   -0.0012 #>    120        0.0087            -nan     0.1000   -0.0011 #>    140        0.0045            -nan     0.1000   -0.0003 #>    150        0.0036            -nan     0.1000   -0.0000 #>  #> Warning: These variables have zero variances: rural, region #> Warning: variable 7: rural has no variation. #> Warning: variable 8: region has no variation. #> Iter   TrainDeviance   ValidDeviance   StepSize   Improve #>      1        1.0986            -nan     0.1000    0.2964 #>      2        0.8967            -nan     0.1000    0.2183 #>      3        0.7544            -nan     0.1000    0.1279 #>      4        0.6496            -nan     0.1000    0.1162 #>      5        0.5666            -nan     0.1000    0.0867 #>      6        0.5076            -nan     0.1000    0.0505 #>      7        0.4595            -nan     0.1000    0.0347 #>      8        0.4216            -nan     0.1000    0.0208 #>      9        0.3932            -nan     0.1000    0.0298 #>     10        0.3630            -nan     0.1000    0.0223 #>     20        0.1864            -nan     0.1000    0.0010 #>     40        0.0782            -nan     0.1000   -0.0173 #>     60        0.0393            -nan     0.1000   -0.0041 #>     80        0.0204            -nan     0.1000   -0.0012 #>    100        0.0143            -nan     0.1000   -0.0019 #>    120        0.0066            -nan     0.1000   -0.0008 #>    140        0.0034            -nan     0.1000   -0.0007 #>    150        0.0027            -nan     0.1000    0.0001 #>  #> Warning: These variables have zero variances: rural, region #> Warning: variable 7: rural has no variation. #> Warning: variable 8: region has no variation. #> Iter   TrainDeviance   ValidDeviance   StepSize   Improve #>      1        1.3863            -nan     0.1000    0.4638 #>      2        1.1243            -nan     0.1000    0.2835 #>      3        0.9726            -nan     0.1000    0.1882 #>      4        0.8410            -nan     0.1000    0.1273 #>      5        0.7484            -nan     0.1000    0.0889 #>      6        0.6905            -nan     0.1000    0.0925 #>      7        0.6400            -nan     0.1000    0.0656 #>      8        0.5909            -nan     0.1000    0.0405 #>      9        0.5516            -nan     0.1000    0.0461 #>     10        0.5210            -nan     0.1000   -0.0021 #>     20        0.3637            -nan     0.1000   -0.0055 #>     40        0.2501            -nan     0.1000   -0.0169 #>     60        0.1989            -nan     0.1000   -0.0249 #>     80        0.1508            -nan     0.1000   -0.0083 #>    100        0.1203            -nan     0.1000   -0.0062 #>    120        0.1015            -nan     0.1000   -0.0056 #>    140        0.0809            -nan     0.1000   -0.0063 #>    150        0.0751            -nan     0.1000   -0.0052 #>  #> Warning: These variables have zero variances: rural, region #> Warning: variable 7: rural has no variation. #> Warning: variable 8: region has no variation. #> Iter   TrainDeviance   ValidDeviance   StepSize   Improve #>      1        1.3863            -nan     0.1000    0.4030 #>      2        1.1420            -nan     0.1000    0.2632 #>      3        0.9535            -nan     0.1000    0.1981 #>      4        0.8314            -nan     0.1000    0.1347 #>      5        0.7346            -nan     0.1000    0.0900 #>      6        0.6636            -nan     0.1000    0.0701 #>      7        0.6099            -nan     0.1000    0.0713 #>      8        0.5647            -nan     0.1000    0.0530 #>      9        0.5210            -nan     0.1000    0.0397 #>     10        0.4860            -nan     0.1000    0.0148 #>     20        0.3162            -nan     0.1000   -0.0073 #>     40        0.1562            -nan     0.1000   -0.0066 #>     60        0.0941            -nan     0.1000   -0.0094 #>     80        0.0664            -nan     0.1000   -0.0138 #>    100        0.0423            -nan     0.1000   -0.0056 #>    120        0.0297            -nan     0.1000    0.0002 #>    140        0.0190            -nan     0.1000   -0.0040 #>    150        0.0161            -nan     0.1000   -0.0038 #>  #> Warning: These variables have zero variances: rural, region #> Warning: variable 7: rural has no variation. #> Warning: variable 8: region has no variation. #> Iter   TrainDeviance   ValidDeviance   StepSize   Improve #>      1        1.3863            -nan     0.1000    0.4395 #>      2        1.1288            -nan     0.1000    0.3015 #>      3        0.9650            -nan     0.1000    0.2059 #>      4        0.8445            -nan     0.1000    0.1509 #>      5        0.7390            -nan     0.1000    0.1120 #>      6        0.6649            -nan     0.1000    0.0534 #>      7        0.6092            -nan     0.1000    0.0621 #>      8        0.5616            -nan     0.1000    0.0457 #>      9        0.5244            -nan     0.1000    0.0134 #>     10        0.4954            -nan     0.1000    0.0478 #>     20        0.2907            -nan     0.1000   -0.0050 #>     40        0.1614            -nan     0.1000   -0.0291 #>     60        0.0820            -nan     0.1000   -0.0110 #>     80        0.0486            -nan     0.1000   -0.0068 #>    100        0.0279            -nan     0.1000   -0.0014 #>    120        0.0172            -nan     0.1000   -0.0003 #>    140        0.0098            -nan     0.1000   -0.0010 #>    150        0.0097            -nan     0.1000   -0.0022 #>  #> Warning: These variables have zero variances: rural, region #> Warning: variable 7: rural has no variation. #> Warning: variable 8: region has no variation. #> Iter   TrainDeviance   ValidDeviance   StepSize   Improve #>      1        1.3863            -nan     0.1000    0.4333 #>      2        1.1477            -nan     0.1000    0.2330 #>      3        0.9965            -nan     0.1000    0.1962 #>      4        0.8716            -nan     0.1000    0.1318 #>      5        0.7745            -nan     0.1000    0.1102 #>      6        0.7026            -nan     0.1000    0.0561 #>      7        0.6550            -nan     0.1000    0.0525 #>      8        0.6069            -nan     0.1000    0.0604 #>      9        0.5690            -nan     0.1000    0.0503 #>     10        0.5374            -nan     0.1000    0.0323 #>     20        0.3638            -nan     0.1000    0.0069 #>     40        0.2265            -nan     0.1000   -0.0063 #>     60        0.1494            -nan     0.1000   -0.0081 #>     80        0.1045            -nan     0.1000   -0.0047 #>    100        0.0726            -nan     0.1000   -0.0045 #>    120        0.0511            -nan     0.1000   -0.0029 #>    140        0.0401            -nan     0.1000   -0.0024 #>    150        0.0343            -nan     0.1000   -0.0030 #>  #> Warning: These variables have zero variances: rural, region #> Warning: variable 7: rural has no variation. #> Warning: variable 8: region has no variation. #> Iter   TrainDeviance   ValidDeviance   StepSize   Improve #>      1        1.3863            -nan     0.1000    0.4060 #>      2        1.1383            -nan     0.1000    0.2759 #>      3        0.9796            -nan     0.1000    0.1555 #>      4        0.8678            -nan     0.1000    0.1557 #>      5        0.7765            -nan     0.1000    0.1041 #>      6        0.7076            -nan     0.1000    0.0871 #>      7        0.6475            -nan     0.1000    0.0823 #>      8        0.5899            -nan     0.1000    0.0469 #>      9        0.5476            -nan     0.1000    0.0391 #>     10        0.5079            -nan     0.1000    0.0319 #>     20        0.2977            -nan     0.1000    0.0022 #>     40        0.1416            -nan     0.1000   -0.0019 #>     60        0.0645            -nan     0.1000   -0.0090 #>     80        0.0359            -nan     0.1000   -0.0050 #>    100        0.0177            -nan     0.1000   -0.0011 #>    120        0.0107            -nan     0.1000   -0.0005 #>    140        0.0068            -nan     0.1000   -0.0010 #>    150        0.0057            -nan     0.1000   -0.0018 #>  #> Warning: These variables have zero variances: rural, region #> Warning: variable 7: rural has no variation. #> Warning: variable 8: region has no variation. #> Iter   TrainDeviance   ValidDeviance   StepSize   Improve #>      1        1.3863            -nan     0.1000    0.4286 #>      2        1.1429            -nan     0.1000    0.2800 #>      3        0.9786            -nan     0.1000    0.1933 #>      4        0.8475            -nan     0.1000    0.1499 #>      5        0.7522            -nan     0.1000    0.1317 #>      6        0.6725            -nan     0.1000    0.0835 #>      7        0.6115            -nan     0.1000    0.0572 #>      8        0.5694            -nan     0.1000    0.0643 #>      9        0.5255            -nan     0.1000    0.0558 #>     10        0.4847            -nan     0.1000    0.0425 #>     20        0.2682            -nan     0.1000    0.0069 #>     40        0.1031            -nan     0.1000    0.0010 #>     60        0.0454            -nan     0.1000   -0.0045 #>     80        0.0210            -nan     0.1000   -0.0017 #>    100        0.0119            -nan     0.1000   -0.0003 #>    120        0.0094            -nan     0.1000   -0.0005 #>    140        0.0050            -nan     0.1000   -0.0020 #>    150        0.0031            -nan     0.1000   -0.0003 #>  #> Warning: These variables have zero variances: rural, region #> Warning: variable 7: rural has no variation. #> Warning: variable 8: region has no variation. #> Iter   TrainDeviance   ValidDeviance   StepSize   Improve #>      1        1.3863            -nan     0.1000    0.4603 #>      2        1.1410            -nan     0.1000    0.3181 #>      3        0.9577            -nan     0.1000    0.1942 #>      4        0.8159            -nan     0.1000    0.1506 #>      5        0.7199            -nan     0.1000    0.1003 #>      6        0.6473            -nan     0.1000    0.1041 #>      7        0.5788            -nan     0.1000    0.0774 #>      8        0.5241            -nan     0.1000    0.0566 #>      9        0.4884            -nan     0.1000    0.0315 #>     10        0.4536            -nan     0.1000    0.0219 #>     20        0.2498            -nan     0.1000   -0.0133 #>     40        0.1455            -nan     0.1000   -0.0064 #>     60        0.1019            -nan     0.1000   -0.0024 #>     80        0.0701            -nan     0.1000   -0.0085 #>    100        0.0490            -nan     0.1000   -0.0084 #>    120        0.0398            -nan     0.1000   -0.0017 #>    140        0.0307            -nan     0.1000   -0.0066 #>    150        0.0300            -nan     0.1000   -0.0034 #>  #> Warning: These variables have zero variances: rural, region #> Warning: variable 7: rural has no variation. #> Warning: variable 8: region has no variation. #> Iter   TrainDeviance   ValidDeviance   StepSize   Improve #>      1        1.3863            -nan     0.1000    0.4556 #>      2        1.1175            -nan     0.1000    0.3043 #>      3        0.9525            -nan     0.1000    0.2058 #>      4        0.8297            -nan     0.1000    0.1817 #>      5        0.7200            -nan     0.1000    0.1146 #>      6        0.6336            -nan     0.1000    0.1071 #>      7        0.5673            -nan     0.1000    0.0808 #>      8        0.5126            -nan     0.1000    0.0618 #>      9        0.4687            -nan     0.1000    0.0534 #>     10        0.4271            -nan     0.1000    0.0244 #>     20        0.2114            -nan     0.1000    0.0085 #>     40        0.0936            -nan     0.1000   -0.0053 #>     60        0.0531            -nan     0.1000   -0.0067 #>     80        0.0262            -nan     0.1000   -0.0012 #>    100        0.0129            -nan     0.1000   -0.0011 #>    120        0.0117            -nan     0.1000   -0.0006 #>    140        0.0064            -nan     0.1000    0.0002 #>    150        0.0052            -nan     0.1000   -0.0005 #>  #> Warning: These variables have zero variances: rural, region #> Warning: variable 7: rural has no variation. #> Warning: variable 8: region has no variation. #> Iter   TrainDeviance   ValidDeviance   StepSize   Improve #>      1        1.3863            -nan     0.1000    0.4489 #>      2        1.1286            -nan     0.1000    0.2651 #>      3        0.9420            -nan     0.1000    0.2255 #>      4        0.8081            -nan     0.1000    0.1670 #>      5        0.7032            -nan     0.1000    0.1093 #>      6        0.6286            -nan     0.1000    0.1124 #>      7        0.5575            -nan     0.1000    0.0693 #>      8        0.5021            -nan     0.1000    0.0711 #>      9        0.4568            -nan     0.1000    0.0443 #>     10        0.4207            -nan     0.1000    0.0410 #>     20        0.2142            -nan     0.1000    0.0058 #>     40        0.0849            -nan     0.1000   -0.0114 #>     60        0.0315            -nan     0.1000   -0.0030 #>     80        0.0167            -nan     0.1000   -0.0007 #>    100        0.0100            -nan     0.1000   -0.0017 #>    120        0.0068            -nan     0.1000   -0.0011 #>    140        0.0046            -nan     0.1000   -0.0019 #>    150        0.0031            -nan     0.1000   -0.0012 #>  #> Warning: These variables have zero variances: rural, region #> Warning: variable 7: rural has no variation. #> Warning: variable 8: region has no variation. #> Iter   TrainDeviance   ValidDeviance   StepSize   Improve #>      1        1.3863            -nan     0.1000    0.4698 #>      2        1.1200            -nan     0.1000    0.3113 #>      3        0.9279            -nan     0.1000    0.2414 #>      4        0.7857            -nan     0.1000    0.1666 #>      5        0.6774            -nan     0.1000    0.1161 #>      6        0.5980            -nan     0.1000    0.0991 #>      7        0.5371            -nan     0.1000    0.0615 #>      8        0.4935            -nan     0.1000    0.0438 #>      9        0.4514            -nan     0.1000    0.0505 #>     10        0.4128            -nan     0.1000    0.0240 #>     20        0.2590            -nan     0.1000    0.0004 #>     40        0.1756            -nan     0.1000   -0.0394 #>     60        0.1237            -nan     0.1000   -0.0181 #>     80        0.0842            -nan     0.1000   -0.0163 #>    100        0.0627            -nan     0.1000   -0.0078 #>    120        0.0474            -nan     0.1000   -0.0026 #>    140        0.0379            -nan     0.1000   -0.0045 #>    150        0.0333            -nan     0.1000   -0.0040 #>  #> Warning: These variables have zero variances: rural, region #> Warning: variable 7: rural has no variation. #> Warning: variable 8: region has no variation. #> Iter   TrainDeviance   ValidDeviance   StepSize   Improve #>      1        1.3863            -nan     0.1000    0.4592 #>      2        1.1252            -nan     0.1000    0.3535 #>      3        0.9197            -nan     0.1000    0.2284 #>      4        0.7784            -nan     0.1000    0.1788 #>      5        0.6724            -nan     0.1000    0.1243 #>      6        0.5866            -nan     0.1000    0.0861 #>      7        0.5249            -nan     0.1000    0.0724 #>      8        0.4745            -nan     0.1000    0.0383 #>      9        0.4357            -nan     0.1000    0.0421 #>     10        0.4020            -nan     0.1000    0.0290 #>     20        0.2161            -nan     0.1000   -0.0120 #>     40        0.1053            -nan     0.1000   -0.0208 #>     60        0.0538            -nan     0.1000   -0.0154 #>     80        0.0316            -nan     0.1000   -0.0058 #>    100        0.0241            -nan     0.1000   -0.0079 #>    120        0.0156            -nan     0.1000   -0.0065 #>    140        0.0089            -nan     0.1000   -0.0019 #>    150        0.0082            -nan     0.1000   -0.0027 #>  #> Warning: These variables have zero variances: rural, region #> Warning: variable 7: rural has no variation. #> Warning: variable 8: region has no variation. #> Iter   TrainDeviance   ValidDeviance   StepSize   Improve #>      1        1.3863            -nan     0.1000    0.5074 #>      2        1.0962            -nan     0.1000    0.3353 #>      3        0.9201            -nan     0.1000    0.2291 #>      4        0.7853            -nan     0.1000    0.1192 #>      5        0.6998            -nan     0.1000    0.1370 #>      6        0.6127            -nan     0.1000    0.1093 #>      7        0.5405            -nan     0.1000    0.0874 #>      8        0.4835            -nan     0.1000    0.0564 #>      9        0.4420            -nan     0.1000    0.0383 #>     10        0.4029            -nan     0.1000    0.0480 #>     20        0.2140            -nan     0.1000   -0.0137 #>     40        0.0928            -nan     0.1000   -0.0124 #>     60        0.0434            -nan     0.1000   -0.0048 #>     80        0.0227            -nan     0.1000   -0.0083 #>    100        0.0119            -nan     0.1000   -0.0028 #>    120        0.0067            -nan     0.1000   -0.0007 #>    140        0.0053            -nan     0.1000   -0.0004 #>    150        0.0040            -nan     0.1000   -0.0013 #>  #> Warning: These variables have zero variances: rural, region #> Warning: variable 7: rural has no variation. #> Warning: variable 8: region has no variation. #> Iter   TrainDeviance   ValidDeviance   StepSize   Improve #>      1        1.3863            -nan     0.1000    0.3929 #>      2        1.1497            -nan     0.1000    0.2552 #>      3        1.0034            -nan     0.1000    0.1373 #>      4        0.8851            -nan     0.1000    0.1317 #>      5        0.7928            -nan     0.1000    0.0899 #>      6        0.7193            -nan     0.1000    0.0666 #>      7        0.6664            -nan     0.1000    0.0484 #>      8        0.6273            -nan     0.1000    0.0362 #>      9        0.5923            -nan     0.1000    0.0246 #>     10        0.5597            -nan     0.1000    0.0499 #>     20        0.3766            -nan     0.1000   -0.0098 #>     40        0.2462            -nan     0.1000   -0.0101 #>     60        0.1776            -nan     0.1000   -0.0193 #>     80        0.1260            -nan     0.1000   -0.0042 #>    100        0.0959            -nan     0.1000   -0.0048 #>    120        0.0754            -nan     0.1000   -0.0027 #>    140        0.0626            -nan     0.1000   -0.0024 #>    150        0.0579            -nan     0.1000   -0.0038 #>  #> Warning: These variables have zero variances: rural, region #> Warning: variable 7: rural has no variation. #> Warning: variable 8: region has no variation. #> Iter   TrainDeviance   ValidDeviance   StepSize   Improve #>      1        1.3863            -nan     0.1000    0.4146 #>      2        1.1443            -nan     0.1000    0.2687 #>      3        0.9913            -nan     0.1000    0.2186 #>      4        0.8681            -nan     0.1000    0.1477 #>      5        0.7792            -nan     0.1000    0.1178 #>      6        0.7036            -nan     0.1000    0.0823 #>      7        0.6379            -nan     0.1000    0.0440 #>      8        0.5937            -nan     0.1000    0.0404 #>      9        0.5469            -nan     0.1000    0.0332 #>     10        0.5081            -nan     0.1000    0.0393 #>     20        0.2996            -nan     0.1000    0.0208 #>     40        0.1345            -nan     0.1000   -0.0053 #>     60        0.0698            -nan     0.1000   -0.0032 #>     80        0.0373            -nan     0.1000   -0.0032 #>    100        0.0190            -nan     0.1000   -0.0028 #>    120        0.0113            -nan     0.1000   -0.0011 #>    140        0.0076            -nan     0.1000   -0.0019 #>    150        0.0069            -nan     0.1000   -0.0003 #>  #> Warning: These variables have zero variances: rural, region #> Warning: variable 7: rural has no variation. #> Warning: variable 8: region has no variation. #> Iter   TrainDeviance   ValidDeviance   StepSize   Improve #>      1        1.3863            -nan     0.1000    0.4027 #>      2        1.1461            -nan     0.1000    0.2554 #>      3        0.9904            -nan     0.1000    0.1819 #>      4        0.8702            -nan     0.1000    0.1374 #>      5        0.7712            -nan     0.1000    0.1096 #>      6        0.6954            -nan     0.1000    0.0619 #>      7        0.6412            -nan     0.1000    0.0632 #>      8        0.5931            -nan     0.1000    0.0767 #>      9        0.5429            -nan     0.1000    0.0512 #>     10        0.5006            -nan     0.1000    0.0166 #>     20        0.2926            -nan     0.1000    0.0055 #>     40        0.1307            -nan     0.1000   -0.0053 #>     60        0.0493            -nan     0.1000   -0.0022 #>     80        0.0230            -nan     0.1000   -0.0038 #>    100        0.0141            -nan     0.1000   -0.0007 #>    120        0.0067            -nan     0.1000    0.0003 #>    140        0.0058            -nan     0.1000   -0.0020 #>    150        0.0074            -nan     0.1000   -0.0003 #>  #> Warning: These variables have zero variances: rural, region #> Warning: variable 7: rural has no variation. #> Warning: variable 8: region has no variation. #> Iter   TrainDeviance   ValidDeviance   StepSize   Improve #>      1        1.3863            -nan     0.1000    0.3634 #>      2        1.1580            -nan     0.1000    0.2606 #>      3        0.9903            -nan     0.1000    0.2001 #>      4        0.8664            -nan     0.1000    0.1417 #>      5        0.7736            -nan     0.1000    0.1064 #>      6        0.7101            -nan     0.1000    0.0839 #>      7        0.6529            -nan     0.1000    0.0664 #>      8        0.6056            -nan     0.1000    0.0592 #>      9        0.5662            -nan     0.1000    0.0288 #>     10        0.5339            -nan     0.1000    0.0103 #>     20        0.3404            -nan     0.1000    0.0083 #>     40        0.1857            -nan     0.1000   -0.0055 #>     60        0.1199            -nan     0.1000   -0.0080 #>     80        0.0838            -nan     0.1000   -0.0041 #>    100        0.0503            -nan     0.1000   -0.0047 #>    120        0.0358            -nan     0.1000   -0.0038 #>    140        0.0266            -nan     0.1000   -0.0017 #>    150        0.0233            -nan     0.1000   -0.0014 #>  #> Warning: These variables have zero variances: rural, region #> Warning: variable 7: rural has no variation. #> Warning: variable 8: region has no variation. #> Iter   TrainDeviance   ValidDeviance   StepSize   Improve #>      1        1.3863            -nan     0.1000    0.3844 #>      2        1.1530            -nan     0.1000    0.2538 #>      3        0.9869            -nan     0.1000    0.2057 #>      4        0.8532            -nan     0.1000    0.1627 #>      5        0.7491            -nan     0.1000    0.1204 #>      6        0.6696            -nan     0.1000    0.0572 #>      7        0.6100            -nan     0.1000    0.0650 #>      8        0.5605            -nan     0.1000    0.0478 #>      9        0.5231            -nan     0.1000    0.0565 #>     10        0.4818            -nan     0.1000    0.0118 #>     20        0.2500            -nan     0.1000    0.0115 #>     40        0.0977            -nan     0.1000   -0.0071 #>     60        0.0392            -nan     0.1000   -0.0014 #>     80        0.0249            -nan     0.1000   -0.0049 #>    100        0.0166            -nan     0.1000    0.0001 #>    120        0.0067            -nan     0.1000   -0.0002 #>    140        0.0038            -nan     0.1000   -0.0002 #>    150        0.0032            -nan     0.1000   -0.0003 #>  #> Warning: These variables have zero variances: rural, region #> Warning: variable 7: rural has no variation. #> Warning: variable 8: region has no variation. #> Iter   TrainDeviance   ValidDeviance   StepSize   Improve #>      1        1.3863            -nan     0.1000    0.4169 #>      2        1.1380            -nan     0.1000    0.3004 #>      3        0.9708            -nan     0.1000    0.1708 #>      4        0.8443            -nan     0.1000    0.1552 #>      5        0.7506            -nan     0.1000    0.0770 #>      6        0.6799            -nan     0.1000    0.0852 #>      7        0.6170            -nan     0.1000    0.0893 #>      8        0.5608            -nan     0.1000    0.0589 #>      9        0.5193            -nan     0.1000    0.0516 #>     10        0.4685            -nan     0.1000    0.0450 #>     20        0.2327            -nan     0.1000    0.0030 #>     40        0.0974            -nan     0.1000   -0.0081 #>     60        0.0425            -nan     0.1000   -0.0031 #>     80        0.0124            -nan     0.1000   -0.0011 #>    100        0.0074            -nan     0.1000   -0.0014 #>    120        0.0061            -nan     0.1000   -0.0024 #>    140        0.0023            -nan     0.1000   -0.0003 #>    150        0.0024            -nan     0.1000   -0.0007 #>  #> Warning: These variables have zero variances: rural, region #> Warning: variable 7: rural has no variation. #> Warning: variable 8: region has no variation. #> Iter   TrainDeviance   ValidDeviance   StepSize   Improve #>      1        1.3863            -nan     0.1000    0.4373 #>      2        1.1239            -nan     0.1000    0.3106 #>      3        0.9159            -nan     0.1000    0.2060 #>      4        0.7819            -nan     0.1000    0.1543 #>      5        0.6874            -nan     0.1000    0.1167 #>      6        0.6148            -nan     0.1000    0.0875 #>      7        0.5622            -nan     0.1000    0.0675 #>      8        0.5140            -nan     0.1000    0.0604 #>      9        0.4732            -nan     0.1000    0.0461 #>     10        0.4398            -nan     0.1000    0.0251 #>     20        0.2826            -nan     0.1000    0.0067 #>     40        0.1735            -nan     0.1000   -0.0226 #>     60        0.1150            -nan     0.1000   -0.0106 #>     80        0.0811            -nan     0.1000   -0.0098 #>    100        0.0574            -nan     0.1000   -0.0046 #>    120        0.0430            -nan     0.1000   -0.0021 #>    140        0.0307            -nan     0.1000   -0.0014 #>    150        0.0275            -nan     0.1000   -0.0007 #>  #> Warning: These variables have zero variances: rural, region #> Warning: variable 7: rural has no variation. #> Warning: variable 8: region has no variation. #> Iter   TrainDeviance   ValidDeviance   StepSize   Improve #>      1        1.3863            -nan     0.1000    0.4908 #>      2        1.1015            -nan     0.1000    0.3332 #>      3        0.9194            -nan     0.1000    0.2003 #>      4        0.7818            -nan     0.1000    0.1585 #>      5        0.6773            -nan     0.1000    0.1074 #>      6        0.6058            -nan     0.1000    0.0887 #>      7        0.5460            -nan     0.1000    0.0831 #>      8        0.4945            -nan     0.1000    0.0562 #>      9        0.4546            -nan     0.1000    0.0470 #>     10        0.4160            -nan     0.1000    0.0352 #>     20        0.2328            -nan     0.1000    0.0012 #>     40        0.1042            -nan     0.1000   -0.0101 #>     60        0.0562            -nan     0.1000   -0.0053 #>     80        0.0280            -nan     0.1000   -0.0014 #>    100        0.0158            -nan     0.1000   -0.0025 #>    120        0.0086            -nan     0.1000   -0.0019 #>    140        0.0071            -nan     0.1000   -0.0015 #>    150        0.0062            -nan     0.1000    0.0001 #>  #> Warning: These variables have zero variances: rural, region #> Warning: variable 7: rural has no variation. #> Warning: variable 8: region has no variation. #> Iter   TrainDeviance   ValidDeviance   StepSize   Improve #>      1        1.3863            -nan     0.1000    0.4421 #>      2        1.1229            -nan     0.1000    0.3209 #>      3        0.9393            -nan     0.1000    0.2282 #>      4        0.8026            -nan     0.1000    0.1519 #>      5        0.7014            -nan     0.1000    0.1295 #>      6        0.6202            -nan     0.1000    0.1064 #>      7        0.5466            -nan     0.1000    0.0655 #>      8        0.4893            -nan     0.1000    0.0597 #>      9        0.4455            -nan     0.1000    0.0231 #>     10        0.4112            -nan     0.1000    0.0416 #>     20        0.2329            -nan     0.1000    0.0078 #>     40        0.1103            -nan     0.1000   -0.0120 #>     60        0.0494            -nan     0.1000   -0.0060 #>     80        0.0326            -nan     0.1000   -0.0084 #>    100        0.0203            -nan     0.1000   -0.0018 #>    120        0.0113            -nan     0.1000   -0.0008 #>    140        0.0058            -nan     0.1000   -0.0010 #>    150        0.0057            -nan     0.1000   -0.0019 #>  #> Warning: These variables have zero variances: rural, region #> Warning: variable 7: rural has no variation. #> Warning: variable 8: region has no variation. #> Iter   TrainDeviance   ValidDeviance   StepSize   Improve #>      1        1.3863            -nan     0.1000    0.4660 #>      2        1.0984            -nan     0.1000    0.2814 #>      3        0.9277            -nan     0.1000    0.2153 #>      4        0.8082            -nan     0.1000    0.1481 #>      5        0.7099            -nan     0.1000    0.0996 #>      6        0.6376            -nan     0.1000    0.0534 #>      7        0.5860            -nan     0.1000    0.0750 #>      8        0.5428            -nan     0.1000    0.0498 #>      9        0.5047            -nan     0.1000    0.0505 #>     10        0.4713            -nan     0.1000    0.0268 #>     20        0.3160            -nan     0.1000    0.0079 #>     40        0.2068            -nan     0.1000   -0.0153 #>     60        0.1355            -nan     0.1000   -0.0080 #>     80        0.1044            -nan     0.1000    0.0027 #>    100        0.0705            -nan     0.1000   -0.0033 #>    120        0.0522            -nan     0.1000   -0.0048 #>    140        0.0432            -nan     0.1000   -0.0053 #>    150        0.0383            -nan     0.1000   -0.0012 #>  #> Warning: These variables have zero variances: rural, region #> Warning: variable 7: rural has no variation. #> Warning: variable 8: region has no variation. #> Iter   TrainDeviance   ValidDeviance   StepSize   Improve #>      1        1.3863            -nan     0.1000    0.4110 #>      2        1.1281            -nan     0.1000    0.3077 #>      3        0.9358            -nan     0.1000    0.2059 #>      4        0.8010            -nan     0.1000    0.1334 #>      5        0.7069            -nan     0.1000    0.1178 #>      6        0.6334            -nan     0.1000    0.0873 #>      7        0.5753            -nan     0.1000    0.0773 #>      8        0.5185            -nan     0.1000    0.0439 #>      9        0.4750            -nan     0.1000    0.0350 #>     10        0.4380            -nan     0.1000    0.0304 #>     20        0.2507            -nan     0.1000   -0.0005 #>     40        0.1091            -nan     0.1000    0.0002 #>     60        0.0614            -nan     0.1000   -0.0035 #>     80        0.0348            -nan     0.1000   -0.0037 #>    100        0.0215            -nan     0.1000   -0.0004 #>    120        0.0130            -nan     0.1000    0.0001 #>    140        0.0096            -nan     0.1000   -0.0008 #>    150        0.0080            -nan     0.1000   -0.0024 #>  #> Warning: These variables have zero variances: rural, region #> Warning: variable 7: rural has no variation. #> Warning: variable 8: region has no variation. #> Iter   TrainDeviance   ValidDeviance   StepSize   Improve #>      1        1.3863            -nan     0.1000    0.4247 #>      2        1.1374            -nan     0.1000    0.3238 #>      3        0.9438            -nan     0.1000    0.2233 #>      4        0.8186            -nan     0.1000    0.1610 #>      5        0.7166            -nan     0.1000    0.0965 #>      6        0.6416            -nan     0.1000    0.0761 #>      7        0.5708            -nan     0.1000    0.0799 #>      8        0.5244            -nan     0.1000    0.0348 #>      9        0.4781            -nan     0.1000    0.0524 #>     10        0.4335            -nan     0.1000    0.0091 #>     20        0.2272            -nan     0.1000    0.0053 #>     40        0.0999            -nan     0.1000   -0.0123 #>     60        0.0469            -nan     0.1000   -0.0041 #>     80        0.0214            -nan     0.1000   -0.0017 #>    100        0.0136            -nan     0.1000   -0.0034 #>    120        0.0065            -nan     0.1000   -0.0004 #>    140        0.0040            -nan     0.1000   -0.0003 #>    150        0.0040            -nan     0.1000   -0.0017 #>  #> Warning: These variables have zero variances: rural, region #> Warning: variable 7: rural has no variation. #> Warning: variable 8: region has no variation. #> Iter   TrainDeviance   ValidDeviance   StepSize   Improve #>      1        1.3863            -nan     0.1000    0.4749 #>      2        1.1219            -nan     0.1000    0.3375 #>      3        0.9261            -nan     0.1000    0.2443 #>      4        0.7856            -nan     0.1000    0.1738 #>      5        0.6768            -nan     0.1000    0.1205 #>      6        0.5972            -nan     0.1000    0.0876 #>      7        0.5353            -nan     0.1000    0.0712 #>      8        0.4837            -nan     0.1000    0.0483 #>      9        0.4390            -nan     0.1000    0.0420 #>     10        0.4048            -nan     0.1000    0.0330 #>     20        0.2397            -nan     0.1000    0.0013 #>     40        0.1362            -nan     0.1000   -0.0113 #>     60        0.0924            -nan     0.1000   -0.0051 #>     80        0.0609            -nan     0.1000   -0.0046 #>    100        0.0451            -nan     0.1000   -0.0083 #>    120        0.0288            -nan     0.1000   -0.0050 #>    140        0.0216            -nan     0.1000   -0.0027 #>    150        0.0171            -nan     0.1000   -0.0031 #>  #> Warning: These variables have zero variances: rural, region #> Warning: variable 7: rural has no variation. #> Warning: variable 8: region has no variation. #> Iter   TrainDeviance   ValidDeviance   StepSize   Improve #>      1        1.3863            -nan     0.1000    0.4474 #>      2        1.1017            -nan     0.1000    0.3407 #>      3        0.9048            -nan     0.1000    0.2247 #>      4        0.7741            -nan     0.1000    0.1406 #>      5        0.6799            -nan     0.1000    0.1414 #>      6        0.5992            -nan     0.1000    0.1018 #>      7        0.5334            -nan     0.1000    0.0767 #>      8        0.4845            -nan     0.1000    0.0500 #>      9        0.4406            -nan     0.1000    0.0368 #>     10        0.4076            -nan     0.1000    0.0557 #>     20        0.2029            -nan     0.1000   -0.0001 #>     40        0.0755            -nan     0.1000   -0.0165 #>     60        0.0411            -nan     0.1000   -0.0068 #>     80        0.0233            -nan     0.1000   -0.0077 #>    100        0.0141            -nan     0.1000   -0.0032 #>    120        0.0099            -nan     0.1000   -0.0031 #>    140        0.0049            -nan     0.1000   -0.0009 #>    150        0.0031            -nan     0.1000   -0.0002 #>  #> Warning: These variables have zero variances: rural, region #> Warning: variable 7: rural has no variation. #> Warning: variable 8: region has no variation. #> Iter   TrainDeviance   ValidDeviance   StepSize   Improve #>      1        1.3863            -nan     0.1000    0.4113 #>      2        1.1290            -nan     0.1000    0.3781 #>      3        0.9305            -nan     0.1000    0.2493 #>      4        0.7857            -nan     0.1000    0.1751 #>      5        0.6802            -nan     0.1000    0.1174 #>      6        0.6039            -nan     0.1000    0.1033 #>      7        0.5387            -nan     0.1000    0.0790 #>      8        0.4809            -nan     0.1000    0.0653 #>      9        0.4332            -nan     0.1000    0.0568 #>     10        0.3931            -nan     0.1000    0.0465 #>     20        0.1879            -nan     0.1000    0.0007 #>     40        0.0754            -nan     0.1000   -0.0110 #>     60        0.0392            -nan     0.1000   -0.0060 #>     80        0.0155            -nan     0.1000   -0.0026 #>    100        0.0115            -nan     0.1000    0.0004 #>    120        0.0048            -nan     0.1000   -0.0008 #>    140        0.0020            -nan     0.1000   -0.0000 #>    150        0.0012            -nan     0.1000   -0.0002 #>  #> Warning: These variables have zero variances: rural, region #> Warning: variable 7: rural has no variation. #> Warning: variable 8: region has no variation. #> Iter   TrainDeviance   ValidDeviance   StepSize   Improve #>      1        1.0986            -nan     0.1000    0.2629 #>      2        0.9169            -nan     0.1000    0.2170 #>      3        0.7814            -nan     0.1000    0.1497 #>      4        0.6793            -nan     0.1000    0.1121 #>      5        0.5906            -nan     0.1000    0.0822 #>      6        0.5328            -nan     0.1000    0.0562 #>      7        0.4798            -nan     0.1000    0.0504 #>      8        0.4392            -nan     0.1000    0.0239 #>      9        0.4127            -nan     0.1000    0.0350 #>     10        0.3855            -nan     0.1000    0.0109 #>     20        0.2700            -nan     0.1000    0.0032 #>     40        0.1656            -nan     0.1000   -0.0050 #>     60        0.1320            -nan     0.1000   -0.0074 #>     80        0.0968            -nan     0.1000   -0.0057 #>    100        0.0798            -nan     0.1000   -0.0126 #>    120        0.0645            -nan     0.1000   -0.0092 #>    140        0.0518            -nan     0.1000   -0.0026 #>    150        0.0451            -nan     0.1000   -0.0036 #>  #> Warning: These variables have zero variances: rural, region #> Warning: variable 7: rural has no variation. #> Warning: variable 8: region has no variation. #> Iter   TrainDeviance   ValidDeviance   StepSize   Improve #>      1        1.0986            -nan     0.1000    0.3248 #>      2        0.9063            -nan     0.1000    0.2338 #>      3        0.7657            -nan     0.1000    0.1552 #>      4        0.6611            -nan     0.1000    0.1153 #>      5        0.5878            -nan     0.1000    0.0847 #>      6        0.5192            -nan     0.1000    0.0765 #>      7        0.4622            -nan     0.1000    0.0554 #>      8        0.4238            -nan     0.1000    0.0405 #>      9        0.3926            -nan     0.1000    0.0339 #>     10        0.3652            -nan     0.1000    0.0156 #>     20        0.2148            -nan     0.1000    0.0009 #>     40        0.1138            -nan     0.1000   -0.0058 #>     60        0.0636            -nan     0.1000   -0.0093 #>     80        0.0354            -nan     0.1000   -0.0032 #>    100        0.0208            -nan     0.1000   -0.0005 #>    120        0.0142            -nan     0.1000   -0.0001 #>    140        0.0079            -nan     0.1000   -0.0008 #>    150        0.0062            -nan     0.1000   -0.0006 #>  #> Warning: These variables have zero variances: rural, region #> Warning: variable 7: rural has no variation. #> Warning: variable 8: region has no variation. #> Iter   TrainDeviance   ValidDeviance   StepSize   Improve #>      1        1.0986            -nan     0.1000    0.3055 #>      2        0.9016            -nan     0.1000    0.2213 #>      3        0.7548            -nan     0.1000    0.1420 #>      4        0.6606            -nan     0.1000    0.1226 #>      5        0.5819            -nan     0.1000    0.0782 #>      6        0.5167            -nan     0.1000    0.0474 #>      7        0.4685            -nan     0.1000    0.0325 #>      8        0.4314            -nan     0.1000    0.0574 #>      9        0.3898            -nan     0.1000    0.0387 #>     10        0.3585            -nan     0.1000    0.0127 #>     20        0.1975            -nan     0.1000   -0.0050 #>     40        0.0971            -nan     0.1000   -0.0012 #>     60        0.0506            -nan     0.1000   -0.0007 #>     80        0.0294            -nan     0.1000   -0.0051 #>    100        0.0157            -nan     0.1000   -0.0030 #>    120        0.0085            -nan     0.1000   -0.0012 #>    140        0.0059            -nan     0.1000   -0.0007 #>    150        0.0046            -nan     0.1000   -0.0009 #>  #> Warning: These variables have zero variances: rural, region #> Warning: variable 7: rural has no variation. #> Warning: variable 8: region has no variation. #> Iter   TrainDeviance   ValidDeviance   StepSize   Improve #>      1        1.3863            -nan     0.1000    0.3116 #>      2        1.1662            -nan     0.1000    0.2592 #>      3        1.0177            -nan     0.1000    0.2064 #>      4        0.8893            -nan     0.1000    0.1486 #>      5        0.7979            -nan     0.1000    0.0945 #>      6        0.7297            -nan     0.1000    0.0600 #>      7        0.6691            -nan     0.1000    0.0549 #>      8        0.6203            -nan     0.1000    0.0482 #>      9        0.5792            -nan     0.1000    0.0179 #>     10        0.5444            -nan     0.1000    0.0024 #>     20        0.3675            -nan     0.1000    0.0012 #>     40        0.2322            -nan     0.1000   -0.0025 #>     60        0.1606            -nan     0.1000   -0.0168 #>     80        0.1227            -nan     0.1000   -0.0109 #>    100        0.0943            -nan     0.1000   -0.0182 #>    120        0.0666            -nan     0.1000   -0.0108 #>    140        0.0536            -nan     0.1000   -0.0051 #>    150        0.0458            -nan     0.1000   -0.0031 #>  #> Warning: These variables have zero variances: rural, region #> Warning: variable 7: rural has no variation. #> Warning: variable 8: region has no variation. #> Iter   TrainDeviance   ValidDeviance   StepSize   Improve #>      1        1.3863            -nan     0.1000    0.4365 #>      2        1.1416            -nan     0.1000    0.2478 #>      3        0.9818            -nan     0.1000    0.1601 #>      4        0.8661            -nan     0.1000    0.1418 #>      5        0.7770            -nan     0.1000    0.1158 #>      6        0.6981            -nan     0.1000    0.0725 #>      7        0.6442            -nan     0.1000    0.0732 #>      8        0.5870            -nan     0.1000    0.0610 #>      9        0.5419            -nan     0.1000    0.0327 #>     10        0.5054            -nan     0.1000    0.0199 #>     20        0.2833            -nan     0.1000    0.0011 #>     40        0.1391            -nan     0.1000   -0.0018 #>     60        0.0753            -nan     0.1000   -0.0120 #>     80        0.0380            -nan     0.1000   -0.0038 #>    100        0.0200            -nan     0.1000   -0.0025 #>    120        0.0125            -nan     0.1000   -0.0016 #>    140        0.0086            -nan     0.1000   -0.0025 #>    150        0.0058            -nan     0.1000   -0.0013 #>  #> Warning: These variables have zero variances: rural, region #> Warning: variable 7: rural has no variation. #> Warning: variable 8: region has no variation. #> Iter   TrainDeviance   ValidDeviance   StepSize   Improve #>      1        1.3863            -nan     0.1000    0.3461 #>      2        1.1593            -nan     0.1000    0.2333 #>      3        0.9953            -nan     0.1000    0.2016 #>      4        0.8623            -nan     0.1000    0.1291 #>      5        0.7687            -nan     0.1000    0.1033 #>      6        0.6991            -nan     0.1000    0.0541 #>      7        0.6406            -nan     0.1000    0.0944 #>      8        0.5811            -nan     0.1000    0.0355 #>      9        0.5446            -nan     0.1000    0.0545 #>     10        0.5008            -nan     0.1000    0.0528 #>     20        0.2522            -nan     0.1000    0.0078 #>     40        0.1085            -nan     0.1000   -0.0143 #>     60        0.0498            -nan     0.1000   -0.0055 #>     80        0.0232            -nan     0.1000   -0.0011 #>    100        0.0113            -nan     0.1000   -0.0006 #>    120        0.0065            -nan     0.1000   -0.0018 #>    140        0.0042            -nan     0.1000   -0.0007 #>    150        0.0034            -nan     0.1000   -0.0004 #>  #> Warning: These variables have zero variances: rural, region #> Warning: variable 7: rural has no variation. #> Warning: variable 8: region has no variation. #> Iter   TrainDeviance   ValidDeviance   StepSize   Improve #>      1        1.3863            -nan     0.1000    0.4006 #>      2        1.1666            -nan     0.1000    0.2692 #>      3        0.9729            -nan     0.1000    0.1878 #>      4        0.8447            -nan     0.1000    0.1453 #>      5        0.7533            -nan     0.1000    0.1209 #>      6        0.6787            -nan     0.1000    0.0976 #>      7        0.6210            -nan     0.1000    0.0629 #>      8        0.5717            -nan     0.1000    0.0647 #>      9        0.5263            -nan     0.1000    0.0409 #>     10        0.4961            -nan     0.1000    0.0297 #>     20        0.3331            -nan     0.1000    0.0076 #>     40        0.2113            -nan     0.1000   -0.0176 #>     60        0.1485            -nan     0.1000   -0.0088 #>     80        0.1119            -nan     0.1000   -0.0120 #>    100        0.0854            -nan     0.1000   -0.0028 #>    120        0.0667            -nan     0.1000   -0.0065 #>    140        0.0518            -nan     0.1000   -0.0055 #>    150        0.0451            -nan     0.1000   -0.0062 #>  #> Warning: These variables have zero variances: rural, region #> Warning: variable 7: rural has no variation. #> Warning: variable 8: region has no variation. #> Iter   TrainDeviance   ValidDeviance   StepSize   Improve #>      1        1.3863            -nan     0.1000    0.3820 #>      2        1.1507            -nan     0.1000    0.3077 #>      3        0.9674            -nan     0.1000    0.1769 #>      4        0.8424            -nan     0.1000    0.1640 #>      5        0.7471            -nan     0.1000    0.1132 #>      6        0.6692            -nan     0.1000    0.0908 #>      7        0.6097            -nan     0.1000    0.0736 #>      8        0.5494            -nan     0.1000    0.0571 #>      9        0.5040            -nan     0.1000    0.0381 #>     10        0.4680            -nan     0.1000    0.0312 #>     20        0.2870            -nan     0.1000    0.0073 #>     40        0.1366            -nan     0.1000   -0.0063 #>     60        0.0773            -nan     0.1000   -0.0084 #>     80        0.0467            -nan     0.1000   -0.0042 #>    100        0.0281            -nan     0.1000   -0.0026 #>    120        0.0162            -nan     0.1000   -0.0029 #>    140        0.0100            -nan     0.1000   -0.0004 #>    150        0.0079            -nan     0.1000   -0.0019 #>  #> Warning: These variables have zero variances: rural, region #> Warning: variable 7: rural has no variation. #> Warning: variable 8: region has no variation. #> Iter   TrainDeviance   ValidDeviance   StepSize   Improve #>      1        1.3863            -nan     0.1000    0.4725 #>      2        1.1253            -nan     0.1000    0.2899 #>      3        0.9464            -nan     0.1000    0.1918 #>      4        0.8177            -nan     0.1000    0.1575 #>      5        0.7181            -nan     0.1000    0.0902 #>      6        0.6444            -nan     0.1000    0.0708 #>      7        0.5860            -nan     0.1000    0.0192 #>      8        0.5404            -nan     0.1000    0.0459 #>      9        0.5014            -nan     0.1000    0.0408 #>     10        0.4643            -nan     0.1000    0.0419 #>     20        0.2641            -nan     0.1000   -0.0040 #>     40        0.1156            -nan     0.1000   -0.0081 #>     60        0.0647            -nan     0.1000   -0.0033 #>     80        0.0363            -nan     0.1000   -0.0005 #>    100        0.0197            -nan     0.1000   -0.0012 #>    120        0.0119            -nan     0.1000   -0.0013 #>    140        0.0087            -nan     0.1000   -0.0022 #>    150        0.0072            -nan     0.1000   -0.0002 #>  #> Warning: These variables have zero variances: rural, region #> Warning: variable 7: rural has no variation. #> Warning: variable 8: region has no variation. #> Iter   TrainDeviance   ValidDeviance   StepSize   Improve #>      1        1.0986            -nan     0.1000    0.3749 #>      2        0.8862            -nan     0.1000    0.2509 #>      3        0.7368            -nan     0.1000    0.1736 #>      4        0.6194            -nan     0.1000    0.1253 #>      5        0.5429            -nan     0.1000    0.0917 #>      6        0.4770            -nan     0.1000    0.0702 #>      7        0.4259            -nan     0.1000    0.0284 #>      8        0.3928            -nan     0.1000    0.0373 #>      9        0.3624            -nan     0.1000    0.0272 #>     10        0.3421            -nan     0.1000    0.0194 #>     20        0.2074            -nan     0.1000   -0.0052 #>     40        0.1236            -nan     0.1000   -0.0102 #>     60        0.0765            -nan     0.1000   -0.0030 #>     80        0.0471            -nan     0.1000   -0.0005 #>    100        0.0339            -nan     0.1000   -0.0024 #>    120        0.0217            -nan     0.1000   -0.0020 #>    140        0.0174            -nan     0.1000   -0.0022 #>    150        0.0155            -nan     0.1000   -0.0018 #>  #> Warning: These variables have zero variances: rural, region #> Warning: variable 7: rural has no variation. #> Warning: variable 8: region has no variation. #> Iter   TrainDeviance   ValidDeviance   StepSize   Improve #>      1        1.0986            -nan     0.1000    0.3684 #>      2        0.8940            -nan     0.1000    0.2533 #>      3        0.7340            -nan     0.1000    0.1778 #>      4        0.6164            -nan     0.1000    0.1122 #>      5        0.5419            -nan     0.1000    0.0987 #>      6        0.4741            -nan     0.1000    0.0693 #>      7        0.4254            -nan     0.1000    0.0508 #>      8        0.3854            -nan     0.1000    0.0325 #>      9        0.3547            -nan     0.1000    0.0388 #>     10        0.3266            -nan     0.1000    0.0070 #>     20        0.1778            -nan     0.1000   -0.0004 #>     40        0.0749            -nan     0.1000   -0.0061 #>     60        0.0385            -nan     0.1000    0.0001 #>     80        0.0188            -nan     0.1000   -0.0016 #>    100        0.0176            -nan     0.1000   -0.0027 #>    120        0.0076            -nan     0.1000   -0.0017 #>    140        0.0090            -nan     0.1000   -0.0038 #>    150        0.0047            -nan     0.1000   -0.0009 #>  #> Warning: These variables have zero variances: rural, region #> Warning: variable 7: rural has no variation. #> Warning: variable 8: region has no variation. #> Iter   TrainDeviance   ValidDeviance   StepSize   Improve #>      1        1.0986            -nan     0.1000    0.3076 #>      2        0.8990            -nan     0.1000    0.2732 #>      3        0.7404            -nan     0.1000    0.1867 #>      4        0.6188            -nan     0.1000    0.1254 #>      5        0.5415            -nan     0.1000    0.1116 #>      6        0.4750            -nan     0.1000    0.0810 #>      7        0.4174            -nan     0.1000    0.0492 #>      8        0.3800            -nan     0.1000    0.0556 #>      9        0.3425            -nan     0.1000    0.0416 #>     10        0.3143            -nan     0.1000    0.0256 #>     20        0.1798            -nan     0.1000    0.0060 #>     40        0.0673            -nan     0.1000   -0.0052 #>     60        0.0332            -nan     0.1000   -0.0040 #>     80        0.0167            -nan     0.1000   -0.0027 #>    100        0.0095            -nan     0.1000   -0.0028 #>    120        0.0070            -nan     0.1000   -0.0017 #>    140        0.0035            -nan     0.1000   -0.0003 #>    150        0.0038            -nan     0.1000   -0.0007 #>  #> Warning: These variables have zero variances: rural, region #> Warning: variable 7: rural has no variation. #> Warning: variable 8: region has no variation. #> Iter   TrainDeviance   ValidDeviance   StepSize   Improve #>      1        1.0986            -nan     0.1000    0.3187 #>      2        0.9195            -nan     0.1000    0.2377 #>      3        0.7994            -nan     0.1000    0.1502 #>      4        0.6966            -nan     0.1000    0.1054 #>      5        0.6320            -nan     0.1000    0.0825 #>      6        0.5626            -nan     0.1000    0.0524 #>      7        0.5220            -nan     0.1000    0.0320 #>      8        0.4840            -nan     0.1000    0.0306 #>      9        0.4553            -nan     0.1000    0.0333 #>     10        0.4293            -nan     0.1000    0.0064 #>     20        0.3020            -nan     0.1000   -0.0110 #>     40        0.1914            -nan     0.1000   -0.0276 #>     60        0.1303            -nan     0.1000   -0.0235 #>     80        0.0953            -nan     0.1000   -0.0211 #>    100        0.0651            -nan     0.1000   -0.0073 #>    120        0.0487            -nan     0.1000   -0.0068 #>    140        0.0340            -nan     0.1000   -0.0028 #>    150        0.0294            -nan     0.1000   -0.0029 #>  #> Warning: These variables have zero variances: rural, region #> Warning: variable 7: rural has no variation. #> Warning: variable 8: region has no variation. #> Iter   TrainDeviance   ValidDeviance   StepSize   Improve #>      1        1.0986            -nan     0.1000    0.2995 #>      2        0.9072            -nan     0.1000    0.2077 #>      3        0.7641            -nan     0.1000    0.1318 #>      4        0.6676            -nan     0.1000    0.0842 #>      5        0.6028            -nan     0.1000    0.0705 #>      6        0.5390            -nan     0.1000    0.0361 #>      7        0.4984            -nan     0.1000    0.0355 #>      8        0.4597            -nan     0.1000    0.0318 #>      9        0.4257            -nan     0.1000    0.0195 #>     10        0.3978            -nan     0.1000    0.0133 #>     20        0.2514            -nan     0.1000    0.0057 #>     40        0.1036            -nan     0.1000   -0.0048 #>     60        0.0540            -nan     0.1000    0.0004 #>     80        0.0300            -nan     0.1000   -0.0009 #>    100        0.0157            -nan     0.1000   -0.0025 #>    120        0.0084            -nan     0.1000   -0.0008 #>    140        0.0046            -nan     0.1000   -0.0002 #>    150        0.0033            -nan     0.1000   -0.0004 #>  #> Warning: These variables have zero variances: rural, region #> Warning: variable 7: rural has no variation. #> Warning: variable 8: region has no variation. #> Iter   TrainDeviance   ValidDeviance   StepSize   Improve #>      1        1.0986            -nan     0.1000    0.3086 #>      2        0.9044            -nan     0.1000    0.2113 #>      3        0.7734            -nan     0.1000    0.1650 #>      4        0.6643            -nan     0.1000    0.1225 #>      5        0.5889            -nan     0.1000    0.0839 #>      6        0.5319            -nan     0.1000    0.0759 #>      7        0.4800            -nan     0.1000    0.0508 #>      8        0.4396            -nan     0.1000    0.0344 #>      9        0.4066            -nan     0.1000    0.0189 #>     10        0.3837            -nan     0.1000    0.0111 #>     20        0.2186            -nan     0.1000   -0.0057 #>     40        0.0853            -nan     0.1000   -0.0012 #>     60        0.0362            -nan     0.1000    0.0013 #>     80        0.0162            -nan     0.1000   -0.0028 #>    100        0.0076            -nan     0.1000   -0.0001 #>    120        0.0041            -nan     0.1000   -0.0003 #>    140        0.0026            -nan     0.1000   -0.0003 #>    150        0.0030            -nan     0.1000   -0.0015 #>  #> Warning: These variables have zero variances: rural, region #> Warning: variable 7: rural has no variation. #> Warning: variable 8: region has no variation. #> Iter   TrainDeviance   ValidDeviance   StepSize   Improve #>      1        1.3863            -nan     0.1000    0.4470 #>      2        1.1329            -nan     0.1000    0.2815 #>      3        0.9475            -nan     0.1000    0.2047 #>      4        0.8185            -nan     0.1000    0.1299 #>      5        0.7253            -nan     0.1000    0.1148 #>      6        0.6617            -nan     0.1000    0.0848 #>      7        0.6018            -nan     0.1000    0.0511 #>      8        0.5580            -nan     0.1000    0.0416 #>      9        0.5275            -nan     0.1000    0.0369 #>     10        0.4931            -nan     0.1000    0.0075 #>     20        0.3362            -nan     0.1000   -0.0154 #>     40        0.2205            -nan     0.1000   -0.0058 #>     60        0.1756            -nan     0.1000   -0.0111 #>     80        0.1363            -nan     0.1000   -0.0067 #>    100        0.1059            -nan     0.1000   -0.0061 #>    120        0.0870            -nan     0.1000   -0.0205 #>    140        0.0725            -nan     0.1000   -0.0025 #>    150        0.0672            -nan     0.1000   -0.0069 #>  #> Warning: These variables have zero variances: rural, region #> Warning: variable 7: rural has no variation. #> Warning: variable 8: region has no variation. #> Iter   TrainDeviance   ValidDeviance   StepSize   Improve #>      1        1.3863            -nan     0.1000    0.4125 #>      2        1.1304            -nan     0.1000    0.3072 #>      3        0.9527            -nan     0.1000    0.2105 #>      4        0.8281            -nan     0.1000    0.1469 #>      5        0.7309            -nan     0.1000    0.1206 #>      6        0.6595            -nan     0.1000    0.0795 #>      7        0.6006            -nan     0.1000    0.0702 #>      8        0.5540            -nan     0.1000    0.0461 #>      9        0.5164            -nan     0.1000    0.0268 #>     10        0.4855            -nan     0.1000    0.0209 #>     20        0.3043            -nan     0.1000   -0.0272 #>     40        0.1524            -nan     0.1000   -0.0107 #>     60        0.0824            -nan     0.1000   -0.0025 #>     80        0.0556            -nan     0.1000   -0.0006 #>    100        0.0291            -nan     0.1000   -0.0034 #>    120        0.0205            -nan     0.1000   -0.0021 #>    140        0.0121            -nan     0.1000   -0.0014 #>    150        0.0109            -nan     0.1000   -0.0017 #>  #> Warning: These variables have zero variances: rural, region #> Warning: variable 7: rural has no variation. #> Warning: variable 8: region has no variation. #> Iter   TrainDeviance   ValidDeviance   StepSize   Improve #>      1        1.3863            -nan     0.1000    0.4421 #>      2        1.1136            -nan     0.1000    0.2921 #>      3        0.9511            -nan     0.1000    0.1913 #>      4        0.8323            -nan     0.1000    0.1532 #>      5        0.7349            -nan     0.1000    0.0874 #>      6        0.6683            -nan     0.1000    0.0770 #>      7        0.6026            -nan     0.1000    0.0625 #>      8        0.5536            -nan     0.1000    0.0413 #>      9        0.5194            -nan     0.1000    0.0224 #>     10        0.4834            -nan     0.1000    0.0231 #>     20        0.2928            -nan     0.1000    0.0023 #>     40        0.1230            -nan     0.1000   -0.0087 #>     60        0.0655            -nan     0.1000   -0.0081 #>     80        0.0371            -nan     0.1000   -0.0042 #>    100        0.0217            -nan     0.1000   -0.0024 #>    120        0.0149            -nan     0.1000   -0.0027 #>    140        0.0089            -nan     0.1000   -0.0006 #>    150        0.0066            -nan     0.1000   -0.0001 #>  #> Warning: These variables have zero variances: rural, region #> Warning: variable 7: rural has no variation. #> Warning: variable 8: region has no variation. #> Iter   TrainDeviance   ValidDeviance   StepSize   Improve #>      1        1.0986            -nan     0.1000    0.3442 #>      2        0.8957            -nan     0.1000    0.1943 #>      3        0.7539            -nan     0.1000    0.1646 #>      4        0.6614            -nan     0.1000    0.1227 #>      5        0.5846            -nan     0.1000    0.0868 #>      6        0.5294            -nan     0.1000    0.0676 #>      7        0.4759            -nan     0.1000    0.0513 #>      8        0.4433            -nan     0.1000    0.0334 #>      9        0.4136            -nan     0.1000    0.0405 #>     10        0.3823            -nan     0.1000    0.0070 #>     20        0.2535            -nan     0.1000   -0.0232 #>     40        0.1664            -nan     0.1000   -0.0110 #>     60        0.1214            -nan     0.1000   -0.0103 #>     80        0.0978            -nan     0.1000   -0.0246 #>    100        0.0672            -nan     0.1000   -0.0020 #>    120        0.0524            -nan     0.1000   -0.0033 #>    140        0.0413            -nan     0.1000   -0.0023 #>    150        0.0386            -nan     0.1000   -0.0086 #>  #> Warning: These variables have zero variances: rural, region #> Warning: variable 7: rural has no variation. #> Warning: variable 8: region has no variation. #> Iter   TrainDeviance   ValidDeviance   StepSize   Improve #>      1        1.0986            -nan     0.1000    0.3316 #>      2        0.9102            -nan     0.1000    0.1661 #>      3        0.7843            -nan     0.1000    0.1582 #>      4        0.6652            -nan     0.1000    0.1029 #>      5        0.5875            -nan     0.1000    0.0864 #>      6        0.5261            -nan     0.1000    0.0719 #>      7        0.4742            -nan     0.1000    0.0475 #>      8        0.4342            -nan     0.1000    0.0400 #>      9        0.3998            -nan     0.1000    0.0392 #>     10        0.3653            -nan     0.1000    0.0225 #>     20        0.2156            -nan     0.1000   -0.0164 #>     40        0.1119            -nan     0.1000   -0.0034 #>     60        0.0509            -nan     0.1000   -0.0007 #>     80        0.0266            -nan     0.1000   -0.0026 #>    100        0.0140            -nan     0.1000   -0.0010 #>    120        0.0096            -nan     0.1000   -0.0007 #>    140        0.0076            -nan     0.1000   -0.0020 #>    150        0.0052            -nan     0.1000   -0.0010 #>  #> Warning: These variables have zero variances: rural, region #> Warning: variable 7: rural has no variation. #> Warning: variable 8: region has no variation. #> Iter   TrainDeviance   ValidDeviance   StepSize   Improve #>      1        1.0986            -nan     0.1000    0.3298 #>      2        0.8902            -nan     0.1000    0.1890 #>      3        0.7489            -nan     0.1000    0.1647 #>      4        0.6484            -nan     0.1000    0.1084 #>      5        0.5689            -nan     0.1000    0.0853 #>      6        0.5069            -nan     0.1000    0.0577 #>      7        0.4598            -nan     0.1000    0.0439 #>      8        0.4219            -nan     0.1000    0.0247 #>      9        0.3948            -nan     0.1000    0.0334 #>     10        0.3678            -nan     0.1000    0.0146 #>     20        0.2009            -nan     0.1000   -0.0217 #>     40        0.0806            -nan     0.1000    0.0024 #>     60        0.0374            -nan     0.1000   -0.0026 #>     80        0.0174            -nan     0.1000   -0.0025 #>    100        0.0156            -nan     0.1000   -0.0042 #>    120        0.0076            -nan     0.1000   -0.0013 #>    140        0.0054            -nan     0.1000   -0.0018 #>    150        0.0074            -nan     0.1000   -0.0003 #>  #> Warning: These variables have zero variances: rural, region #> Warning: variable 7: rural has no variation. #> Warning: variable 8: region has no variation. #> Iter   TrainDeviance   ValidDeviance   StepSize   Improve #>      1        1.3863            -nan     0.1000    0.4476 #>      2        1.1134            -nan     0.1000    0.3665 #>      3        0.8914            -nan     0.1000    0.2458 #>      4        0.7430            -nan     0.1000    0.1871 #>      5        0.6380            -nan     0.1000    0.1345 #>      6        0.5481            -nan     0.1000    0.1127 #>      7        0.4816            -nan     0.1000    0.0787 #>      8        0.4303            -nan     0.1000    0.0519 #>      9        0.3853            -nan     0.1000    0.0502 #>     10        0.3537            -nan     0.1000    0.0408 #>     20        0.2080            -nan     0.1000   -0.0142 #>     40        0.1159            -nan     0.1000   -0.0072 #>     60        0.0780            -nan     0.1000   -0.0006 #>     80        0.0613            -nan     0.1000   -0.0098 #>    100        0.0364            -nan     0.1000   -0.0099 #>    120        0.0313            -nan     0.1000   -0.0052 #>    140        0.0213            -nan     0.1000   -0.0039 #>    150        0.0174            -nan     0.1000   -0.0008 #>  #> Warning: These variables have zero variances: rural, region #> Warning: variable 7: rural has no variation. #> Warning: variable 8: region has no variation. #> Iter   TrainDeviance   ValidDeviance   StepSize   Improve #>      1        1.3863            -nan     0.1000    0.4995 #>      2        1.0878            -nan     0.1000    0.3222 #>      3        0.8856            -nan     0.1000    0.2636 #>      4        0.7366            -nan     0.1000    0.1889 #>      5        0.6275            -nan     0.1000    0.1132 #>      6        0.5499            -nan     0.1000    0.1031 #>      7        0.4798            -nan     0.1000    0.0742 #>      8        0.4278            -nan     0.1000    0.0630 #>      9        0.3836            -nan     0.1000    0.0368 #>     10        0.3500            -nan     0.1000    0.0316 #>     20        0.1851            -nan     0.1000    0.0070 #>     40        0.0700            -nan     0.1000   -0.0107 #>     60        0.0445            -nan     0.1000   -0.0245 #>     80        0.0222            -nan     0.1000   -0.0061 #>    100        0.0159            -nan     0.1000   -0.0037 #>    120        0.0094            -nan     0.1000   -0.0026 #>    140        0.0044            -nan     0.1000   -0.0008 #>    150        0.0031            -nan     0.1000   -0.0006 #>  #> Warning: These variables have zero variances: rural, region #> Warning: variable 7: rural has no variation. #> Warning: variable 8: region has no variation. #> Iter   TrainDeviance   ValidDeviance   StepSize   Improve #>      1        1.3863            -nan     0.1000    0.5416 #>      2        1.0869            -nan     0.1000    0.3521 #>      3        0.8849            -nan     0.1000    0.2206 #>      4        0.7366            -nan     0.1000    0.1605 #>      5        0.6359            -nan     0.1000    0.1409 #>      6        0.5484            -nan     0.1000    0.1016 #>      7        0.4861            -nan     0.1000    0.0810 #>      8        0.4342            -nan     0.1000    0.0506 #>      9        0.3932            -nan     0.1000    0.0500 #>     10        0.3579            -nan     0.1000    0.0335 #>     20        0.1851            -nan     0.1000   -0.0198 #>     40        0.0665            -nan     0.1000   -0.0082 #>     60        0.0255            -nan     0.1000   -0.0020 #>     80        0.0144            -nan     0.1000   -0.0034 #>    100        0.0108            -nan     0.1000   -0.0017 #>    120        0.0038            -nan     0.1000   -0.0002 #>    140        0.0021            -nan     0.1000   -0.0005 #>    150        0.0020            -nan     0.1000   -0.0004 #>  #> Warning: These variables have zero variances: rural, region #> Warning: variable 7: rural has no variation. #> Warning: variable 8: region has no variation. #> Iter   TrainDeviance   ValidDeviance   StepSize   Improve #>      1        1.3863            -nan     0.1000    0.4950 #>      2        1.1166            -nan     0.1000    0.2942 #>      3        0.9390            -nan     0.1000    0.2163 #>      4        0.7949            -nan     0.1000    0.1714 #>      5        0.6980            -nan     0.1000    0.1042 #>      6        0.6203            -nan     0.1000    0.0787 #>      7        0.5609            -nan     0.1000    0.0882 #>      8        0.5063            -nan     0.1000    0.0504 #>      9        0.4637            -nan     0.1000    0.0195 #>     10        0.4296            -nan     0.1000    0.0203 #>     20        0.2686            -nan     0.1000   -0.0037 #>     40        0.1588            -nan     0.1000   -0.0104 #>     60        0.1069            -nan     0.1000   -0.0139 #>     80        0.0850            -nan     0.1000   -0.0080 #>    100        0.0636            -nan     0.1000   -0.0083 #>    120        0.0473            -nan     0.1000   -0.0032 #>    140        0.0343            -nan     0.1000   -0.0032 #>    150        0.0276            -nan     0.1000   -0.0031 #>  #> Warning: These variables have zero variances: rural, region #> Warning: variable 7: rural has no variation. #> Warning: variable 8: region has no variation. #> Iter   TrainDeviance   ValidDeviance   StepSize   Improve #>      1        1.3863            -nan     0.1000    0.3918 #>      2        1.1440            -nan     0.1000    0.3312 #>      3        0.9416            -nan     0.1000    0.2302 #>      4        0.8080            -nan     0.1000    0.1721 #>      5        0.6970            -nan     0.1000    0.1209 #>      6        0.6147            -nan     0.1000    0.0891 #>      7        0.5499            -nan     0.1000    0.0722 #>      8        0.5005            -nan     0.1000    0.0694 #>      9        0.4541            -nan     0.1000    0.0703 #>     10        0.4142            -nan     0.1000    0.0403 #>     20        0.2361            -nan     0.1000   -0.0083 #>     40        0.1057            -nan     0.1000   -0.0094 #>     60        0.0500            -nan     0.1000   -0.0055 #>     80        0.0256            -nan     0.1000   -0.0045 #>    100        0.0152            -nan     0.1000   -0.0009 #>    120        0.0104            -nan     0.1000   -0.0005 #>    140        0.0058            -nan     0.1000    0.0004 #>    150        0.0053            -nan     0.1000   -0.0007 #>  #> Warning: These variables have zero variances: rural, region #> Warning: variable 7: rural has no variation. #> Warning: variable 8: region has no variation. #> Iter   TrainDeviance   ValidDeviance   StepSize   Improve #>      1        1.3863            -nan     0.1000    0.4189 #>      2        1.1343            -nan     0.1000    0.2796 #>      3        0.9499            -nan     0.1000    0.2190 #>      4        0.8124            -nan     0.1000    0.1528 #>      5        0.7136            -nan     0.1000    0.1324 #>      6        0.6289            -nan     0.1000    0.0991 #>      7        0.5606            -nan     0.1000    0.0716 #>      8        0.5096            -nan     0.1000    0.0653 #>      9        0.4640            -nan     0.1000    0.0545 #>     10        0.4269            -nan     0.1000    0.0488 #>     20        0.2405            -nan     0.1000   -0.0074 #>     40        0.0926            -nan     0.1000   -0.0036 #>     60        0.0451            -nan     0.1000   -0.0094 #>     80        0.0224            -nan     0.1000   -0.0025 #>    100        0.0132            -nan     0.1000   -0.0022 #>    120        0.0097            -nan     0.1000   -0.0046 #>    140        0.0055            -nan     0.1000   -0.0013 #>    150        0.0051            -nan     0.1000   -0.0023 #>  #> Warning: These variables have zero variances: rural, region #> Warning: variable 7: rural has no variation. #> Warning: variable 8: region has no variation. #> Iter   TrainDeviance   ValidDeviance   StepSize   Improve #>      1        1.3863            -nan     0.1000    0.5080 #>      2        1.0939            -nan     0.1000    0.2844 #>      3        0.9206            -nan     0.1000    0.2558 #>      4        0.7803            -nan     0.1000    0.1825 #>      5        0.6764            -nan     0.1000    0.1423 #>      6        0.5907            -nan     0.1000    0.0742 #>      7        0.5327            -nan     0.1000    0.0850 #>      8        0.4767            -nan     0.1000    0.0623 #>      9        0.4323            -nan     0.1000    0.0394 #>     10        0.3995            -nan     0.1000    0.0391 #>     20        0.2073            -nan     0.1000    0.0206 #>     40        0.0778            -nan     0.1000    0.0013 #>     60        0.0393            -nan     0.1000   -0.0085 #>     80        0.0226            -nan     0.1000   -0.0038 #>    100        0.0121            -nan     0.1000   -0.0002 #>    120        0.0065            -nan     0.1000   -0.0001 #>    140        0.0036            -nan     0.1000   -0.0005 #>    150        0.0028            -nan     0.1000   -0.0002 #>  #> Warning: These variables have zero variances: rural, region #> Warning: variable 7: rural has no variation. #> Warning: variable 8: region has no variation. #> Iter   TrainDeviance   ValidDeviance   StepSize   Improve #>      1        1.3863            -nan     0.1000    0.5141 #>      2        1.0925            -nan     0.1000    0.3242 #>      3        0.8942            -nan     0.1000    0.2292 #>      4        0.7573            -nan     0.1000    0.1777 #>      5        0.6520            -nan     0.1000    0.1393 #>      6        0.5677            -nan     0.1000    0.0962 #>      7        0.5038            -nan     0.1000    0.0708 #>      8        0.4535            -nan     0.1000    0.0735 #>      9        0.4043            -nan     0.1000    0.0385 #>     10        0.3644            -nan     0.1000    0.0504 #>     20        0.1455            -nan     0.1000   -0.0028 #>     40        0.0343            -nan     0.1000   -0.0017 #>     60        0.0120            -nan     0.1000    0.0003 #>     80        0.0039            -nan     0.1000    0.0001 #>    100        0.0017            -nan     0.1000   -0.0001 #>    120        0.0010            -nan     0.1000   -0.0001 #>    140        0.0005            -nan     0.1000   -0.0000 #>    150        0.0002            -nan     0.1000   -0.0001 #>  #> Warning: These variables have zero variances: rural, region #> Warning: variable 7: rural has no variation. #> Warning: variable 8: region has no variation. #> Iter   TrainDeviance   ValidDeviance   StepSize   Improve #>      1        1.3863            -nan     0.1000    0.4926 #>      2        1.1081            -nan     0.1000    0.3095 #>      3        0.9129            -nan     0.1000    0.2255 #>      4        0.7855            -nan     0.1000    0.1564 #>      5        0.6825            -nan     0.1000    0.1397 #>      6        0.5971            -nan     0.1000    0.1115 #>      7        0.5229            -nan     0.1000    0.0899 #>      8        0.4642            -nan     0.1000    0.0707 #>      9        0.4145            -nan     0.1000    0.0422 #>     10        0.3793            -nan     0.1000    0.0516 #>     20        0.1450            -nan     0.1000    0.0049 #>     40        0.0288            -nan     0.1000   -0.0002 #>     60        0.0095            -nan     0.1000   -0.0001 #>     80        0.0065            -nan     0.1000   -0.0002 #>    100        0.0043            -nan     0.1000   -0.0007 #>    120        0.0033            -nan     0.1000    0.0001 #>    140        0.0014            -nan     0.1000   -0.0002 #>    150        0.0007            -nan     0.1000    0.0001 #>  #> Warning: These variables have zero variances: rural, region #> Warning: variable 7: rural has no variation. #> Warning: variable 8: region has no variation. #> Iter   TrainDeviance   ValidDeviance   StepSize   Improve #>      1        1.3863            -nan     0.1000    0.4039 #>      2        1.1567            -nan     0.1000    0.2782 #>      3        0.9932            -nan     0.1000    0.2008 #>      4        0.8583            -nan     0.1000    0.0978 #>      5        0.7791            -nan     0.1000    0.1137 #>      6        0.7024            -nan     0.1000    0.0701 #>      7        0.6400            -nan     0.1000    0.0470 #>      8        0.5951            -nan     0.1000    0.0409 #>      9        0.5558            -nan     0.1000    0.0287 #>     10        0.5233            -nan     0.1000    0.0188 #>     20        0.3573            -nan     0.1000   -0.0123 #>     40        0.2323            -nan     0.1000    0.0071 #>     60        0.1569            -nan     0.1000   -0.0218 #>     80        0.1187            -nan     0.1000   -0.0019 #>    100        0.0929            -nan     0.1000   -0.0127 #>    120        0.0655            -nan     0.1000   -0.0017 #>    140        0.0529            -nan     0.1000   -0.0079 #>    150        0.0477            -nan     0.1000   -0.0057 #>  #> Warning: These variables have zero variances: rural, region #> Warning: variable 7: rural has no variation. #> Warning: variable 8: region has no variation. #> Iter   TrainDeviance   ValidDeviance   StepSize   Improve #>      1        1.3863            -nan     0.1000    0.3637 #>      2        1.1616            -nan     0.1000    0.2886 #>      3        0.9820            -nan     0.1000    0.2267 #>      4        0.8512            -nan     0.1000    0.1341 #>      5        0.7572            -nan     0.1000    0.1066 #>      6        0.6877            -nan     0.1000    0.0787 #>      7        0.6265            -nan     0.1000    0.0605 #>      8        0.5781            -nan     0.1000    0.0667 #>      9        0.5370            -nan     0.1000    0.0447 #>     10        0.5011            -nan     0.1000    0.0424 #>     20        0.2762            -nan     0.1000   -0.0003 #>     40        0.1324            -nan     0.1000   -0.0023 #>     60        0.0595            -nan     0.1000   -0.0039 #>     80        0.0326            -nan     0.1000   -0.0079 #>    100        0.0211            -nan     0.1000   -0.0009 #>    120        0.0118            -nan     0.1000   -0.0036 #>    140        0.0088            -nan     0.1000   -0.0035 #>    150        0.0071            -nan     0.1000   -0.0014 #>  #> Warning: These variables have zero variances: rural, region #> Warning: variable 7: rural has no variation. #> Warning: variable 8: region has no variation. #> Iter   TrainDeviance   ValidDeviance   StepSize   Improve #>      1        1.3863            -nan     0.1000    0.4299 #>      2        1.1417            -nan     0.1000    0.2670 #>      3        0.9770            -nan     0.1000    0.1645 #>      4        0.8527            -nan     0.1000    0.1250 #>      5        0.7590            -nan     0.1000    0.0857 #>      6        0.6857            -nan     0.1000    0.0884 #>      7        0.6233            -nan     0.1000    0.0672 #>      8        0.5765            -nan     0.1000    0.0674 #>      9        0.5352            -nan     0.1000    0.0248 #>     10        0.5023            -nan     0.1000    0.0132 #>     20        0.2597            -nan     0.1000    0.0114 #>     40        0.1035            -nan     0.1000   -0.0055 #>     60        0.0506            -nan     0.1000   -0.0080 #>     80        0.0238            -nan     0.1000   -0.0039 #>    100        0.0133            -nan     0.1000   -0.0024 #>    120        0.0086            -nan     0.1000   -0.0013 #>    140        0.0067            -nan     0.1000   -0.0004 #>    150        0.0059            -nan     0.1000   -0.0003 #>  #> Warning: These variables have zero variances: rural, region #> Warning: variable 7: rural has no variation. #> Warning: variable 8: region has no variation. #> Iter   TrainDeviance   ValidDeviance   StepSize   Improve #>      1        1.3863            -nan     0.1000    0.4034 #>      2        1.1315            -nan     0.1000    0.2982 #>      3        0.9484            -nan     0.1000    0.1953 #>      4        0.8330            -nan     0.1000    0.1032 #>      5        0.7458            -nan     0.1000    0.1197 #>      6        0.6645            -nan     0.1000    0.0658 #>      7        0.6150            -nan     0.1000    0.0827 #>      8        0.5678            -nan     0.1000    0.0442 #>      9        0.5287            -nan     0.1000    0.0361 #>     10        0.4995            -nan     0.1000    0.0194 #>     20        0.3532            -nan     0.1000   -0.0001 #>     40        0.2508            -nan     0.1000   -0.0198 #>     50        0.2156            -nan     0.1000   -0.0377 #>  #> Warning: variable 7: rural has no variation. #> Warning: variable 8: region has no variation. #> Iter   TrainDeviance   ValidDeviance   StepSize   Improve #>      1        1.3863            -nan     0.0010    0.0054 #>      2        1.3835            -nan     0.0010    0.0052 #>      3        1.3806            -nan     0.0010    0.0048 #>      4        1.3780            -nan     0.0010    0.0050 #>      5        1.3752            -nan     0.0010    0.0053 #>      6        1.3724            -nan     0.0010    0.0052 #>      7        1.3694            -nan     0.0010    0.0052 #>      8        1.3666            -nan     0.0010    0.0050 #>      9        1.3638            -nan     0.0010    0.0048 #>     10        1.3611            -nan     0.0010    0.0049 #>     20        1.3342            -nan     0.0010    0.0050 #>     40        1.2841            -nan     0.0010    0.0047 #>     60        1.2379            -nan     0.0010    0.0042 #>     80        1.1945            -nan     0.0010    0.0035 #>    100        1.1537            -nan     0.0010    0.0037 #>  #> Warning: No observation for response level(s): Informal #> Warning: The following classes were not found in 'response': Informal. BchMk.GBM$finalModel #> A gradient boosted model with multinomial loss function. #> 50 iterations were performed. #> There were 12 predictors of which 7 had non-zero influence. BchMk.GBM$Roc$auc #> Multi-class area under the curve: 0.6187 # }"},{"path":"https://seymakalay.github.io/pomodoro/reference/GLM_Model.html","id":null,"dir":"Reference","previous_headings":"","what":"Generalized Linear Model — GLM_Model","title":"Generalized Linear Model — GLM_Model","text":"Generalized Linear Model","code":""},{"path":"https://seymakalay.github.io/pomodoro/reference/GLM_Model.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generalized Linear Model — GLM_Model","text":"","code":"GLM_Model(Data, xvar, yvar)"},{"path":"https://seymakalay.github.io/pomodoro/reference/GLM_Model.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generalized Linear Model — GLM_Model","text":"Data name Dataset. xvar X variables. yvar Y variable.","code":""},{"path":"https://seymakalay.github.io/pomodoro/reference/GLM_Model.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generalized Linear Model — GLM_Model","text":"output  GLM_Model.","code":""},{"path":"https://seymakalay.github.io/pomodoro/reference/GLM_Model.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Generalized Linear Model — GLM_Model","text":"Let y vector response variable accessing credit applicant \\(n\\), \\(y_{}=1\\)  applicant-\\(\\) access credit, zero otherwise. Furthermore, let let \\(\\bold{x} = x_{ij}\\),  \\(=1,\\ldots,n\\) \\(j=1,\\ldots,p\\) characteristics applicants. log-odds can define : $$log(\\frac{\\pi_{}}{1-\\pi_{}}) = \\beta_{0}+\\bold{x}_{\\bold{}}\\beta = \\beta_{0}+\\sum_{=1}^{p}\\beta_{}\\bold{x}_{}$$ \\(\\beta_{0}\\) intercept, \\(\\beta = (\\beta_{1},\\ldots, \\beta_{p})\\)  \\(p\\) \\(x\\) \\(1\\) vector coefficients \t     \\(\\bold{x_{}}\\) \\(i_{th}\\) row  x.","code":""},{"path":"https://seymakalay.github.io/pomodoro/reference/GLM_Model.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generalized Linear Model — GLM_Model","text":"","code":"yvar <- c(\"multi.level\") sample_data <- sample_data[c(1:750),] xvar <- c(\"sex\", \"married\", \"age\", \"havejob\", \"educ\", \"political.afl\", \"rural\", \"region\", \"fin.intermdiaries\", \"fin.knowldge\", \"income\") BchMk.GLM <- GLM_Model(sample_data, c(xvar, \"networth\"), yvar ) #> + Fold01: parameter=none  #> - Fold01: parameter=none  #> + Fold02: parameter=none  #> - Fold02: parameter=none  #> + Fold03: parameter=none  #> - Fold03: parameter=none  #> + Fold04: parameter=none  #> - Fold04: parameter=none  #> + Fold05: parameter=none  #> - Fold05: parameter=none  #> + Fold06: parameter=none  #> - Fold06: parameter=none  #> + Fold07: parameter=none  #> - Fold07: parameter=none  #> + Fold08: parameter=none  #> - Fold08: parameter=none  #> + Fold09: parameter=none  #> - Fold09: parameter=none  #> + Fold10: parameter=none  #> - Fold10: parameter=none  #> Aggregating results #> Fitting final model on full training set #> Warning: glm.fit: algorithm did not converge BchMk.GLM$finalModel #>  #> Call:  glm(formula = Data.sub.train[, yvar] ~ ., family = binomial(link = \"logit\"),  #>     data = Data.sub.train) #>  #> Coefficients: #>       (Intercept)                sex            married                age   #>          -1.20704           -0.06493           -0.06183           -0.75239   #>           havejob               educ      political.afl              rural   #>           0.13974            0.09900           -0.05111           -0.17108   #>            region  fin.intermdiaries       fin.knowldge             income   #>           0.01923            0.01041            0.08658            0.69631   #>          networth   #>           0.19579   #>  #> Degrees of Freedom: 600 Total (i.e. Null);  588 Residual #> Null Deviance:\t    690.4  #> Residual Deviance: 591.3 \tAIC: 617.3 BchMk.GLM$Roc$auc #> Multi-class area under the curve: 0.7555"},{"path":"https://seymakalay.github.io/pomodoro/reference/MLM_Model.html","id":null,"dir":"Reference","previous_headings":"","what":"Multinominal Logistic Model — MLM_Model","title":"Multinominal Logistic Model — MLM_Model","text":"Multinominal Logistic Model","code":""},{"path":"https://seymakalay.github.io/pomodoro/reference/MLM_Model.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Multinominal Logistic Model — MLM_Model","text":"","code":"MLM_Model(Data, xvar, yvar)"},{"path":"https://seymakalay.github.io/pomodoro/reference/MLM_Model.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Multinominal Logistic Model — MLM_Model","text":"Data name Dataset. xvar X variables. yvar Y variable.","code":""},{"path":"https://seymakalay.github.io/pomodoro/reference/MLM_Model.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Multinominal Logistic Model — MLM_Model","text":"output  MLM_Model.","code":""},{"path":"https://seymakalay.github.io/pomodoro/reference/MLM_Model.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Multinominal Logistic Model — MLM_Model","text":"Multi-nominal model generalized form generalized logistic model can define $$\\pi_{}^{h} = P(y_{}^{h} = 1 | \\bold{x}_{\\bold{}}^{h})$$ \\(h\\) presents class labels (\"1--h\") basis input vector \\(x_j\\), case \\(x_j\\) loan types (\"Formal Loan\", \"Informal Loan\", \"Loan\", \"Loan\").  Furthermore, \\(y_{}^h =  1\\)weight w    \\(x_j\\) corresponds belong class  \\(y_{}^h=0\\) otherwise.   \\(\\) \\(\\\\) \\(1,\\ldots,h\\)   weight vectors w^corresponds class \\(\\). set \\({\\bold{{w}}^{h}} = 0\\) parameters learned weight vectors w^\\(\\) \\(\\\\) \\(1,\\ldots,h-1\\) . class probabilities must satisfy $$\\sum_{=1}^{h} P(y_{}^{h} = 1 | \\bold{x}_{\\bold{}}^{h}, \\bold{w}) = 1.$$","code":""},{"path":"https://seymakalay.github.io/pomodoro/reference/MLM_Model.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Multinominal Logistic Model — MLM_Model","text":"","code":"yvar <- c(\"Loan.Type\") sample_data <- sample_data[c(1:750),] xvar <- c(\"sex\", \"married\", \"age\", \"havejob\", \"educ\", \"political.afl\", \"rural\", \"region\", \"fin.intermdiaries\", \"fin.knowldge\", \"income\") BchMk.MLM <- MLM_Model(sample_data, c(xvar, \"networth\"), yvar ) #> + Fold01: decay=0e+00  #> # weights:  56 (39 variable) #> initial  value 749.985249  #> iter  10 value 364.275000 #> iter  20 value 349.993215 #> iter  30 value 348.132163 #> iter  40 value 348.054675 #> final  value 348.053959  #> converged #> - Fold01: decay=0e+00  #> + Fold01: decay=1e-01  #> # weights:  56 (39 variable) #> initial  value 749.985249  #> iter  10 value 366.551383 #> iter  20 value 353.548709 #> iter  30 value 352.181839 #> iter  40 value 352.097005 #> final  value 352.095989  #> converged #> - Fold01: decay=1e-01  #> + Fold01: decay=1e-04  #> # weights:  56 (39 variable) #> initial  value 749.985249  #> iter  10 value 364.277301 #> iter  20 value 349.996916 #> iter  30 value 348.136493 #> iter  40 value 348.059033 #> final  value 348.058318  #> converged #> - Fold01: decay=1e-04  #> + Fold02: decay=0e+00  #> # weights:  56 (39 variable) #> initial  value 751.371544  #> iter  10 value 443.570754 #> iter  20 value 384.960856 #> iter  30 value 352.538320 #> iter  40 value 344.812048 #> iter  50 value 344.345576 #> final  value 344.345291  #> converged #> - Fold02: decay=0e+00  #> + Fold02: decay=1e-01  #> # weights:  56 (39 variable) #> initial  value 751.371544  #> iter  10 value 455.605668 #> iter  20 value 382.613784 #> iter  30 value 353.653999 #> iter  40 value 348.673023 #> iter  50 value 348.509703 #> final  value 348.509569  #> converged #> - Fold02: decay=1e-01  #> + Fold02: decay=1e-04  #> # weights:  56 (39 variable) #> initial  value 751.371544  #> iter  10 value 443.584015 #> iter  20 value 384.965254 #> iter  30 value 352.492968 #> iter  40 value 344.817045 #> iter  50 value 344.350014 #> final  value 344.349775  #> converged #> - Fold02: decay=1e-04  #> + Fold03: decay=0e+00  #> # weights:  56 (39 variable) #> initial  value 751.371544  #> iter  10 value 489.828340 #> iter  20 value 384.206322 #> iter  30 value 362.592686 #> iter  40 value 354.641152 #> iter  50 value 354.526822 #> final  value 354.526765  #> converged #> - Fold03: decay=0e+00  #> + Fold03: decay=1e-01  #> # weights:  56 (39 variable) #> initial  value 751.371544  #> iter  10 value 497.910157 #> iter  20 value 390.379744 #> iter  30 value 362.646251 #> iter  40 value 358.407098 #> iter  50 value 358.328134 #> final  value 358.327852  #> converged #> - Fold03: decay=1e-01  #> + Fold03: decay=1e-04  #> # weights:  56 (39 variable) #> initial  value 751.371544  #> iter  10 value 489.837728 #> iter  20 value 384.204240 #> iter  30 value 362.537731 #> iter  40 value 354.645598 #> iter  50 value 354.530918 #> final  value 354.530860  #> converged #> - Fold03: decay=1e-04  #> + Fold04: decay=0e+00  #> # weights:  56 (39 variable) #> initial  value 747.212661  #> iter  10 value 456.813060 #> iter  20 value 369.345519 #> iter  30 value 350.474542 #> iter  40 value 344.054112 #> iter  50 value 343.965802 #> iter  50 value 343.965800 #> iter  50 value 343.965800 #> final  value 343.965800  #> converged #> - Fold04: decay=0e+00  #> + Fold04: decay=1e-01  #> # weights:  56 (39 variable) #> initial  value 747.212661  #> iter  10 value 467.483579 #> iter  20 value 375.442704 #> iter  30 value 349.810962 #> iter  40 value 348.093411 #> iter  50 value 348.075721 #> iter  50 value 348.075719 #> iter  50 value 348.075719 #> final  value 348.075719  #> converged #> - Fold04: decay=1e-01  #> + Fold04: decay=1e-04  #> # weights:  56 (39 variable) #> initial  value 747.212661  #> iter  10 value 456.824689 #> iter  20 value 369.353322 #> iter  30 value 350.476989 #> iter  40 value 344.059007 #> iter  50 value 343.970247 #> iter  50 value 343.970246 #> iter  50 value 343.970246 #> final  value 343.970246  #> converged #> - Fold04: decay=1e-04  #> + Fold05: decay=0e+00  #> # weights:  56 (39 variable) #> initial  value 751.371544  #> iter  10 value 454.564198 #> iter  20 value 375.895647 #> iter  30 value 353.935369 #> iter  40 value 347.467043 #> iter  50 value 347.371319 #> final  value 347.371306  #> converged #> - Fold05: decay=0e+00  #> + Fold05: decay=1e-01  #> # weights:  56 (39 variable) #> initial  value 751.371544  #> iter  10 value 464.973931 #> iter  20 value 379.876784 #> iter  30 value 353.915531 #> iter  40 value 351.219655 #> iter  50 value 351.150661 #> final  value 351.150645  #> converged #> - Fold05: decay=1e-01  #> + Fold05: decay=1e-04  #> # weights:  56 (39 variable) #> initial  value 751.371544  #> iter  10 value 454.575618 #> iter  20 value 375.901987 #> iter  30 value 353.949227 #> iter  40 value 347.472747 #> iter  50 value 347.375332 #> final  value 347.375319  #> converged #> - Fold05: decay=1e-04  #> + Fold06: decay=0e+00  #> # weights:  56 (39 variable) #> initial  value 748.598955  #> iter  10 value 360.994011 #> iter  20 value 344.187916 #> iter  30 value 342.589368 #> iter  40 value 342.439367 #> final  value 342.437864  #> converged #> - Fold06: decay=0e+00  #> + Fold06: decay=1e-01  #> # weights:  56 (39 variable) #> initial  value 748.598955  #> iter  10 value 363.028043 #> iter  20 value 347.408506 #> iter  30 value 346.104049 #> iter  40 value 345.996028 #> iter  50 value 345.994094 #> final  value 345.994085  #> converged #> - Fold06: decay=1e-01  #> + Fold06: decay=1e-04  #> # weights:  56 (39 variable) #> initial  value 748.598955  #> iter  10 value 360.996062 #> iter  20 value 344.191219 #> iter  30 value 342.593015 #> iter  40 value 342.443065 #> final  value 342.441562  #> converged #> - Fold06: decay=1e-04  #> + Fold07: decay=0e+00  #> # weights:  56 (39 variable) #> initial  value 749.985249  #> iter  10 value 472.261822 #> iter  20 value 374.628529 #> iter  30 value 351.933868 #> iter  40 value 347.542492 #> iter  50 value 347.500880 #> final  value 347.498560  #> converged #> - Fold07: decay=0e+00  #> + Fold07: decay=1e-01  #> # weights:  56 (39 variable) #> initial  value 749.985249  #> iter  10 value 484.240787 #> iter  20 value 379.265281 #> iter  30 value 354.781592 #> iter  40 value 351.718334 #> iter  50 value 351.681314 #> iter  50 value 351.681314 #> iter  50 value 351.681314 #> final  value 351.681314  #> converged #> - Fold07: decay=1e-01  #> + Fold07: decay=1e-04  #> # weights:  56 (39 variable) #> initial  value 749.985249  #> iter  10 value 472.274962 #> iter  20 value 374.635454 #> iter  30 value 351.932197 #> iter  40 value 347.548088 #> iter  50 value 347.505440 #> final  value 347.503130  #> converged #> - Fold07: decay=1e-04  #> + Fold08: decay=0e+00  #> # weights:  56 (39 variable) #> initial  value 749.985249  #> iter  10 value 459.718079 #> iter  20 value 375.599428 #> iter  30 value 351.233951 #> iter  40 value 344.638897 #> iter  50 value 344.386044 #> final  value 344.386019  #> converged #> - Fold08: decay=0e+00  #> + Fold08: decay=1e-01  #> # weights:  56 (39 variable) #> initial  value 749.985249  #> iter  10 value 483.638037 #> iter  20 value 381.962440 #> iter  30 value 353.692247 #> iter  40 value 348.328545 #> iter  50 value 348.175001 #> final  value 348.174740  #> converged #> - Fold08: decay=1e-01  #> + Fold08: decay=1e-04  #> # weights:  56 (39 variable) #> initial  value 749.985249  #> iter  10 value 459.735477 #> iter  20 value 375.639248 #> iter  30 value 351.235940 #> iter  40 value 344.642717 #> iter  50 value 344.390057 #> final  value 344.390030  #> converged #> - Fold08: decay=1e-04  #> + Fold09: decay=0e+00  #> # weights:  56 (39 variable) #> initial  value 748.598955  #> iter  10 value 443.942467 #> iter  20 value 369.112430 #> iter  30 value 346.459203 #> iter  40 value 340.534452 #> iter  50 value 340.442128 #> final  value 340.442110  #> converged #> - Fold09: decay=0e+00  #> + Fold09: decay=1e-01  #> # weights:  56 (39 variable) #> initial  value 748.598955  #> iter  10 value 457.687356 #> iter  20 value 371.313341 #> iter  30 value 346.852253 #> iter  40 value 344.558356 #> iter  50 value 344.475684 #> iter  50 value 344.475682 #> iter  50 value 344.475682 #> final  value 344.475682  #> converged #> - Fold09: decay=1e-01  #> + Fold09: decay=1e-04  #> # weights:  56 (39 variable) #> initial  value 748.598955  #> iter  10 value 443.957360 #> iter  20 value 369.119376 #> iter  30 value 346.428259 #> iter  40 value 340.539974 #> iter  50 value 340.446429 #> final  value 340.446412  #> converged #> - Fold09: decay=1e-04  #> + Fold10: decay=0e+00  #> # weights:  56 (39 variable) #> initial  value 749.985249  #> iter  10 value 466.524964 #> iter  20 value 365.821449 #> iter  30 value 350.687420 #> iter  40 value 347.070899 #> iter  50 value 346.977851 #> final  value 346.977842  #> converged #> - Fold10: decay=0e+00  #> + Fold10: decay=1e-01  #> # weights:  56 (39 variable) #> initial  value 749.985249  #> iter  10 value 477.977482 #> iter  20 value 375.774098 #> iter  30 value 356.609507 #> iter  40 value 351.794751 #> iter  50 value 351.288776 #> final  value 351.288551  #> converged #> - Fold10: decay=1e-01  #> + Fold10: decay=1e-04  #> # weights:  56 (39 variable) #> initial  value 749.985249  #> iter  10 value 466.537478 #> iter  20 value 365.833152 #> iter  30 value 350.703925 #> iter  40 value 347.088672 #> iter  50 value 346.995548 #> iter  60 value 346.986247 #> final  value 346.983098  #> converged #> - Fold10: decay=1e-04  #> Aggregating results #> Selecting tuning parameters #> Fitting decay = 1e-04 on full training set #> # weights:  56 (39 variable) #> initial  value 833.162911  #> iter  10 value 407.522712 #> iter  20 value 387.784474 #> iter  30 value 386.971261 #> iter  40 value 386.769896 #> iter  50 value 386.743524 #> final  value 386.743519  #> converged BchMk.MLM$finalModel #> Call: #> nnet::multinom(formula = .outcome ~ ., data = dat, decay = param$decay) #>  #> Coefficients: #>          (Intercept)         sex     married        age      havejob #> Formal     -2.883352 -0.29845912  0.20842889 -1.0508652 0.4050999418 #> Informal   -2.829452 -0.07438462 -0.06553534 -0.6294929 0.0008134758 #> L.Both     -3.493449 -0.25150913 -0.29699362 -1.1340836 0.3309852056 #>                 educ political.afl       rural     region fin.intermdiaries #> Formal    0.09718129     0.2855784  0.54460619 -0.4505575       0.007309791 #> Informal -0.20778309    -0.2617058 -0.07323338  0.1155695      -0.157459459 #> L.Both    0.31616307     0.2857973 -0.43727925  0.1542035       0.141371798 #>          fin.knowldge     income   networth #> Formal     0.14354111  0.7750757  0.4497748 #> Informal   0.20747504 -2.3438761 -1.2754599 #> L.Both     0.02142886  0.3304522  0.3101215 #>  #> Residual Deviance: 773.487  #> AIC: 851.487  BchMk.MLM$Roc$auc #> Multi-class area under the curve: 0.7047"},{"path":"https://seymakalay.github.io/pomodoro/reference/RF_Model.html","id":null,"dir":"Reference","previous_headings":"","what":"Random Forest — RF_Model","title":"Random Forest — RF_Model","text":"Random Forest","code":""},{"path":"https://seymakalay.github.io/pomodoro/reference/RF_Model.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Random Forest — RF_Model","text":"","code":"RF_Model(Data, xvar, yvar)"},{"path":"https://seymakalay.github.io/pomodoro/reference/RF_Model.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Random Forest — RF_Model","text":"Data name Dataset. xvar X variables. yvar Y variable.","code":""},{"path":"https://seymakalay.github.io/pomodoro/reference/RF_Model.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Random Forest — RF_Model","text":"output  RF_Model.","code":""},{"path":"https://seymakalay.github.io/pomodoro/reference/RF_Model.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Random Forest — RF_Model","text":"Rather considering random sample \\(m\\) predictors total \\(p\\) predictors split, random forest consider majority \\(p\\) predictors, considers split fresh sample  \\(m_{try}\\) usually set  \\(m_{try} \\approx \\sqrt{p}\\) Random forests de-correlate trees considering  \\(m_{try} \\approx \\sqrt{p}\\) show improvement bagged trees  \\(m = p\\).","code":""},{"path":"https://seymakalay.github.io/pomodoro/reference/RF_Model.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Random Forest — RF_Model","text":"","code":"# \\donttest{ sample_data <- sample_data[c(1:750),] yvar <- c(\"Loan.Type\") xvar <- c(\"sex\", \"married\", \"age\", \"havejob\", \"educ\", \"political.afl\", \"rural\", \"region\", \"fin.intermdiaries\", \"fin.knowldge\", \"income\") BchMk.RF <- RF_Model(sample_data, c(xvar, \"networth\"), yvar ) #> + Fold01: mtry= 2  #> - Fold01: mtry= 2  #> + Fold01: mtry= 7  #> - Fold01: mtry= 7  #> + Fold01: mtry=12  #> - Fold01: mtry=12  #> + Fold02: mtry= 2  #> - Fold02: mtry= 2  #> + Fold02: mtry= 7  #> - Fold02: mtry= 7  #> + Fold02: mtry=12  #> - Fold02: mtry=12  #> + Fold03: mtry= 2  #> - Fold03: mtry= 2  #> + Fold03: mtry= 7  #> - Fold03: mtry= 7  #> + Fold03: mtry=12  #> - Fold03: mtry=12  #> + Fold04: mtry= 2  #> - Fold04: mtry= 2  #> + Fold04: mtry= 7  #> - Fold04: mtry= 7  #> + Fold04: mtry=12  #> - Fold04: mtry=12  #> + Fold05: mtry= 2  #> - Fold05: mtry= 2  #> + Fold05: mtry= 7  #> - Fold05: mtry= 7  #> + Fold05: mtry=12  #> - Fold05: mtry=12  #> + Fold06: mtry= 2  #> - Fold06: mtry= 2  #> + Fold06: mtry= 7  #> - Fold06: mtry= 7  #> + Fold06: mtry=12  #> - Fold06: mtry=12  #> + Fold07: mtry= 2  #> - Fold07: mtry= 2  #> + Fold07: mtry= 7  #> - Fold07: mtry= 7  #> + Fold07: mtry=12  #> - Fold07: mtry=12  #> + Fold08: mtry= 2  #> - Fold08: mtry= 2  #> + Fold08: mtry= 7  #> - Fold08: mtry= 7  #> + Fold08: mtry=12  #> - Fold08: mtry=12  #> + Fold09: mtry= 2  #> - Fold09: mtry= 2  #> + Fold09: mtry= 7  #> - Fold09: mtry= 7  #> + Fold09: mtry=12  #> - Fold09: mtry=12  #> + Fold10: mtry= 2  #> - Fold10: mtry= 2  #> + Fold10: mtry= 7  #> - Fold10: mtry= 7  #> + Fold10: mtry=12  #> - Fold10: mtry=12  #> Aggregating results #> Selecting tuning parameters #> Fitting mtry = 2 on full training set BchMk.RF #> Random Forest  #>  #> 601 samples #>  12 predictor #>   4 classes: 'No.Loan', 'Formal', 'Informal', 'L.Both'  #>  #> Pre-processing: centered (12), scaled (12)  #> Resampling: Cross-Validated (10 fold)  #> Summary of sample sizes: 539, 542, 541, 541, 540, 541, ...  #> Resampling results across tuning parameters: #>  #>   mtry  Accuracy   Kappa     #>    2    0.7638425  0.2074747 #>    7    0.7455337  0.2130976 #>   12    0.7438671  0.2255766 #>  #> Accuracy was used to select the optimal model using the largest value. #> The final value used for the model was mtry = 2.  # }"},{"path":"https://seymakalay.github.io/pomodoro/reference/sample_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Sample data for analysis.\n\nA dataset containing information of access to credit. — sample_data","title":"Sample data for analysis.\n\nA dataset containing information of access to credit. — sample_data","text":"Sample data analysis. dataset containing information access credit.","code":""},{"path":"https://seymakalay.github.io/pomodoro/reference/sample_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sample data for analysis.\n\nA dataset containing information of access to credit. — sample_data","text":"","code":"sample_data"},{"path":"https://seymakalay.github.io/pomodoro/reference/sample_data.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Sample data for analysis.\n\nA dataset containing information of access to credit. — sample_data","text":"data_frame 53940 rows 10 variables: x1 hhid, household id number x2 swgt, survey weight x3 region, 3 factor level, west, east, center x4 .Loan, household loan x5 Formal, household formal loan x6 , household loan x7 Informal, household informal loan x8 sex, household male y1 Loan.Type, 4 factor level type loan y2 multi.level, 2 factor level household access loan ","code":""}]
